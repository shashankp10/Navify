[
  {
    "id": "1",
    "url": "https://supabase.com/docs",
    "title": "Supabase Docs",
    "content": "Search docs...\nSearch docs...\nSupabase DocumentationLearn how to get up and running with Supabase through tutorials, APIs and platform resources.Getting StartedDiscover how to set up a database to an app making queries in just a few minutes.\n  \t.t3e352ec5-c80f-4c5c-b0a1-3831f7d56595 {\n\t    color: #fff;\n\t    background: #222;\n\t    border: 1px solid transparent;\n\t    border-radius: undefinedpx;\n\t    padding: 8px 21px;\n  \t}\n\n  \t.t3e352ec5-c80f-4c5c-b0a1-3831f7d56595.place-top {\n        margin-top: -10px;\n    }\n    .t3e352ec5-c80f-4c5c-b0a1-3831f7d56595.place-top::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: 2;\n        width: 20px;\n        height: 12px;\n    }\n    .t3e352ec5-c80f-4c5c-b0a1-3831f7d56595.place-top::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        bottom: -6px;\n        left: 50%;\n        margin-left: -6px;\n        transform: rotate(135deg);\n    }\n\n    .t3e352ec5-c80f-4c5c-b0a1-3831f7d56595.place-bottom {\n        margin-top: 10px;\n    }\n    .t3e352ec5-c80f-4c5c-b0a1-3831f7d56595.place-bottom::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 18px;\n        height: 10px;\n    }\n    .t3e352ec5-c80f-4c5c-b0a1-3831f7d56595.place-bottom::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        top: -6px;\n        left: 50%;\n        margin-left: -6px;\n        transform: rotate(45deg);\n    }\n\n    .t3e352ec5-c80f-4c5c-b0a1-3831f7d56595.place-left {\n        margin-left: -10px;\n    }\n    .t3e352ec5-c80f-4c5c-b0a1-3831f7d56595.place-left::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 10px;\n        height: 18px;\n    }\n    .t3e352ec5-c80f-4c5c-b0a1-3831f7d56595.place-left::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        right: -6px;\n        top: 50%;\n        margin-top: -6px;\n        transform: rotate(45deg);\n    }\n\n    .t3e352ec5-c80f-4c5c-b0a1-3831f7d56595.place-right {\n        margin-left: 10px;\n    }\n    .t3e352ec5-c80f-4c5c-b0a1-3831f7d56595.place-right::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 10px;\n        height: 18px;\n    }\n    .t3e352ec5-c80f-4c5c-b0a1-3831f7d56595.place-right::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        left: -6px;\n        top: 50%;\n        margin-top: -6px;\n        transform: rotate(-135deg);\n    }\n  \n  \t.t18f3b1b3-2b40-4753-9378-9b9e72a17436 {\n\t    color: #fff;\n\t    background: #222;\n\t    border: 1px solid transparent;\n\t    border-radius: undefinedpx;\n\t    padding: 8px 21px;\n  \t}\n\n  \t.t18f3b1b3-2b40-4753-9378-9b9e72a17436.place-top {\n        margin-top: -10px;\n    }\n    .t18f3b1b3-2b40-4753-9378-9b9e72a17436.place-top::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: 2;\n        width: 20px;\n        height: 12px;\n    }\n    .t18f3b1b3-2b40-4753-9378-9b9e72a17436.place-top::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        bottom: -6px;\n        left: 50%;\n        margin-left: -6px;\n        transform: rotate(135deg);\n    }\n\n    .t18f3b1b3-2b40-4753-9378-9b9e72a17436.place-bottom {\n        margin-top: 10px;\n    }\n    .t18f3b1b3-2b40-4753-9378-9b9e72a17436.place-bottom::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 18px;\n        height: 10px;\n    }\n    .t18f3b1b3-2b40-4753-9378-9b9e72a17436.place-bottom::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        top: -6px;\n        left: 50%;\n        margin-left: -6px;\n        transform: rotate(45deg);\n    }\n\n    .t18f3b1b3-2b40-4753-9378-9b9e72a17436.place-left {\n        margin-left: -10px;\n    }\n    .t18f3b1b3-2b40-4753-9378-9b9e72a17436.place-left::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 10px;\n        height: 18px;\n    }\n    .t18f3b1b3-2b40-4753-9378-9b9e72a17436.place-left::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        right: -6px;\n        top: 50%;\n        margin-top: -6px;\n        transform: rotate(45deg);\n    }\n\n    .t18f3b1b3-2b40-4753-9378-9b9e72a17436.place-right {\n        margin-left: 10px;\n    }\n    .t18f3b1b3-2b40-4753-9378-9b9e72a17436.place-right::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 10px;\n        height: 18px;\n    }\n    .t18f3b1b3-2b40-4753-9378-9b9e72a17436.place-right::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        left: -6px;\n        top: 50%;\n        margin-top: -6px;\n        transform: rotate(-135deg);\n    }\n  \n  \t.t8ad22733-4df4-4a21-99fb-87630c199948 {\n\t    color: #fff;\n\t    background: #222;\n\t    border: 1px solid transparent;\n\t    border-radius: undefinedpx;\n\t    padding: 8px 21px;\n  \t}\n\n  \t.t8ad22733-4df4-4a21-99fb-87630c199948.place-top {\n        margin-top: -10px;\n    }\n    .t8ad22733-4df4-4a21-99fb-87630c199948.place-top::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: 2;\n        width: 20px;\n        height: 12px;\n    }\n    .t8ad22733-4df4-4a21-99fb-87630c199948.place-top::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        bottom: -6px;\n        left: 50%;\n        margin-left: -6px;\n        transform: rotate(135deg);\n    }\n\n    .t8ad22733-4df4-4a21-99fb-87630c199948.place-bottom {\n        margin-top: 10px;\n    }\n    .t8ad22733-4df4-4a21-99fb-87630c199948.place-bottom::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 18px;\n        height: 10px;\n    }\n    .t8ad22733-4df4-4a21-99fb-87630c199948.place-bottom::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        top: -6px;\n        left: 50%;\n        margin-left: -6px;\n        transform: rotate(45deg);\n    }\n\n    .t8ad22733-4df4-4a21-99fb-87630c199948.place-left {\n        margin-left: -10px;\n    }\n    .t8ad22733-4df4-4a21-99fb-87630c199948.place-left::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 10px;\n        height: 18px;\n    }\n    .t8ad22733-4df4-4a21-99fb-87630c199948.place-left::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        right: -6px;\n        top: 50%;\n        margin-top: -6px;\n        transform: rotate(45deg);\n    }\n\n    .t8ad22733-4df4-4a21-99fb-87630c199948.place-right {\n        margin-left: 10px;\n    }\n    .t8ad22733-4df4-4a21-99fb-87630c199948.place-right::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 10px;\n        height: 18px;\n    }\n    .t8ad22733-4df4-4a21-99fb-87630c199948.place-right::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        left: -6px;\n        top: 50%;\n        margin-top: -6px;\n        transform: rotate(-135deg);\n    }\n  \n  \t.te41508e1-6d57-4b67-a1a2-c236056af764 {\n\t    color: #fff;\n\t    background: #222;\n\t    border: 1px solid transparent;\n\t    border-radius: undefinedpx;\n\t    padding: 8px 21px;\n  \t}\n\n  \t.te41508e1-6d57-4b67-a1a2-c236056af764.place-top {\n        margin-top: -10px;\n    }\n    .te41508e1-6d57-4b67-a1a2-c236056af764.place-top::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: 2;\n        width: 20px;\n        height: 12px;\n    }\n    .te41508e1-6d57-4b67-a1a2-c236056af764.place-top::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        bottom: -6px;\n        left: 50%;\n        margin-left: -6px;\n        transform: rotate(135deg);\n    }\n\n    .te41508e1-6d57-4b67-a1a2-c236056af764.place-bottom {\n        margin-top: 10px;\n    }\n    .te41508e1-6d57-4b67-a1a2-c236056af764.place-bottom::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 18px;\n        height: 10px;\n    }\n    .te41508e1-6d57-4b67-a1a2-c236056af764.place-bottom::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        top: -6px;\n        left: 50%;\n        margin-left: -6px;\n        transform: rotate(45deg);\n    }\n\n    .te41508e1-6d57-4b67-a1a2-c236056af764.place-left {\n        margin-left: -10px;\n    }\n    .te41508e1-6d57-4b67-a1a2-c236056af764.place-left::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 10px;\n        height: 18px;\n    }\n    .te41508e1-6d57-4b67-a1a2-c236056af764.place-left::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        right: -6px;\n        top: 50%;\n        margin-top: -6px;\n        transform: rotate(45deg);\n    }\n\n    .te41508e1-6d57-4b67-a1a2-c236056af764.place-right {\n        margin-left: 10px;\n    }\n    .te41508e1-6d57-4b67-a1a2-c236056af764.place-right::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 10px;\n        height: 18px;\n    }\n    .te41508e1-6d57-4b67-a1a2-c236056af764.place-right::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        left: -6px;\n        top: 50%;\n        margin-top: -6px;\n        transform: rotate(-135deg);\n    }\n  \n  \t.t0dcff75b-3a10-4493-9c69-dc825d657d16 {\n\t    color: #fff;\n\t    background: #222;\n\t    border: 1px solid transparent;\n\t    border-radius: undefinedpx;\n\t    padding: 8px 21px;\n  \t}\n\n  \t.t0dcff75b-3a10-4493-9c69-dc825d657d16.place-top {\n        margin-top: -10px;\n    }\n    .t0dcff75b-3a10-4493-9c69-dc825d657d16.place-top::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: 2;\n        width: 20px;\n        height: 12px;\n    }\n    .t0dcff75b-3a10-4493-9c69-dc825d657d16.place-top::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        bottom: -6px;\n        left: 50%;\n        margin-left: -6px;\n        transform: rotate(135deg);\n    }\n\n    .t0dcff75b-3a10-4493-9c69-dc825d657d16.place-bottom {\n        margin-top: 10px;\n    }\n    .t0dcff75b-3a10-4493-9c69-dc825d657d16.place-bottom::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 18px;\n        height: 10px;\n    }\n    .t0dcff75b-3a10-4493-9c69-dc825d657d16.place-bottom::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        top: -6px;\n        left: 50%;\n        margin-left: -6px;\n        transform: rotate(45deg);\n    }\n\n    .t0dcff75b-3a10-4493-9c69-dc825d657d16.place-left {\n        margin-left: -10px;\n    }\n    .t0dcff75b-3a10-4493-9c69-dc825d657d16.place-left::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 10px;\n        height: 18px;\n    }\n    .t0dcff75b-3a10-4493-9c69-dc825d657d16.place-left::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        right: -6px;\n        top: 50%;\n        margin-top: -6px;\n        transform: rotate(45deg);\n    }\n\n    .t0dcff75b-3a10-4493-9c69-dc825d657d16.place-right {\n        margin-left: 10px;\n    }\n    .t0dcff75b-3a10-4493-9c69-dc825d657d16.place-right::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 10px;\n        height: 18px;\n    }\n    .t0dcff75b-3a10-4493-9c69-dc825d657d16.place-right::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        left: -6px;\n        top: 50%;\n        margin-top: -6px;\n        transform: rotate(-135deg);\n    }\n  \n  \t.t207ad653-8317-40da-9485-a84c51892518 {\n\t    color: #fff;\n\t    background: #222;\n\t    border: 1px solid transparent;\n\t    border-radius: undefinedpx;\n\t    padding: 8px 21px;\n  \t}\n\n  \t.t207ad653-8317-40da-9485-a84c51892518.place-top {\n        margin-top: -10px;\n    }\n    .t207ad653-8317-40da-9485-a84c51892518.place-top::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: 2;\n        width: 20px;\n        height: 12px;\n    }\n    .t207ad653-8317-40da-9485-a84c51892518.place-top::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        bottom: -6px;\n        left: 50%;\n        margin-left: -6px;\n        transform: rotate(135deg);\n    }\n\n    .t207ad653-8317-40da-9485-a84c51892518.place-bottom {\n        margin-top: 10px;\n    }\n    .t207ad653-8317-40da-9485-a84c51892518.place-bottom::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 18px;\n        height: 10px;\n    }\n    .t207ad653-8317-40da-9485-a84c51892518.place-bottom::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        top: -6px;\n        left: 50%;\n        margin-left: -6px;\n        transform: rotate(45deg);\n    }\n\n    .t207ad653-8317-40da-9485-a84c51892518.place-left {\n        margin-left: -10px;\n    }\n    .t207ad653-8317-40da-9485-a84c51892518.place-left::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 10px;\n        height: 18px;\n    }\n    .t207ad653-8317-40da-9485-a84c51892518.place-left::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        right: -6px;\n        top: 50%;\n        margin-top: -6px;\n        transform: rotate(45deg);\n    }\n\n    .t207ad653-8317-40da-9485-a84c51892518.place-right {\n        margin-left: 10px;\n    }\n    .t207ad653-8317-40da-9485-a84c51892518.place-right::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 10px;\n        height: 18px;\n    }\n    .t207ad653-8317-40da-9485-a84c51892518.place-right::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        left: -6px;\n        top: 50%;\n        margin-top: -6px;\n        transform: rotate(-135deg);\n    }\n  \n  \t.t1fce123d-cc6c-4cce-9b3a-143bf186e5b5 {\n\t    color: #fff;\n\t    background: #222;\n\t    border: 1px solid transparent;\n\t    border-radius: undefinedpx;\n\t    padding: 8px 21px;\n  \t}\n\n  \t.t1fce123d-cc6c-4cce-9b3a-143bf186e5b5.place-top {\n        margin-top: -10px;\n    }\n    .t1fce123d-cc6c-4cce-9b3a-143bf186e5b5.place-top::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: 2;\n        width: 20px;\n        height: 12px;\n    }\n    .t1fce123d-cc6c-4cce-9b3a-143bf186e5b5.place-top::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        bottom: -6px;\n        left: 50%;\n        margin-left: -6px;\n        transform: rotate(135deg);\n    }\n\n    .t1fce123d-cc6c-4cce-9b3a-143bf186e5b5.place-bottom {\n        margin-top: 10px;\n    }\n    .t1fce123d-cc6c-4cce-9b3a-143bf186e5b5.place-bottom::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 18px;\n        height: 10px;\n    }\n    .t1fce123d-cc6c-4cce-9b3a-143bf186e5b5.place-bottom::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        top: -6px;\n        left: 50%;\n        margin-left: -6px;\n        transform: rotate(45deg);\n    }\n\n    .t1fce123d-cc6c-4cce-9b3a-143bf186e5b5.place-left {\n        margin-left: -10px;\n    }\n    .t1fce123d-cc6c-4cce-9b3a-143bf186e5b5.place-left::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 10px;\n        height: 18px;\n    }\n    .t1fce123d-cc6c-4cce-9b3a-143bf186e5b5.place-left::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        right: -6px;\n        top: 50%;\n        margin-top: -6px;\n        transform: rotate(45deg);\n    }\n\n    .t1fce123d-cc6c-4cce-9b3a-143bf186e5b5.place-right {\n        margin-left: 10px;\n    }\n    .t1fce123d-cc6c-4cce-9b3a-143bf186e5b5.place-right::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 10px;\n        height: 18px;\n    }\n    .t1fce123d-cc6c-4cce-9b3a-143bf186e5b5.place-right::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        left: -6px;\n        top: 50%;\n        margin-top: -6px;\n        transform: rotate(-135deg);\n    }\n  \n  \t.t3e7ccd23-2d1e-447d-9f54-593dc2f59237 {\n\t    color: #fff;\n\t    background: #222;\n\t    border: 1px solid transparent;\n\t    border-radius: undefinedpx;\n\t    padding: 8px 21px;\n  \t}\n\n  \t.t3e7ccd23-2d1e-447d-9f54-593dc2f59237.place-top {\n        margin-top: -10px;\n    }\n    .t3e7ccd23-2d1e-447d-9f54-593dc2f59237.place-top::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: 2;\n        width: 20px;\n        height: 12px;\n    }\n    .t3e7ccd23-2d1e-447d-9f54-593dc2f59237.place-top::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        bottom: -6px;\n        left: 50%;\n        margin-left: -6px;\n        transform: rotate(135deg);\n    }\n\n    .t3e7ccd23-2d1e-447d-9f54-593dc2f59237.place-bottom {\n        margin-top: 10px;\n    }\n    .t3e7ccd23-2d1e-447d-9f54-593dc2f59237.place-bottom::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 18px;\n        height: 10px;\n    }\n    .t3e7ccd23-2d1e-447d-9f54-593dc2f59237.place-bottom::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        top: -6px;\n        left: 50%;\n        margin-left: -6px;\n        transform: rotate(45deg);\n    }\n\n    .t3e7ccd23-2d1e-447d-9f54-593dc2f59237.place-left {\n        margin-left: -10px;\n    }\n    .t3e7ccd23-2d1e-447d-9f54-593dc2f59237.place-left::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 10px;\n        height: 18px;\n    }\n    .t3e7ccd23-2d1e-447d-9f54-593dc2f59237.place-left::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        right: -6px;\n        top: 50%;\n        margin-top: -6px;\n        transform: rotate(45deg);\n    }\n\n    .t3e7ccd23-2d1e-447d-9f54-593dc2f59237.place-right {\n        margin-left: 10px;\n    }\n    .t3e7ccd23-2d1e-447d-9f54-593dc2f59237.place-right::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 10px;\n        height: 18px;\n    }\n    .t3e7ccd23-2d1e-447d-9f54-593dc2f59237.place-right::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        left: -6px;\n        top: 50%;\n        margin-top: -6px;\n        transform: rotate(-135deg);\n    }\n  \n  \t.t96f39134-d627-4c6a-b5f4-c3922a2b96c4 {\n\t    color: #fff;\n\t    background: #222;\n\t    border: 1px solid transparent;\n\t    border-radius: undefinedpx;\n\t    padding: 8px 21px;\n  \t}\n\n  \t.t96f39134-d627-4c6a-b5f4-c3922a2b96c4.place-top {\n        margin-top: -10px;\n    }\n    .t96f39134-d627-4c6a-b5f4-c3922a2b96c4.place-top::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: 2;\n        width: 20px;\n        height: 12px;\n    }\n    .t96f39134-d627-4c6a-b5f4-c3922a2b96c4.place-top::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        bottom: -6px;\n        left: 50%;\n        margin-left: -6px;\n        transform: rotate(135deg);\n    }\n\n    .t96f39134-d627-4c6a-b5f4-c3922a2b96c4.place-bottom {\n        margin-top: 10px;\n    }\n    .t96f39134-d627-4c6a-b5f4-c3922a2b96c4.place-bottom::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 18px;\n        height: 10px;\n    }\n    .t96f39134-d627-4c6a-b5f4-c3922a2b96c4.place-bottom::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        top: -6px;\n        left: 50%;\n        margin-left: -6px;\n        transform: rotate(45deg);\n    }\n\n    .t96f39134-d627-4c6a-b5f4-c3922a2b96c4.place-left {\n        margin-left: -10px;\n    }\n    .t96f39134-d627-4c6a-b5f4-c3922a2b96c4.place-left::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 10px;\n        height: 18px;\n    }\n    .t96f39134-d627-4c6a-b5f4-c3922a2b96c4.place-left::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        right: -6px;\n        top: 50%;\n        margin-top: -6px;\n        transform: rotate(45deg);\n    }\n\n    .t96f39134-d627-4c6a-b5f4-c3922a2b96c4.place-right {\n        margin-left: 10px;\n    }\n    .t96f39134-d627-4c6a-b5f4-c3922a2b96c4.place-right::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 10px;\n        height: 18px;\n    }\n    .t96f39134-d627-4c6a-b5f4-c3922a2b96c4.place-right::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        left: -6px;\n        top: 50%;\n        margin-top: -6px;\n        transform: rotate(-135deg);\n    }\n  \n  \t.ta8157e14-4d04-4e90-8e7d-a579d065f9bc {\n\t    color: #fff;\n\t    background: #222;\n\t    border: 1px solid transparent;\n\t    border-radius: undefinedpx;\n\t    padding: 8px 21px;\n  \t}\n\n  \t.ta8157e14-4d04-4e90-8e7d-a579d065f9bc.place-top {\n        margin-top: -10px;\n    }\n    .ta8157e14-4d04-4e90-8e7d-a579d065f9bc.place-top::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: 2;\n        width: 20px;\n        height: 12px;\n    }\n    .ta8157e14-4d04-4e90-8e7d-a579d065f9bc.place-top::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        bottom: -6px;\n        left: 50%;\n        margin-left: -6px;\n        transform: rotate(135deg);\n    }\n\n    .ta8157e14-4d04-4e90-8e7d-a579d065f9bc.place-bottom {\n        margin-top: 10px;\n    }\n    .ta8157e14-4d04-4e90-8e7d-a579d065f9bc.place-bottom::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 18px;\n        height: 10px;\n    }\n    .ta8157e14-4d04-4e90-8e7d-a579d065f9bc.place-bottom::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        top: -6px;\n        left: 50%;\n        margin-left: -6px;\n        transform: rotate(45deg);\n    }\n\n    .ta8157e14-4d04-4e90-8e7d-a579d065f9bc.place-left {\n        margin-left: -10px;\n    }\n    .ta8157e14-4d04-4e90-8e7d-a579d065f9bc.place-left::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 10px;\n        height: 18px;\n    }\n    .ta8157e14-4d04-4e90-8e7d-a579d065f9bc.place-left::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        right: -6px;\n        top: 50%;\n        margin-top: -6px;\n        transform: rotate(45deg);\n    }\n\n    .ta8157e14-4d04-4e90-8e7d-a579d065f9bc.place-right {\n        margin-left: 10px;\n    }\n    .ta8157e14-4d04-4e90-8e7d-a579d065f9bc.place-right::before {\n        content: \"\";\n        background-color: inherit;\n        position: absolute;\n        z-index: -1;\n        width: 10px;\n        height: 18px;\n    }\n    .ta8157e14-4d04-4e90-8e7d-a579d065f9bc.place-right::after {\n        content: \"\";\n        position: absolute;\n        width: 10px;\n        height: 10px;\n        border-top-right-radius: undefinedpx;\n        border: 1px solid transparent;\n        background-color: #222;\n        z-index: -2;\n        left: -6px;\n        top: 50%;\n        margin-top: -6px;\n        transform: rotate(-135deg);\n    }\n  ProductsDatabaseSupabase provides a full Postgres database for every project with Realtime functionality, database backups, extensions, and more.AuthAdd and manage email and password, passwordless, OAuth, and mobile logins to your project through a suite of identity providers and APIs.StorageStore, organize, transform, and serve large filesâ€”fully integrated with your Postgres database with Row Level Security access policies.AI & VectorsUse Supabase to store and search embedding vectors.RealtimeListen to database changes, store and sync user states across clients, broadcast data to clients subscribed to a channel, and more.Edge FunctionsGlobally distributed, server-side functions to execute your code closest to your users for the lowest latency.Client LibrariesJavascriptFlutterPythonC#SwiftKotlinMigrate to SupabaseBring your existing data, auth and storage to Supabase following our migration guides.Explore more resources about /guides/resourcesExplore more resourcesAuth0Firebase AuthFirestore DataFirebase StorageHerokuRenderAmazon RDSPostgresVercel PostgresNeonMySQLMSSQLAdditional resourcesManagement APIManage your Supabase projects and organizations.Supabase CLIUse the CLI to develop, manage and deploy your projects.Platform GuidesLearn more about the tools and services powering Supabase.IntegrationsExplore a variety of integrations from Supabase partners.Self-HostingGet started with self-hosting Supabase.More on Self-Hosting about /guides/self-hostingMore on Self-HostingAuthRealtimeStorageAnalytics\nSupabase Documentation\nLearn how to get up and running with Supabase through tutorials, APIs and platform resources.\nGetting Started\nDiscover how to set up a database to an app making queries in just a few minutes.\nProducts\nDatabase\nAuth\nStorage\nAI & Vectors\nRealtime\nEdge Functions\nClient Libraries\nJavascript\nFlutter\nPython\nC#\nSwift\nKotlin\nMigrate to Supabase\nBring your existing data, auth and storage to Supabase following our migration guides.\nAuth0\nFirebase Auth\nFirestore Data\nFirebase Storage\nHeroku\nRender\nAmazon RDS\nPostgres\nVercel Postgres\nNeon\nMySQL\nMSSQL\nAdditional resources\nManagement API\nSupabase CLI\nPlatform Guides\nIntegrations\nSelf-Hosting\nGet started with self-hosting Supabase.\nAuth\nRealtime\nStorage\nAnalytics\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "2",
    "url": "https://supabase.com/docs/guides/getting-started",
    "title": "Getting Started | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nGetting StartedFeaturesA non-exhaustive list of features that Supabase provides for every project.ArchitectureAn overview of Supabase's architecture and product principles.Local DevelopmentUse the Supabase CLI to develop locally and collaborate between teams.\nUse cases#\nAI, Vectors, and embeddingsBuild AI-enabled applications using our Vector toolkit.Subscription Payments (SaaS)Clone, deploy, and fully customize a SaaS subscription application with Next.js.Partner GalleryPostgres full-text search, image storage, and more.\nFramework quickstarts#\nReactLearn how to create a Supabase project, add some sample data to your database, and query the data from a React app.Next.jsLearn how to create a Supabase project, add some sample data to your database, and query the data from a Next.js app.NuxtJSLearn how to create a Supabase project, add some sample data to your database, and query the data from a NuxtJS app.RedwoodJSLearn how to create a Supabase project, add some sample data to your database using Prisma migration and seeds, and query the data from a RedwoodJS app.FlutterLearn how to create a Supabase project, add some sample data to your database, and query the data from a Flutter app.iOS SwiftUILearn how to create a Supabase project, add some sample data to your database, and query the data from an iOS app.Android KotlinLearn how to create a Supabase project, add some sample data to your database, and query the data from an Android Kotlin app.SvelteKitLearn how to create a Supabase project, add some sample data to your database, and query the data from a SvelteKit app.SolidJSLearn how to create a Supabase project, add some sample data to your database, and query the data from a SolidJS app.VueLearn how to create a Supabase project, add some sample data to your database, and query the data from a Vue app.refineLearn how to create a Supabase project, add some sample data to your database, and query the data from a refine app.\nWeb app demos#\nNext.jsLearn how to build a user management app with Next.js and Supabase Database, Auth, and Storage functionality.ReactLearn how to build a user management app with React and Supabase Database, Auth, and Storage functionality.Vue 3Learn how to build a user management app with Vue 3 and Supabase Database, Auth, and Storage functionality.Nuxt 3Learn how to build a user management app with Nuxt 3 and Supabase Database, Auth, and Storage functionality.AngularLearn how to build a user management app with Angular and Supabase Database, Auth, and Storage functionality.RedwoodJSLearn how to build a user management app with RedwoodJS and Supabase Database, Auth, and Storage functionality.SvelteLearn how to build a user management app with Svelte and Supabase Database, Auth, and Storage functionality.SvelteKitLearn how to build a user management app with SvelteKit and Supabase Database, Auth, and Storage functionality.refineLearn how to build a user management app with refine and Supabase Database, Auth, and Storage functionality.\nMobile tutorials#\nFlutterLearn how to build a user management app with Flutter and Supabase Database, Auth, and Storage functionality.Expo React NativeLearn how to build a user management app with Expo React Native and Supabase Database, Auth, and Storage functionality.Android KotlinLearn how to build a product management app with Android and Supabase Database, Auth, and Storage functionality.iOS SwiftLearn how to build a user management app with iOS and Supabase Database, Auth, and Storage functionality.Ionic ReactLearn how to build a user management app with Ionic React and Supabase Database, Auth, and Storage functionality.Ionic VueLearn how to build a user management app with Ionic Vue and Supabase Database, Auth, and Storage functionality.Ionic AngularLearn how to build a user management app with Ionic Angular and Supabase Database, Auth, and Storage functionality.Edit this page on GitHub\nGetting Started\nFeatures\nArchitecture\nLocal Development\nUse cases#\nAI, Vectors, and embeddings\nSubscription Payments (SaaS)\nPartner Gallery\nFramework quickstarts#\nReact\nNext.js\nNuxtJS\nRedwoodJS\nFlutter\niOS SwiftUI\nAndroid Kotlin\nSvelteKit\nSolidJS\nVue\nrefine\nWeb app demos#\nNext.js\nReact\nVue 3\nNuxt 3\nAngular\nRedwoodJS\nSvelte\nSvelteKit\nrefine\nMobile tutorials#\nFlutter\nExpo React Native\nAndroid Kotlin\niOS Swift\nIonic React\nIonic Vue\nIonic Angular\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "3",
    "url": "https://supabase.com/docs/guides/getting-started/quickstarts/reactjs",
    "title": "Use Supabase with React | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nUse Supabase with ReactLearn how to create a Supabase project, add some sample data to your database, and query the data from a React app.[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\n1[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nCreate a Supabase projectGo to database.new and create a new Supabase project.When your project is up and running, go to the Table Editor, create a new table and insert some data.Alternatively, you can run the following snippet in your project's SQL Editor. This will create a countries table with some sample data.\nSQL_EDITOR_13-- Create the table_13create table countries (_13  id bigint primary key generated always as identity,_13  name text not null_13);_13-- Insert some sample data into the table_13insert into countries (name)_13values_13  ('Canada'),_13  ('United States'),_13  ('Mexico');_13_13alter table countries enable row level security;\nMake the data in your table publicly readable by adding an RLS policy:\nSQL_EDITOR_10create policy \"public can read countries\"_10on public.countries_10for select to anon_10using (true);2Create a React appCreate a React app using a Vite template.Terminal_10npm create vite@latest my-app -- --template react3Install the Supabase client libraryThe fastest way to get started is to use the supabase-js client library which provides a convenient interface for working with Supabase from a React app.Navigate to the React app and install supabase-js.Terminal_10cd my-app && npm install @supabase/supabase-js4Query data from the appIn App.jsx, create a Supabase client using your project URL and public API (anon) key:Project URLLoading...Anon keyLoading...Add a getCountries function to fetch the data and display the query result to the page.src/App.jsx_27  import { useEffect, useState } from \"react\";_27  import { createClient } from \"@supabase/supabase-js\";_27_27  const supabase = createClient(\"https://<project>.supabase.co\", \"<your-anon-key>\");_27_27  function App() {_27    const [countries, setCountries] = useState([]);_27_27    useEffect(() => {_27      getCountries();_27    }, []);_27_27    async function getCountries() {_27      const { data } = await supabase.from(\"countries\").select();_27      setCountries(data);_27    }_27_27    return (_27      <ul>_27        {countries.map((country) => (_27          <li key={country.name}>{country.name}</li>_27        ))}_27      </ul>_27    );_27  }_27_27  export default App;5Start the appStart the app, go to http://localhost:5173 in a browser, and open the browser console and you should see the list of countries.Terminal_10npm run dev\nNext steps#\n\nSet up Auth for your app\nInsert more data into your database\nUpload and serve static files using Storage\nEdit this page on GitHub\nUse Supabase with React\nLearn how to create a Supabase project, add some sample data to your database, and query the data from a React app.\nCreate a Supabase project\nGo to database.new and create a new Supabase project.\nWhen your project is up and running, go to the Table Editor, create a new table and insert some data.\nAlternatively, you can run the following snippet in your project's SQL Editor. This will create a countries table with some sample data.\n\nMake the data in your table publicly readable by adding an RLS policy:\nCreate a React app\nCreate a React app using a Vite template.\nInstall the Supabase client library\nThe fastest way to get started is to use the supabase-js client library which provides a convenient interface for working with Supabase from a React app.\nNavigate to the React app and install supabase-js.\nQuery data from the app\nIn App.jsx, create a Supabase client using your project URL and public API (anon) key:\nProject URL\nAnon key\nAdd a getCountries function to fetch the data and display the query result to the page.\nStart the app\nStart the app, go to http://localhost:5173 in a browser, and open the browser console and you should see the list of countries.\nNext steps#\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "4",
    "url": "https://supabase.com/docs/guides/getting-started/quickstarts/nextjs",
    "title": "Use Supabase with Next.js | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nUse Supabase with Next.jsLearn how to create a Supabase project, add some sample data, and query from a Next.js app.[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\n1[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nCreate a Supabase projectGo to database.new and create a new Supabase project.When your project is up and running, go to the Table Editor, create a new table and insert some data.Alternatively, you can run the following snippet in your project's SQL Editor. This will create a countries table with some sample data.\nSQL_EDITOR_13-- Create the table_13create table countries (_13  id bigint primary key generated always as identity,_13  name text not null_13);_13-- Insert some sample data into the table_13insert into countries (name)_13values_13  ('Canada'),_13  ('United States'),_13  ('Mexico');_13_13alter table countries enable row level security;\nMake the data in your table publicly readable by adding an RLS policy:\nSQL_EDITOR_10create policy \"public can read countries\"_10on public.countries_10for select to anon_10using (true);2Create a Next.js appUse the create-next-app command and the with-supabase template, to create a Next.js app pre-configured with:\nCookie-based Auth\nTypeScript\nTailwind CSS\nTerminal_10npx create-next-app -e with-supabase3Declare Supabase Environment VariablesRename .env.example to .env.local and populate with your Supabase connection variables:Project URLLoading...Anon keyLoading....env.local_10NEXT_PUBLIC_SUPABASE_URL=<SUBSTITUTE_SUPABASE_URL>_10NEXT_PUBLIC_SUPABASE_ANON_KEY=<SUBSTITUTE_SUPABASE_ANON_KEY>4Query Supabase data from Next.jsCreate a new file at app/countries/page.tsx and populate with the following.This will select all the rows from the countries table in Supabase and render them on the page.app/countries/page.tsxutils/supabase/server.ts_10  import { createClient } from '@/utils/supabase/server';_10_10  export default async function Countries() {_10    const supabase = await createClient();_10    const { data: countries } = await supabase.from(\"countries\").select();_10_10    return <pre>{JSON.stringify(countries, null, 2)}</pre>_10  }5Start the appRun the development server, go to http://localhost:3000/countries in a browser and you should see the list of countries.Terminal_10npm run dev\nNext steps#\n\nSet up Auth for your app\nInsert more data into your database\nUpload and serve static files using Storage\nEdit this page on GitHub\nUse Supabase with Next.js\nLearn how to create a Supabase project, add some sample data, and query from a Next.js app.\nCreate a Supabase project\nGo to database.new and create a new Supabase project.\nWhen your project is up and running, go to the Table Editor, create a new table and insert some data.\nAlternatively, you can run the following snippet in your project's SQL Editor. This will create a countries table with some sample data.\n\nMake the data in your table publicly readable by adding an RLS policy:\nCreate a Next.js app\nUse the create-next-app command and the with-supabase template, to create a Next.js app pre-configured with:\nDeclare Supabase Environment Variables\nRename .env.example to .env.local and populate with your Supabase connection variables:\nProject URL\nAnon key\nQuery Supabase data from Next.js\nCreate a new file at app/countries/page.tsx and populate with the following.\nThis will select all the rows from the countries table in Supabase and render them on the page.\nStart the app\nRun the development server, go to http://localhost:3000/countries in a browser and you should see the list of countries.\nNext steps#\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "5",
    "url": "https://supabase.com/docs/guides/getting-started/quickstarts/redwoodjs",
    "title": "Use Supabase with RedwoodJS | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nUse Supabase with RedwoodJSLearn how to create a Supabase project, add some sample data to your database using Prisma migration and seeds, and query the data from a RedwoodJS app.[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\n1Setup your new Supabase ProjectCreate a new project in the Supabase Dashboard.Be sure to make note of the Database Password you used as you will need this later to connect to your database.2Gather Database Connection StringsGo to the database settings page. In this quickstart, we are going to connect via the connection pooler. If your network supports IPv6, you can connect to the database directly without using the connection pooler.We will use the pooler both in Transaction and Session mode. Transaction mode is used for application queries and Session mode is used for running migrations with Prisma.To do this, set the connection mode to Transaction in the database settings page and copy the connection string and append ?pgbouncer=true&&connection_limit=1. pgbouncer=true disables Prisma from generating prepared statements. This is required since our connection pooler does not support prepared statements in transaction mode yet. The connection_limit=1 parameter is only required if you are using Prisma from a serverless environment. This is the Transaction mode connection string.To get the Session mode connection pooler string, change the port of the connection string from the dashboard to 5432.You will need the Transaction mode connection string and the Session mode connection string to setup environment variables in Step 5.You can copy and paste these connection strings from the Supabase Dashboard when needed in later steps.3Create a RedwoodJS appCreate a RedwoodJS app with TypeScript.The yarn package manager is required to create a RedwoodJS app. You will use it to run RedwoodJS commands later.While TypeScript is recommended, If you want a JavaScript app, omit the --ts flag.Terminal_10yarn create redwood-app my-app --ts4Open your RedwoodJS app in VS CodeYou'll develop your app, manage database migrations, and run your app in VS Code.Terminal_10cd my-app_10code .5Configure Environment VariablesIn your .env file, add the following environment variables for your database connection:\n\nThe DATABASE_URL should use the Transaction mode connection string you copied in Step 1.\n\n\nThe DIRECT_URL should use the Session mode connection string you copied in Step 1.\n\n.env_10# Transaction mode connection string used for migrations_10DATABASE_URL=\"postgres://postgres.[project-ref]:[db-password]@xxx.pooler.supabase.com:6543/postgres?pgbouncer=true&connection_limit=1\"_10_10# Session mode connection string â€” used by Prisma Client_10DIRECT_URL=\"postgres://postgres.[project-ref]:[db-password]@xxx.pooler.supabase.com:5432/postgres\"6Update your Prisma SchemaBy default, RedwoodJS ships with a SQLite database, but we want to use PostgreSQL.Update your Prisma schema file api/db/schema.prisma to use your Supabase PostgreSQL database connection environment variables you setup in Step 5.api/prisma/schema.prisma_10datasource db {_10  provider  = \"postgresql\"_10  url       = env(\"DATABASE_URL\")_10  directUrl = env(\"DIRECT_URL\")_10}7Create the Country model and apply a schema migrationCreate the Country model in api/db/schema.prisma and then run yarn rw prisma migrate dev from your terminal to apply the migration.api/db/schema.prisma_10model Country {_10  id   Int    @id @default(autoincrement())_10  name String @unique_10}8Update seed scriptLet's seed the database with a few countries.Update the file scripts/seeds.ts to contain the following code:scripts/seed.ts_20import type { Prisma } from '@prisma/client'_20import { db } from 'api/src/lib/db'_20_20export default async () => {_20  try {_20    const data: Prisma.CountryCreateArgs['data'][] = [_20      { name: 'United States' },_20      { name: 'Canada' },_20      { name: 'Mexico' },_20    ]_20_20    console.log('Seeding countries ...')_20_20    const countries = await db.country.createMany({ data })_20_20    console.log('Done.', countries)_20  } catch (error) {_20    console.error(error)_20  }_20}9Seed your databaseRun the seed database command to populate the Country table with the countries you just created.The reset database command yarn rw prisma db reset will recreate the tables and will also run the seed script.Terminal_10yarn rw prisma db seed10Scaffold the Country UINow, we'll use RedwoodJS generators to scaffold a CRUD UI for the Country model.Terminal_10yarn rw g scaffold country11Start the appStart the app via yarn rw dev. A browser will open to the RedwoodJS Splash page.12View Countries UIClick on /countries to visit http://localhost:8910/countries where should see the list of countries.You may now edit, delete, and add new countries using the scaffolded UI.Edit this page on GitHub\nUse Supabase with RedwoodJS\nLearn how to create a Supabase project, add some sample data to your database using Prisma migration and seeds, and query the data from a RedwoodJS app.\nSetup your new Supabase Project\nCreate a new project in the Supabase Dashboard.\nBe sure to make note of the Database Password you used as you will need this later to connect to your database.\n\nGather Database Connection Strings\nGo to the database settings page. In this quickstart, we are going to connect via the connection pooler. If your network supports IPv6, you can connect to the database directly without using the connection pooler.\nWe will use the pooler both in Transaction and Session mode. Transaction mode is used for application queries and Session mode is used for running migrations with Prisma.\nTo do this, set the connection mode to Transaction in the database settings page and copy the connection string and append ?pgbouncer=true&&connection_limit=1. pgbouncer=true disables Prisma from generating prepared statements. This is required since our connection pooler does not support prepared statements in transaction mode yet. The connection_limit=1 parameter is only required if you are using Prisma from a serverless environment. This is the Transaction mode connection string.\nTo get the Session mode connection pooler string, change the port of the connection string from the dashboard to 5432.\nYou will need the Transaction mode connection string and the Session mode connection string to setup environment variables in Step 5.\nYou can copy and paste these connection strings from the Supabase Dashboard when needed in later steps.\n\nCreate a RedwoodJS app\nCreate a RedwoodJS app with TypeScript.\nThe yarn package manager is required to create a RedwoodJS app. You will use it to run RedwoodJS commands later.\nWhile TypeScript is recommended, If you want a JavaScript app, omit the --ts flag.\nOpen your RedwoodJS app in VS Code\nYou'll develop your app, manage database migrations, and run your app in VS Code.\nConfigure Environment Variables\nIn your .env file, add the following environment variables for your database connection:\nThe DATABASE_URL should use the Transaction mode connection string you copied in Step 1.\nThe DIRECT_URL should use the Session mode connection string you copied in Step 1.\nUpdate your Prisma Schema\nBy default, RedwoodJS ships with a SQLite database, but we want to use PostgreSQL.\nUpdate your Prisma schema file api/db/schema.prisma to use your Supabase PostgreSQL database connection environment variables you setup in Step 5.\nCreate the Country model and apply a schema migration\nCreate the Country model in api/db/schema.prisma and then run yarn rw prisma migrate dev from your terminal to apply the migration.\nUpdate seed script\nLet's seed the database with a few countries.\nUpdate the file scripts/seeds.ts to contain the following code:\nSeed your database\nRun the seed database command to populate the Country table with the countries you just created.\nThe reset database command yarn rw prisma db reset will recreate the tables and will also run the seed script.\nScaffold the Country UI\nNow, we'll use RedwoodJS generators to scaffold a CRUD UI for the Country model.\nStart the app\nStart the app via yarn rw dev. A browser will open to the RedwoodJS Splash page.\n\nView Countries UI\nClick on /countries to visit http://localhost:8910/countries where should see the list of countries.\nYou may now edit, delete, and add new countries using the scaffolded UI.\n\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "6",
    "url": "https://supabase.com/docs/guides/getting-started/quickstarts/flutter",
    "title": "Use Supabase with Flutter | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nUse Supabase with FlutterLearn how to create a Supabase project, add some sample data to your database, and query the data from a Flutter app.[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\n1[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nCreate a Supabase projectGo to database.new and create a new Supabase project.When your project is up and running, go to the Table Editor, create a new table and insert some data.Alternatively, you can run the following snippet in your project's SQL Editor. This will create a countries table with some sample data.\nSQL_EDITOR_13-- Create the table_13create table countries (_13  id bigint primary key generated always as identity,_13  name text not null_13);_13-- Insert some sample data into the table_13insert into countries (name)_13values_13  ('Canada'),_13  ('United States'),_13  ('Mexico');_13_13alter table countries enable row level security;\nMake the data in your table publicly readable by adding an RLS policy:\nSQL_EDITOR_10create policy \"public can read countries\"_10on public.countries_10for select to anon_10using (true);2Create a Flutter appCreate a Flutter app using the flutter create command. You can skip this step if you already have a working app.Terminal_10flutter create my_app3Install the Supabase client libraryThe fastest way to get started is to use the supabase_flutter client library which provides a convenient interface for working with Supabase from a Flutter app.Open the pubspec.yaml file inside your Flutter app and add supabase_flutter as a dependency.pubspec.yaml_10supabase_flutter: ^2.0.04Initialize the Supabase clientOpen lib/main.dart and edit the main function to initialize Supabase using your project URL and public API (anon) key:Project URLLoading...Anon keyLoading...lib/main.dart_11import 'package:supabase_flutter/supabase_flutter.dart';_11_11Future<void> main() async {_11  WidgetsFlutterBinding.ensureInitialized();_11_11  await Supabase.initialize(_11    url: 'YOUR_SUPABASE_URL',_11    anonKey: 'YOUR_SUPABASE_ANON_KEY',_11  );_11  runApp(MyApp());_11}5Query data from the appUse a FutureBuilder to fetch the data when the home page loads and display the query result in a ListView.Replace the default MyApp and MyHomePage classes with the following code.lib/main.dart_48class MyApp extends StatelessWidget {_48  const MyApp({super.key});_48_48  @override_48  Widget build(BuildContext context) {_48    return const MaterialApp(_48      title: 'Countries',_48      home: HomePage(),_48    );_48  }_48}_48_48class HomePage extends StatefulWidget {_48  const HomePage({super.key});_48_48  @override_48  State<HomePage> createState() => _HomePageState();_48}_48_48class _HomePageState extends State<HomePage> {_48  final _future = Supabase.instance.client_48      .from('countries')_48      .select();_48_48  @override_48  Widget build(BuildContext context) {_48    return Scaffold(_48      body: FutureBuilder(_48        future: _future,_48        builder: (context, snapshot) {_48          if (!snapshot.hasData) {_48            return const Center(child: CircularProgressIndicator());_48          }_48          final countries = snapshot.data!;_48          return ListView.builder(_48            itemCount: countries.length,_48            itemBuilder: ((context, index) {_48              final country = countries[index];_48              return ListTile(_48                title: Text(country['name']),_48              );_48            }),_48          );_48        },_48      ),_48    );_48  }_48}6Start the appRun your app on a platform of your choosing! By default an app should launch in your web browser.Note that supabase_flutter is compatible with web, iOS, Android, macOS, and Windows apps.\nRunning the app on MacOS requires additional configuration to set the entitlements.Terminal_10flutter run\nGoing to production#\nAndroid#\nIn production, your Android app needs explicit permission to use the internet connection on the user's device which is required to communicate with Supabase APIs.\nTo do this, add the following line to the android/app/src/main/AndroidManifest.xml file.\n_10<manifest xmlns:android=\"http://schemas.android.com/apk/res/android\">_10  <!-- Required to fetch data from the internet. -->_10  <uses-permission android:name=\"android.permission.INTERNET\" />_10  <!-- ... -->_10</manifest>Edit this page on GitHub\nUse Supabase with Flutter\nLearn how to create a Supabase project, add some sample data to your database, and query the data from a Flutter app.\nCreate a Supabase project\nGo to database.new and create a new Supabase project.\nWhen your project is up and running, go to the Table Editor, create a new table and insert some data.\nAlternatively, you can run the following snippet in your project's SQL Editor. This will create a countries table with some sample data.\n\nMake the data in your table publicly readable by adding an RLS policy:\nCreate a Flutter app\nCreate a Flutter app using the flutter create command. You can skip this step if you already have a working app.\nInstall the Supabase client library\nThe fastest way to get started is to use the supabase_flutter client library which provides a convenient interface for working with Supabase from a Flutter app.\nOpen the pubspec.yaml file inside your Flutter app and add supabase_flutter as a dependency.\nInitialize the Supabase client\nOpen lib/main.dart and edit the main function to initialize Supabase using your project URL and public API (anon) key:\nProject URL\nAnon key\nQuery data from the app\nUse a FutureBuilder to fetch the data when the home page loads and display the query result in a ListView.\nReplace the default MyApp and MyHomePage classes with the following code.\nStart the app\nRun your app on a platform of your choosing! By default an app should launch in your web browser.\nNote that supabase_flutter is compatible with web, iOS, Android, macOS, and Windows apps.\nRunning the app on MacOS requires additional configuration to set the entitlements.\nGoing to production#\nAndroid#\nIn production, your Android app needs explicit permission to use the internet connection on the user's device which is required to communicate with Supabase APIs.\nTo do this, add the following line to the android/app/src/main/AndroidManifest.xml file.\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "7",
    "url": "https://supabase.com/docs/guides/getting-started/quickstarts/kotlin",
    "title": "Use Supabase with Android Kotlin | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nUse Supabase with Android KotlinLearn how to create a Supabase project, add some sample data to your database, and query the data from an Android Kotlin app.[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\n1[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nCreate a Supabase projectGo to database.new and create a new Supabase project.When your project is up and running, go to the Table Editor, create a new table and insert some data.Alternatively, you can run the following snippet in your project's SQL Editor. This will create a countries table with some sample data.\nSQL_EDITOR_13-- Create the table_13create table countries (_13  id bigint primary key generated always as identity,_13  name text not null_13);_13-- Insert some sample data into the table_13insert into countries (name)_13values_13  ('Canada'),_13  ('United States'),_13  ('Mexico');_13_13alter table countries enable row level security;\nMake the data in your table publicly readable by adding an RLS policy:\nSQL_EDITOR_10create policy \"public can read countries\"_10on public.countries_10for select to anon_10using (true);2Create an Android app with Android StudioOpen Android Studio > New > New Android Project.3Install the DependenciesOpen build.gradle.kts (app) file and add the serialization plug, Ktor client, and Supabase client.Replace the version placeholders $kotlin_version with the Kotlin version of the project, and  $supabase_version and $ktor_version with the respective latest versions.The latest supabase-kt version can be found here and Ktor version can be found here._11plugins {_11  ..._11  kotlin(\"plugin.serialization\") version \"$kotlin_version\"_11}_11..._11dependencies {_11  ..._11  implementation(platform(\"io.github.jan-tennert.supabase:bom:$supabase_version\"))_11  implementation(\"io.github.jan-tennert.supabase:postgrest-kt\")_11  implementation(\"io.ktor:ktor-client-android:$ktor_version\")_11}4Add internet access permissionAdd the following line to the AndroidManifest.xml file under the manifest tag and outside the application tag._10..._10<uses-permission android:name=\"android.permission.INTERNET\" />_10...5Initialize the Supabase clientYou can create a Supabase client whenever you need to perform an API call.For the sake of simplicity, we will create a client in the MainActivity.kt file at the top just below the imports.Replace the supabaseUrl and supabaseKey with your own:Project URLLoading...Anon keyLoading..._10import ..._10_10val supabase = createSupabaseClient(_10    supabaseUrl = \"https://xyzcompany.supabase.co\",_10    supabaseKey = \"your_public_anon_key\"_10  ) {_10    install(Postgrest)_10}_10...6Create a data model for countriesCreate a serializable data class to represent the data from the database.Add the following below the createSupabaseClient function in the MainActivity.kt file._10@Serializable_10data class Country(_10    val id: Int,_10    val name: String,_10)7Query data from the appUse LaunchedEffect to fetch data from the database and display it in a LazyColumn.Replace the default MainActivity class with the following code.Note that we are making a network request from our UI code. In production, you should probably use a ViewModel to separate the UI and data fetching logic._38class MainActivity : ComponentActivity() {_38    override fun onCreate(savedInstanceState: Bundle?) {_38        super.onCreate(savedInstanceState)_38        setContent {_38            SupabaseTutorialTheme {_38                // A surface container using the 'background' color from the theme_38                Surface(_38                    modifier = Modifier.fillMaxSize(),_38                    color = MaterialTheme.colorScheme.background_38                ) {_38                    CountriesList()_38                }_38            }_38        }_38    }_38}_38_38@Composable_38fun CountriesList() {_38    var countries by remember { mutableStateOf<List<Country>>(listOf()) }_38    LaunchedEffect(Unit) {_38        withContext(Dispatchers.IO) {_38            countries = supabase.from(\"countries\")_38                              .select().decodeList<Country>()_38        }_38    }_38    LazyColumn {_38        items(_38            countries,_38            key = { country -> country.id },_38        ) { country ->_38            Text(_38                country.name,_38                modifier = Modifier.padding(8.dp),_38            )_38        }_38    }_38}8Start the appRun the app on an emulator or a physical device by clicking the Run app button in Android Studio.Edit this page on GitHub\nUse Supabase with Android Kotlin\nLearn how to create a Supabase project, add some sample data to your database, and query the data from an Android Kotlin app.\nCreate a Supabase project\nGo to database.new and create a new Supabase project.\nWhen your project is up and running, go to the Table Editor, create a new table and insert some data.\nAlternatively, you can run the following snippet in your project's SQL Editor. This will create a countries table with some sample data.\n\nMake the data in your table publicly readable by adding an RLS policy:\nCreate an Android app with Android Studio\nOpen Android Studio > New > New Android Project.\nInstall the Dependencies\nOpen build.gradle.kts (app) file and add the serialization plug, Ktor client, and Supabase client.\nReplace the version placeholders $kotlin_version with the Kotlin version of the project, and  $supabase_version and $ktor_version with the respective latest versions.\nThe latest supabase-kt version can be found here and Ktor version can be found here.\nAdd internet access permission\nAdd the following line to the AndroidManifest.xml file under the manifest tag and outside the application tag.\nInitialize the Supabase client\nYou can create a Supabase client whenever you need to perform an API call.\nFor the sake of simplicity, we will create a client in the MainActivity.kt file at the top just below the imports.\nReplace the supabaseUrl and supabaseKey with your own:\nProject URL\nAnon key\nCreate a data model for countries\nCreate a serializable data class to represent the data from the database.\nAdd the following below the createSupabaseClient function in the MainActivity.kt file.\nQuery data from the app\nUse LaunchedEffect to fetch data from the database and display it in a LazyColumn.\nReplace the default MainActivity class with the following code.\nNote that we are making a network request from our UI code. In production, you should probably use a ViewModel to separate the UI and data fetching logic.\nStart the app\nRun the app on an emulator or a physical device by clicking the Run app button in Android Studio.\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "8",
    "url": "https://supabase.com/docs/guides/getting-started/quickstarts/sveltekit",
    "title": "Use Supabase with SvelteKit | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nUse Supabase with SvelteKitLearn how to create a Supabase project, add some sample data to your database, and query the data from a SvelteKit app.[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\n1[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nCreate a Supabase projectGo to database.new and create a new Supabase project.When your project is up and running, go to the Table Editor, create a new table and insert some data.Alternatively, you can run the following snippet in your project's SQL Editor. This will create a countries table with some sample data.\nSQL_EDITOR_13-- Create the table_13create table countries (_13  id bigint primary key generated always as identity,_13  name text not null_13);_13-- Insert some sample data into the table_13insert into countries (name)_13values_13  ('Canada'),_13  ('United States'),_13  ('Mexico');_13_13alter table countries enable row level security;\nMake the data in your table publicly readable by adding an RLS policy:\nSQL_EDITOR_10create policy \"public can read countries\"_10on public.countries_10for select to anon_10using (true);2Create a SvelteKit appCreate a SvelteKit app using the npm create command.Terminal_10npx sv create my-app3Install the Supabase client libraryThe fastest way to get started is to use the supabase-js client library which provides a convenient interface for working with Supabase from a SvelteKit app.Navigate to the SvelteKit app and install supabase-js.Terminal_10cd my-app && npm install @supabase/supabase-js4Create the Supabase clientCreate a src/lib directory in your SvelteKit app, create a file called supabaseClient.js and add the following code to initialize the Supabase client with your project URL and public API (anon) key:Project URLLoading...Anon keyLoading...src/lib/supabaseClient.js_10  import { createClient } from '@supabase/supabase-js'_10_10  export const supabase = createClient('https://<project>.supabase.co', '<your-anon-key>')5Query data from the appUse load method to fetch the data server-side and display the query results as a simple list.Create +page.server.js file in the src/routes directory with the following code.src/routes/+page.server.js_10  import { supabase } from \"$lib/supabaseClient\";_10_10  export async function load() {_10    const { data } = await supabase.from(\"countries\").select();_10    return {_10      countries: data ?? [],_10    };_10  }Replace the existing content in your +page.svelte file in the src/routes directory with the following code.src/routes/+page.svelte_10  <script>_10    let { data } = $props();_10  </script>_10_10  <ul>_10    {#each data.countries as country}_10      <li>{country.name}</li>_10    {/each}_10  </ul>6Start the appStart the app and go to http://localhost:5173 in a browser and you should see the list of countries.Terminal_10npm run dev\nNext steps#\n\nSet up Auth for your app\nInsert more data into your database\nUpload and serve static files using Storage\nEdit this page on GitHub\nUse Supabase with SvelteKit\nLearn how to create a Supabase project, add some sample data to your database, and query the data from a SvelteKit app.\nCreate a Supabase project\nGo to database.new and create a new Supabase project.\nWhen your project is up and running, go to the Table Editor, create a new table and insert some data.\nAlternatively, you can run the following snippet in your project's SQL Editor. This will create a countries table with some sample data.\n\nMake the data in your table publicly readable by adding an RLS policy:\nCreate a SvelteKit app\nCreate a SvelteKit app using the npm create command.\nInstall the Supabase client library\nThe fastest way to get started is to use the supabase-js client library which provides a convenient interface for working with Supabase from a SvelteKit app.\nNavigate to the SvelteKit app and install supabase-js.\nCreate the Supabase client\nCreate a src/lib directory in your SvelteKit app, create a file called supabaseClient.js and add the following code to initialize the Supabase client with your project URL and public API (anon) key:\nProject URL\nAnon key\nQuery data from the app\nUse load method to fetch the data server-side and display the query results as a simple list.\nCreate +page.server.js file in the src/routes directory with the following code.\n\nReplace the existing content in your +page.svelte file in the src/routes directory with the following code.\nStart the app\nStart the app and go to http://localhost:5173 in a browser and you should see the list of countries.\nNext steps#\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "9",
    "url": "https://supabase.com/docs/guides/getting-started/quickstarts/solidjs",
    "title": "Use Supabase with SolidJS | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nUse Supabase with SolidJSLearn how to create a Supabase project, add some sample data to your database, and query the data from a SolidJS app.[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\n1[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nCreate a Supabase projectGo to database.new and create a new Supabase project.When your project is up and running, go to the Table Editor, create a new table and insert some data.Alternatively, you can run the following snippet in your project's SQL Editor. This will create a countries table with some sample data.\nSQL_EDITOR_13-- Create the table_13create table countries (_13  id bigint primary key generated always as identity,_13  name text not null_13);_13-- Insert some sample data into the table_13insert into countries (name)_13values_13  ('Canada'),_13  ('United States'),_13  ('Mexico');_13_13alter table countries enable row level security;\nMake the data in your table publicly readable by adding an RLS policy:\nSQL_EDITOR_10create policy \"public can read countries\"_10on public.countries_10for select to anon_10using (true);2Create a SolidJS appCreate a SolidJS app using the degit command.Terminal_10npx degit solidjs/templates/js my-app3Install the Supabase client libraryThe fastest way to get started is to use the supabase-js client library which provides a convenient interface for working with Supabase from a SolidJS app.Navigate to the SolidJS app and install supabase-js.Terminal_10cd my-app && npm install @supabase/supabase-js4Query data from the appIn App.jsx, create a Supabase client using your project URL and public API (anon) key:Project URLLoading...Anon keyLoading...Add a getCountries function to fetch the data and display the query result to the page.src/App.jsx_21  import { createClient } from \"@supabase/supabase-js\";_21  import { createResource, For } from \"solid-js\";_21_21  const supabase = createClient('https://<project>.supabase.co', '<your-anon-key>');_21_21  async function getCountries() {_21    const { data } = await supabase.from(\"countries\").select();_21    return data;_21  }_21_21  function App() {_21    const [countries] = createResource(getCountries);_21_21    return (_21      <ul>_21        <For each={countries()}>{(country) => <li>{country.name}</li>}</For>_21      </ul>_21    );_21  }_21_21  export default App;5Start the appStart the app and go to http://localhost:3000 in a browser and you should see the list of countries.Terminal_10npm run devEdit this page on GitHub\nUse Supabase with SolidJS\nLearn how to create a Supabase project, add some sample data to your database, and query the data from a SolidJS app.\nCreate a Supabase project\nGo to database.new and create a new Supabase project.\nWhen your project is up and running, go to the Table Editor, create a new table and insert some data.\nAlternatively, you can run the following snippet in your project's SQL Editor. This will create a countries table with some sample data.\n\nMake the data in your table publicly readable by adding an RLS policy:\nCreate a SolidJS app\nCreate a SolidJS app using the degit command.\nInstall the Supabase client library\nThe fastest way to get started is to use the supabase-js client library which provides a convenient interface for working with Supabase from a SolidJS app.\nNavigate to the SolidJS app and install supabase-js.\nQuery data from the app\nIn App.jsx, create a Supabase client using your project URL and public API (anon) key:\nProject URL\nAnon key\nAdd a getCountries function to fetch the data and display the query result to the page.\nStart the app\nStart the app and go to http://localhost:3000 in a browser and you should see the list of countries.\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "10",
    "url": "https://supabase.com/docs/guides/getting-started/quickstarts/vue",
    "title": "Use Supabase with Vue | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nUse Supabase with VueLearn how to create a Supabase project, add some sample data to your database, and query the data from a Vue app.[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\n1[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nCreate a Supabase projectGo to database.new and create a new Supabase project.When your project is up and running, go to the Table Editor, create a new table and insert some data.Alternatively, you can run the following snippet in your project's SQL Editor. This will create a countries table with some sample data.\nSQL_EDITOR_13-- Create the table_13create table countries (_13  id bigint primary key generated always as identity,_13  name text not null_13);_13-- Insert some sample data into the table_13insert into countries (name)_13values_13  ('Canada'),_13  ('United States'),_13  ('Mexico');_13_13alter table countries enable row level security;\nMake the data in your table publicly readable by adding an RLS policy:\nSQL_EDITOR_10create policy \"public can read countries\"_10on public.countries_10for select to anon_10using (true);2Create a Vue appCreate a Vue app using the npm init command.Terminal_10npm init vue@latest my-app3Install the Supabase client libraryThe fastest way to get started is to use the supabase-js client library which provides a convenient interface for working with Supabase from a Vue app.Navigate to the Vue app and install supabase-js.Terminal_10cd my-app && npm install @supabase/supabase-js4Create the Supabase clientCreate a /src/lib directory in your Vue app, create a file called supabaseClient.js and add the following code to initialize the Supabase client with your project URL and public API (anon) key:Project URLLoading...Anon keyLoading...src/lib/supabaseClient.js_10  import { createClient } from '@supabase/supabase-js'_10_10  export const supabase = createClient('https://<project>.supabase.co', '<your-anon-key>')5Query data from the appReplace the existing content in your App.vue file with the following code.src/App.vue_21  <script setup>_21  import { ref, onMounted } from 'vue'_21  import { supabase } from './lib/supabaseClient'_21_21  const countries = ref([])_21_21  async function getCountries() {_21    const { data } = await supabase.from('countries').select()_21    countries.value = data_21  }_21_21  onMounted(() => {_21    getCountries()_21  })_21  </script>_21_21  <template>_21    <ul>_21      <li v-for=\"country in countries\" :key=\"country.id\">{{ country.name }}</li>_21    </ul>_21  </template>6Start the appStart the app and go to http://localhost:5173 in a browser and you should see the list of countries.Terminal_10npm run devEdit this page on GitHub\nUse Supabase with Vue\nLearn how to create a Supabase project, add some sample data to your database, and query the data from a Vue app.\nCreate a Supabase project\nGo to database.new and create a new Supabase project.\nWhen your project is up and running, go to the Table Editor, create a new table and insert some data.\nAlternatively, you can run the following snippet in your project's SQL Editor. This will create a countries table with some sample data.\n\nMake the data in your table publicly readable by adding an RLS policy:\nCreate a Vue app\nCreate a Vue app using the npm init command.\nInstall the Supabase client library\nThe fastest way to get started is to use the supabase-js client library which provides a convenient interface for working with Supabase from a Vue app.\nNavigate to the Vue app and install supabase-js.\nCreate the Supabase client\nCreate a /src/lib directory in your Vue app, create a file called supabaseClient.js and add the following code to initialize the Supabase client with your project URL and public API (anon) key:\nProject URL\nAnon key\nQuery data from the app\nReplace the existing content in your App.vue file with the following code.\nStart the app\nStart the app and go to http://localhost:5173 in a browser and you should see the list of countries.\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "11",
    "url": "https://supabase.com/docs/guides/getting-started/quickstarts/nuxtjs",
    "title": "Use Supabase with NuxtJS | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nUse Supabase with NuxtJSLearn how to create a Supabase project, add some sample data to your database, and query the data from a NuxtJS app.[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\n1[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nCreate a Supabase projectGo to database.new and create a new Supabase project.When your project is up and running, go to the Table Editor, create a new table and insert some data.Alternatively, you can run the following snippet in your project's SQL Editor. This will create a countries table with some sample data.\nSQL_EDITOR_13-- Create the table_13create table countries (_13  id bigint primary key generated always as identity,_13  name text not null_13);_13-- Insert some sample data into the table_13insert into countries (name)_13values_13  ('Canada'),_13  ('United States'),_13  ('Mexico');_13_13alter table countries enable row level security;\nMake the data in your table publicly readable by adding an RLS policy:\nSQL_EDITOR_10create policy \"public can read countries\"_10on public.countries_10for select to anon_10using (true);2Create a NuxtJS appCreate a Nuxt.js app using the npx nuxi command.Terminal_10npx nuxi@latest init my-app3Install the Supabase client libraryThe fastest way to get started is to use the supabase-js client library which provides a convenient interface for working with Supabase from a NuxtJS app.Navigate to the NuxtJS app and install supabase-js.Terminal_10cd my-app && npm install @supabase/supabase-js4Query data from the appIn app.vue, create a Supabase client using your project URL and public API (anon) key:Project URLLoading...Anon keyLoading...Replace the existing content in your app.vue file with the following code.app.vue_20<script setup>_20import { createClient } from '@supabase/supabase-js'_20const supabase = createClient('https://<project>.supabase.co', '<your-anon-key>')_20const countries = ref([])_20_20async function getCountries() {_20  const { data } = await supabase.from('countries').select()_20  countries.value = data_20}_20_20onMounted(() => {_20  getCountries()_20})_20</script>_20_20<template>_20  <ul>_20    <li v-for=\"country in countries\" :key=\"country.id\">{{ country.name }}</li>_20  </ul>_20</template>5Start the appStart the app, navigate to http://localhost:3000 in the browser, open the browser console, and you should see the list of countries.Terminal_10npm run dev\nThe community-maintained @nuxtjs/supabase module provides an alternate DX for working with Supabase in Nuxt.Edit this page on GitHub\nUse Supabase with NuxtJS\nLearn how to create a Supabase project, add some sample data to your database, and query the data from a NuxtJS app.\nCreate a Supabase project\nGo to database.new and create a new Supabase project.\nWhen your project is up and running, go to the Table Editor, create a new table and insert some data.\nAlternatively, you can run the following snippet in your project's SQL Editor. This will create a countries table with some sample data.\n\nMake the data in your table publicly readable by adding an RLS policy:\nCreate a NuxtJS app\nCreate a Nuxt.js app using the npx nuxi command.\nInstall the Supabase client library\nThe fastest way to get started is to use the supabase-js client library which provides a convenient interface for working with Supabase from a NuxtJS app.\nNavigate to the NuxtJS app and install supabase-js.\nQuery data from the app\nIn app.vue, create a Supabase client using your project URL and public API (anon) key:\nProject URL\nAnon key\nReplace the existing content in your app.vue file with the following code.\nStart the app\nStart the app, navigate to http://localhost:3000 in the browser, open the browser console, and you should see the list of countries.\nThe community-maintained @nuxtjs/supabase module provides an alternate DX for working with Supabase in Nuxt.\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "12",
    "url": "https://supabase.com/docs/guides/getting-started/quickstarts/refine",
    "title": "Use Supabase with refine | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nUse Supabase with refineLearn how to create a Supabase project, add some sample data to your database, and query the data from a refine app.[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\n1[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nCreate a Supabase projectGo to database.new and create a new Supabase project.When your project is up and running, go to the Table Editor, create a new table and insert some data.Alternatively, you can run the following snippet in your project's SQL Editor. This will create a countries table with some sample data.\nSQL_EDITOR_13-- Create the table_13create table countries (_13  id bigint primary key generated always as identity,_13  name text not null_13);_13-- Insert some sample data into the table_13insert into countries (name)_13values_13  ('Canada'),_13  ('United States'),_13  ('Mexico');_13_13alter table countries enable row level security;\nMake the data in your table publicly readable by adding an RLS policy:\nSQL_EDITOR_10create policy \"public can read countries\"_10on public.countries_10for select to anon_10using (true);2Create a refine appCreate a refine app using the create refine-app.The refine-supabase preset adds @refinedev/supabase supplementary package that supports Supabase in a refine app. @refinedev/supabase out-of-the-box includes the Supabase dependency: supabase-js.Terminal_10npm create refine-app@latest -- --preset refine-supabase my-app3Open your refine app in VS CodeYou will develop your app, connect to the Supabase backend and run the refine app in VS Code.Terminal_10cd my-app_10code .4Start the appStart the app, go to http://localhost:5173 in a browser, and you should be greeted with the refine Welcome page.Terminal_10npm run dev5Update `supabaseClient`You now have to update the supabaseClient with the SUPABASE_URL and SUPABASE_KEY of your Supabase API. The supabaseClient is used in auth provider and data provider methods that allow the refine app to connect to your Supabase backend.Project URLLoading...Anon keyLoading...src/utility/supabaseClient.ts_13import { createClient } from \"@refinedev/supabase\";_13_13const SUPABASE_URL = YOUR_SUPABASE_URL;_13const SUPABASE_KEY = YOUR_SUPABASE_KEY_13_13export const supabaseClient = createClient(SUPABASE_URL, SUPABASE_KEY, {_13  db: {_13    schema: \"public\",_13  },_13  auth: {_13    persistSession: true,_13  },_13});6Add countries resource and pagesYou have to then configure resources and define pages for countries resource.Use the following command to automatically add resources and generate code for pages for countries using refine Inferencer.This defines pages for list, create, show and edit actions inside the src/pages/countries/ directory with <HeadlessInferencer /> component.The <HeadlessInferencer /> component depends on @refinedev/react-table and @refinedev/react-hook-form packages. In order to avoid errors, you should install them as dependencies with npm install @refinedev/react-table @refinedev/react-hook-form.The <HeadlessInferencer /> is a refine Inferencer component that automatically generates necessary code for the list, create, show and edit pages.More on how the Inferencer works is available in the docs here.Terminal_10npm run refine create-resource countries7Add routes for countries pagesAdd routes for the list, create, show, and edit pages.You should remove the index route for the Welcome page presented with the <Welcome /> component.src/App.tsx_56import { Refine, WelcomePage } from \"@refinedev/core\";_56import { RefineKbar, RefineKbarProvider } from \"@refinedev/kbar\";_56import routerBindings, {_56  DocumentTitleHandler,_56  NavigateToResource,_56  UnsavedChangesNotifier,_56} from \"@refinedev/react-router-v6\";_56import { dataProvider, liveProvider } from \"@refinedev/supabase\";_56import { BrowserRouter, Route, Routes } from \"react-router-dom\";_56_56import \"./App.css\";_56import authProvider from \"./authProvider\";_56import { supabaseClient } from \"./utility\";_56import { CountriesCreate, CountriesEdit, CountriesList, CountriesShow } from \"./pages/countries\";_56_56function App() {_56  return (_56    <BrowserRouter>_56      <RefineKbarProvider>_56        <Refine_56          dataProvider={dataProvider(supabaseClient)}_56          liveProvider={liveProvider(supabaseClient)}_56          authProvider={authProvider}_56          routerProvider={routerBindings}_56          options={{_56            syncWithLocation: true,_56            warnWhenUnsavedChanges: true,_56          }}_56          resources={[{_56            name: \"countries\",_56            list: \"/countries\",_56            create: \"/countries/create\",_56            edit: \"/countries/edit/:id\",_56            show: \"/countries/show/:id\"_56          }]}>_56          <Routes>_56            <Route index_56              element={<NavigateToResource resource=\"countries\" />}_56            />_56            <Route path=\"/countries\">_56              <Route index element={<CountriesList />} />_56              <Route path=\"create\" element={<CountriesCreate />} />_56              <Route path=\"edit/:id\" element={<CountriesEdit />} />_56              <Route path=\"show/:id\" element={<CountriesShow />} />_56            </Route>_56          </Routes>_56          <RefineKbar />_56          <UnsavedChangesNotifier />_56          <DocumentTitleHandler />_56        </Refine>_56      </RefineKbarProvider>_56    </BrowserRouter>_56  );_56}_56_56export default App;8View countries pagesNow you should be able to see the countries pages along the /countries routes. You may now edit and add new countries using the Inferencer generated UI.The Inferencer auto-generated code gives you a good starting point on which to keep building your list, create, show and edit pages. They can be obtained by clicking the Show the auto-generated code buttons in their respective pages.Edit this page on GitHub\nUse Supabase with refine\nLearn how to create a Supabase project, add some sample data to your database, and query the data from a refine app.\nCreate a Supabase project\nGo to database.new and create a new Supabase project.\nWhen your project is up and running, go to the Table Editor, create a new table and insert some data.\nAlternatively, you can run the following snippet in your project's SQL Editor. This will create a countries table with some sample data.\n\nMake the data in your table publicly readable by adding an RLS policy:\nCreate a refine app\nCreate a refine app using the create refine-app.\nThe refine-supabase preset adds @refinedev/supabase supplementary package that supports Supabase in a refine app. @refinedev/supabase out-of-the-box includes the Supabase dependency: supabase-js.\nOpen your refine app in VS Code\nYou will develop your app, connect to the Supabase backend and run the refine app in VS Code.\nStart the app\nStart the app, go to http://localhost:5173 in a browser, and you should be greeted with the refine Welcome page.\n\nUpdate `supabaseClient`\nYou now have to update the supabaseClient with the SUPABASE_URL and SUPABASE_KEY of your Supabase API. The supabaseClient is used in auth provider and data provider methods that allow the refine app to connect to your Supabase backend.\nProject URL\nAnon key\nAdd countries resource and pages\nYou have to then configure resources and define pages for countries resource.\nUse the following command to automatically add resources and generate code for pages for countries using refine Inferencer.\nThis defines pages for list, create, show and edit actions inside the src/pages/countries/ directory with <HeadlessInferencer /> component.\nThe <HeadlessInferencer /> component depends on @refinedev/react-table and @refinedev/react-hook-form packages. In order to avoid errors, you should install them as dependencies with npm install @refinedev/react-table @refinedev/react-hook-form.\nThe <HeadlessInferencer /> is a refine Inferencer component that automatically generates necessary code for the list, create, show and edit pages.\nMore on how the Inferencer works is available in the docs here.\nAdd routes for countries pages\nAdd routes for the list, create, show, and edit pages.\nYou should remove the index route for the Welcome page presented with the <Welcome /> component.\nView countries pages\nNow you should be able to see the countries pages along the /countries routes. You may now edit and add new countries using the Inferencer generated UI.\nThe Inferencer auto-generated code gives you a good starting point on which to keep building your list, create, show and edit pages. They can be obtained by clicking the Show the auto-generated code buttons in their respective pages.\n\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "13",
    "url": "https://supabase.com/docs/guides/database/overview",
    "title": "Database | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nDatabaseEvery Supabase project comes with a full Postgres database, a free and open source database which is considered one of the world's most stable and advanced databases.\nFeatures#\nTable view#\nYou don't have to be a database expert to start using Supabase. Our table view makes Postgres as easy to use as a spreadsheet.\n\nRelationships#\nDig into the relationships within your data.\n\nClone tables#\nYou can duplicate your tables, just like you would inside a spreadsheet.\n\nThe SQL editor#\nSupabase comes with a SQL Editor. You can also save your favorite queries to run later!\n\nAdditional features#\n\nSupabase extends Postgres with realtime functionality using our Realtime Server.\nEvery project is a full Postgres database, with postgres level access.\nSupabase manages your database backups.\nImport data directly from a CSV or excel spreadsheet.\n\nDatabase backups do not include objects stored via the Storage API, as the database only includes metadata about these objects. Restoring an old backup does not restore objects that have been deleted since then.\nExtensions#\nTo expand the functionality of your Postgres database, you can use extensions.\nYou can enable Postgres extensions with the click of a button within the Supabase dashboard.\n\nLearn more about all the extensions provided on Supabase.\nTerminology#\nPostgres or PostgreSQL?#\nPostgreSQL the database was derived from the POSTGRES Project, a package written at the University of California at Berkeley in 1986.\nThis package included a query language called \"PostQUEL\".\nIn 1994, Postgres95 was built on top of POSTGRES code, adding an SQL language interpreter as a replacement for PostQUEL.\nEventually, Postgres95 was renamed to PostgreSQL to reflect the SQL query capability.\nAfter this, many people referred to it as Postgres since it's less prone to confusion. Supabase is all about simplicity, so we also refer to it as Postgres.\nTips#\nRead about resetting your database password here and changing the timezone of your server here.\nNext steps#\n\nRead more about Postgres\nSign in: supabase.com/dashboard\nEdit this page on GitHub\nDatabase\nEvery Supabase project comes with a full Postgres database, a free and open source database which is considered one of the world's most stable and advanced databases.\nFeatures#\nTable view#\nYou don't have to be a database expert to start using Supabase. Our table view makes Postgres as easy to use as a spreadsheet.\n\nRelationships#\nDig into the relationships within your data.\nClone tables#\nYou can duplicate your tables, just like you would inside a spreadsheet.\nThe SQL editor#\nSupabase comes with a SQL Editor. You can also save your favorite queries to run later!\nAdditional features#\nDatabase backups do not include objects stored via the Storage API, as the database only includes metadata about these objects. Restoring an old backup does not restore objects that have been deleted since then.\nExtensions#\nTo expand the functionality of your Postgres database, you can use extensions.\nYou can enable Postgres extensions with the click of a button within the Supabase dashboard.\nLearn more about all the extensions provided on Supabase.\nTerminology#\nPostgres or PostgreSQL?#\nPostgreSQL the database was derived from the POSTGRES Project, a package written at the University of California at Berkeley in 1986.\nThis package included a query language called \"PostQUEL\".\nIn 1994, Postgres95 was built on top of POSTGRES code, adding an SQL language interpreter as a replacement for PostQUEL.\nEventually, Postgres95 was renamed to PostgreSQL to reflect the SQL query capability.\nAfter this, many people referred to it as Postgres since it's less prone to confusion. Supabase is all about simplicity, so we also refer to it as Postgres.\nTips#\nRead about resetting your database password here and changing the timezone of your server here.\nNext steps#\nIs this helpful? Yes  No Thanks for your feedback!\nIs this helpful?\nNeed some help?\nLatest product updates?\nSomething's not right?\nWe use first-party cookies to improve our services. Learn more Learn moreâ€¢Privacy settings Accept  Opt out Privacy settings\nWe use first-party cookies to improve our services. Learn more"
  },
  {
    "id": "14",
    "url": "https://supabase.com/docs/guides/auth",
    "title": "Auth | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nAuthUse Supabase to authenticate and authorize your users.Supabase Auth makes it easy to implement authentication and authorization in your app. We provide client SDKs and API endpoints to help you create and manage users.\nYour users can use many popular Auth methods, including password, magic link, one-time password (OTP), social login, and single sign-on (SSO).\nAbout authentication and authorization#\nAuthentication and authorization are the core responsibilities of any Auth system.\n\nAuthentication means checking that a user is who they say they are.\nAuthorization means checking what resources a user is allowed to access.\n\nSupabase Auth uses JSON Web Tokens (JWTs) for authentication. Auth integrates with Supabase's database features, making it easy to use Row Level Security (RLS) for authorization.\nThe Supabase ecosystem#\nYou can use Supabase Auth as a standalone product, but it's also built to integrate with the Supabase ecosystem.\nAuth uses your project's Postgres database under the hood, storing user data and other Auth information in a special schema. You can connect this data to your own tables using triggers and foreign key references.\nAuth also enables access control to your database's automatically generated REST API. When using Supabase SDKs, your data requests are automatically sent with the user's Auth Token. The Auth Token scopes database access on a row-by-row level when used along with RLS policies.\nProviders#\nSupabase Auth works with many popular Auth methods, including Social and Phone Auth using third-party providers. See the following sections for a list of supported third-party providers.\nSocial Auth#\nAppleAzure (Microsoft)BitbucketDiscordFacebookFigmaGitHubGitLabGoogleKakaoKeycloakLinkedInNotionSlackSpotifyTwitterTwitchWorkOSZoom\nPhone Auth#\nMessageBirdTwilioVonageEdit this page on GitHub\nAuth\nUse Supabase to authenticate and authorize your users.\nSupabase Auth makes it easy to implement authentication and authorization in your app. We provide client SDKs and API endpoints to help you create and manage users.\nYour users can use many popular Auth methods, including password, magic link, one-time password (OTP), social login, and single sign-on (SSO).\nAbout authentication and authorization#\nAuthentication and authorization are the core responsibilities of any Auth system.\nSupabase Auth uses JSON Web Tokens (JWTs) for authentication. Auth integrates with Supabase's database features, making it easy to use Row Level Security (RLS) for authorization.\nThe Supabase ecosystem#\nYou can use Supabase Auth as a standalone product, but it's also built to integrate with the Supabase ecosystem.\nAuth uses your project's Postgres database under the hood, storing user data and other Auth information in a special schema. You can connect this data to your own tables using triggers and foreign key references.\nAuth also enables access control to your database's automatically generated REST API. When using Supabase SDKs, your data requests are automatically sent with the user's Auth Token. The Auth Token scopes database access on a row-by-row level when used along with RLS policies.\nProviders#\nSupabase Auth works with many popular Auth methods, including Social and Phone Auth using third-party providers. See the following sections for a list of supported third-party providers.\nSocial Auth#\nApple\nAzure (Microsoft)\nBitbucket\nDiscord\nFacebook\nFigma\nGitHub\nGitLab\nGoogle\nKakao\nKeycloak\nLinkedIn\nNotion\nSlack\nSpotify\nTwitter\nTwitch\nWorkOS\nZoom\nPhone Auth#\nMessageBird\nTwilio\nVonage\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "15",
    "url": "https://supabase.com/docs/guides/storage",
    "title": "Storage | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nStorageUse Supabase to store and serve files.Supabase Storage makes it simple to upload and serve files of any size, providing a robust framework for file access controls.\nFeatures#\nYou can use Supabase Storage to store images, videos, documents, and any other file type. Serve your assets with a global CDN to reduce latency from over 285 cities globally. Supabase Storage includes a built-in image optimizer, so you can resize and compress your media files on the fly.\nExamples#\nCheck out all of the Storage templates and examples in our GitHub repository.\nResumable Uploads with UppyUse Uppy to upload files to Supabase Storage using the TUS protocol (resumable uploads).\n\nResources#\nFind the source code and documentation in the Supabase GitHub repository.\nSupabase Storage APIView the source code.OpenAPI SpecSee the Swagger Documentation for Supabase Storage.Edit this page on GitHub\nStorage\nUse Supabase to store and serve files.\nSupabase Storage makes it simple to upload and serve files of any size, providing a robust framework for file access controls.\nFeatures#\nYou can use Supabase Storage to store images, videos, documents, and any other file type. Serve your assets with a global CDN to reduce latency from over 285 cities globally. Supabase Storage includes a built-in image optimizer, so you can resize and compress your media files on the fly.\nExamples#\nCheck out all of the Storage templates and examples in our GitHub repository.\nResumable Uploads with Uppy\nResources#\nFind the source code and documentation in the Supabase GitHub repository.\nSupabase Storage API\nOpenAPI Spec\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "16",
    "url": "https://supabase.com/docs/guides/ai",
    "title": "AI & Vectors | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nAI & VectorsThe best vector database is the database you already have.Supabase provides an open source toolkit for developing AI applications using Postgres and pgvector. Use the Supabase client libraries to store, index, and query your vector embeddings at scale.\nThe toolkit includes:\n\nA vector store and embeddings support using Postgres and pgvector.\nA Python client for managing unstructured embeddings.\nAn embedding generation process using open source models directly in Edge Functions.\nDatabase migrations for managing structured embeddings.\nIntegrations with all popular AI providers, such as OpenAI, Hugging Face, LangChain, and more.\n\nSearch#\nYou can use Supabase to build different types of search features for your app, including:\n\nSemantic search: search by meaning rather than exact keywords\nKeyword search: search by words or phrases\nHybrid search: combine semantic search with keyword search\n\nExamples#\nCheck out all of the AI templates and examples in our GitHub repository.\n\nHeadless Vector SearchA toolkit to perform vector similarity search on your knowledge base embeddings.Image Search with OpenAI CLIPImplement image search with the OpenAI CLIP Model and Supabase Vector.Hugging Face inferenceGenerate image captions using Hugging Face.OpenAI completionsGenerate GPT text completions using OpenAI in Edge Functions.Building ChatGPT PluginsUse Supabase as a Retrieval Store for your ChatGPT plugin.Vector search with Next.js and OpenAILearn how to build a ChatGPT-style doc search powered by Next.js, OpenAI, and Supabase.\n\n\nIntegrations#\n\nOpenAIOpenAI is an AI research and deployment company. Supabase provides a simple way to use OpenAI in your applications.Amazon BedrockA fully managed service that offers a choice of high-performing foundation models from leading AI companies.Hugging FaceHugging Face is an open-source provider of NLP technologies. Supabase provides a simple way to use Hugging Face's models in your applications.LangChainLangChain is a language-agnostic, open-source, and self-hosted API for text translation, summarization, and sentiment analysis.LlamaIndexLlamaIndex is a data framework for your LLM applications.\n\n\nCase studies#\n\nBerri AI Boosts Productivity by Migrating from AWS RDS to Supabase with pgvectorLearn how Berri AI overcame challenges with self-hosting their vector database on AWS RDS and successfully migrated to Supabase.Mendable switches from Pinecone to Supabase for PostgreSQL vector embeddingsHow Mendable boosts efficiency and accuracy of chat powered search for documentation using Supabase with pgvectorMarkprompt: GDPR-Compliant AI Chatbots for Docs and WebsitesAI-powered chatbot platform, Markprompt, empowers developers to deliver efficient and GDPR-compliant prompt experiences on top of their content, by leveraging Supabase's secure and privacy-focused database and authentication solutions\nEdit this page on GitHub\nAI & Vectors\nThe best vector database is the database you already have.\nSupabase provides an open source toolkit for developing AI applications using Postgres and pgvector. Use the Supabase client libraries to store, index, and query your vector embeddings at scale.\nThe toolkit includes:\nSearch#\nYou can use Supabase to build different types of search features for your app, including:\nExamples#\nCheck out all of the AI templates and examples in our GitHub repository.\nHeadless Vector Search\nImage Search with OpenAI CLIP\nHugging Face inference\nOpenAI completions\nBuilding ChatGPT Plugins\nVector search with Next.js and OpenAI\nIntegrations#\nOpenAI\nAmazon Bedrock\nHugging Face\nLangChain\nLlamaIndex\nCase studies#\nBerri AI Boosts Productivity by Migrating from AWS RDS to Supabase with pgvector\nMendable switches from Pinecone to Supabase for PostgreSQL vector embeddings\nMarkprompt: GDPR-Compliant AI Chatbots for Docs and Websites\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "17",
    "url": "https://supabase.com/docs/guides/realtime",
    "title": "Realtime | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nRealtimeSend and receive messages to connected clients.[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nSupabase provides a globally distributed cluster of Realtime servers that enable the following functionality:\n\nBroadcast: Send ephemeral messages from client to clients with low latency.\nPresence: Track and synchronize shared state between clients.\nPostgres Changes: Listen to Postgres database changes and send them to authorized clients.\n\nRealtime API#\nBy default Realtime is disabled on your database. Let's turn on Realtime for a todos table.\nDashboardSQL\nGo to the Database page in the Dashboard.\nClick on Publications in the sidebar.\nControl which database events are sent by toggling Insert, Update, and Delete.\nControl which tables broadcast changes by selecting Source and toggling each table.\n\nFrom the client, we can listen to any new data that is inserted into the todos table:\nJavaScriptDartSwift1// Initialize the JS client2import { createClient } from '@supabase/supabase-js'3const supabase = createClient(SUPABASE_URL, SUPABASE_ANON_KEY)45// Create a function to handle inserts6const handleInserts = (payload) => {7  console.log('Change received!', payload)8}910// Listen to inserts11supabase12  .channel('todos')13  .on('postgres_changes', { event: 'INSERT', schema: 'public', table: 'todos' }, handleInserts)14  .subscribe()\nUse subscribe() to listen to database changes.\nThe Realtime API works through PostgreSQL's replication functionality. Postgres sends database changes to a publication\ncalled supabase_realtime, and by managing this publication you can control which data is broadcast.\nExamples#\nMultiplayer.devMouse movements and chat messages.\nResources#\nFind the source code and documentation in the Supabase GitHub repository.\nSupabase RealtimeView the source code.Realtime: Multiplayer EditionRead more about Supabase Realtime.Edit this page on GitHub\nRealtime\nSend and receive messages to connected clients.\nSupabase provides a globally distributed cluster of Realtime servers that enable the following functionality:\nRealtime API#\nBy default Realtime is disabled on your database. Let's turn on Realtime for a todos table.\nFrom the client, we can listen to any new data that is inserted into the todos table:\nUse subscribe() to listen to database changes.\nThe Realtime API works through PostgreSQL's replication functionality. Postgres sends database changes to a publication\ncalled supabase_realtime, and by managing this publication you can control which data is broadcast.\nExamples#\nMultiplayer.dev\nResources#\nFind the source code and documentation in the Supabase GitHub repository.\nSupabase Realtime\nRealtime: Multiplayer Edition\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "18",
    "url": "https://supabase.com/docs/guides/functions",
    "title": "Edge Functions | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nEdge FunctionsGlobally distributed TypeScript functions.Edge Functions are server-side TypeScript functions, distributed globally at the edgeâ€”close to your users. They can be used for listening to webhooks or integrating your Supabase project with third-parties like Stripe. Edge Functions are developed using Deno, which offers a few benefits to you as a developer:\n\nIt is open source.\nIt is portable. Supabase Edge Functions run locally, and on any other Deno-compatible platform (including self-hosted infrastructure).\nIt is TypeScript first and supports WASM.\nEdge Functions are globally distributed for low-latency.\n\nGet started\nExamples#\nCheck out the Edge Function Examples in our GitHub repository.\nWith supabase-jsUse the Supabase client inside your Edge Function.Type-Safe SQL with KyselyCombining Kysely with Deno Postgres gives you a convenient developer experience for interacting directly with your Postgres database.Monitoring with SentryMonitor Edge Functions with the Sentry Deno SDK.With CORS headersSend CORS headers for invoking from the browser.React Native with StripeFull example for using Supabase and Stripe, with Expo.Flutter with StripeFull example for using Supabase and Stripe, with Flutter.Building a RESTful Service APILearn how to use HTTP methods and paths to build a RESTful service for managing tasks.Working with Supabase StorageAn example on reading a file from Supabase Storage.Open Graph Image GenerationGenerate Open Graph images with Deno and Supabase Edge Functions.OG Image Generation & Storage CDN CachingCache generated images with Supabase Storage CDN.Get User LocationGet user location data from user's IP address.Cloudflare TurnstileProtecting Forms with Cloudflare Turnstile.Connect to PostgresConnecting to Postgres from Edge Functions.Github ActionsDeploying Edge Functions with GitHub Actions.Oak Server MiddlewareRequest Routing with Oak server middleware.Hugging FaceAccess 100,000+ Machine Learning models.Amazon BedrockAmazon Bedrock Image GeneratorOpenAIUsing OpenAI in Edge Functions.Stripe WebhooksHandling signed Stripe Webhooks with Edge Functions.Send emailsSend emails in Edge Functions with Resend.Web StreamServer-Sent Events in Edge Functions.PuppeteerGenerate screenshots with Puppeteer.Discord BotBuilding a Slash Command Discord Bot with Edge Functions.Telegram BotBuilding a Telegram Bot with Edge Functions.Upload FileProcess multipart/form-data.Upstash RedisBuild an Edge Functions Counter with Upstash Redis.Rate LimitingRate Limiting Edge Functions with Upstash Redis.Slack Bot Mention Edge FunctionSlack Bot handling Slack mentions in Edge FunctionEdit this page on GitHub\nEdge Functions\nGlobally distributed TypeScript functions.\nEdge Functions are server-side TypeScript functions, distributed globally at the edgeâ€”close to your users. They can be used for listening to webhooks or integrating your Supabase project with third-parties like Stripe. Edge Functions are developed using Deno, which offers a few benefits to you as a developer:\nExamples#\nCheck out the Edge Function Examples in our GitHub repository.\nWith supabase-js\nType-Safe SQL with Kysely\nMonitoring with Sentry\nWith CORS headers\nReact Native with Stripe\nFlutter with Stripe\nBuilding a RESTful Service API\nWorking with Supabase Storage\nOpen Graph Image Generation\nOG Image Generation & Storage CDN Caching\nGet User Location\nCloudflare Turnstile\nConnect to Postgres\nGithub Actions\nOak Server Middleware\nHugging Face\nAmazon Bedrock\nOpenAI\nStripe Webhooks\nSend emails\nWeb Stream\nPuppeteer\nDiscord Bot\nTelegram Bot\nUpload File\nUpstash Redis\nRate Limiting\nSlack Bot Mention Edge Function\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "19",
    "url": "https://supabase.com/docs/reference/javascript/introduction",
    "title": "JavaScript: Introduction | Supabase Docs",
    "content": "JavaScript: Introduction\nThis reference documents every object and method available in Supabase's isomorphic JavaScript library, supabase-js. You can use supabase-js to interact with your Postgres database, listen to database changes, invoke Deno Edge Functions, build login and user management functionality, and manage large files."
  },
  {
    "id": "20",
    "url": "https://supabase.com/docs/reference/dart/introduction",
    "title": "Flutter: Introduction | Supabase Docs",
    "content": "Flutter: Introduction\nThis reference documents every object and method available in Supabase's Flutter library, supabase-flutter. You can use supabase-flutter to interact with your Postgres database, listen to database changes, invoke Deno Edge Functions, build login and user management functionality, and manage large files.\nWe also provide a supabase package for non-Flutter projects."
  },
  {
    "id": "21",
    "url": "https://supabase.com/docs/reference/python/introduction",
    "title": "Python: Introduction | Supabase Docs",
    "content": "Python: Introduction\nThis reference documents every object and method available in Supabase's Python library, supabase-py. You can use supabase-py to interact with your Postgres database, listen to database changes, invoke Deno Edge Functions, build login and user management functionality, and manage large files."
  },
  {
    "id": "22",
    "url": "https://supabase.com/docs/reference/csharp/introduction",
    "title": "C#: Introduction | Supabase Docs",
    "content": "C#: Introduction\nThis reference documents every object and method available in Supabase's C# library, supabase. You can use Supabase to interact with your Postgres database, listen to database changes, invoke Deno Edge Functions, build login and user management functionality, and manage large files.\nThe C# client library is created and maintained by the Supabase community, and is not an official library. Please be tolerant of areas where the library is still being developed, and â€” as with all the libraries â€” feel free to contribute wherever you find issues.\nHuge thanks to official maintainer, Joseph Schultz. As well as Will Iverson, Ben Randall, and Rhuan Barros for their help."
  },
  {
    "id": "23",
    "url": "https://supabase.com/docs/reference/swift/introduction",
    "title": "Swift: Introduction | Supabase Docs",
    "content": "Swift: Introduction\nThis reference documents every object and method available in Supabase's Swift library, supabase-swift. You can use supabase-swift to interact with your Postgres database, listen to database changes, invoke Deno Edge Functions, build login and user management functionality, and manage large files."
  },
  {
    "id": "24",
    "url": "https://supabase.com/docs/reference/kotlin/introduction",
    "title": "Kotlin: Introduction | Supabase Docs",
    "content": "Kotlin: Introduction\nThis reference documents every object and method available in Supabase's Kotlin Multiplatform library,Â supabase-kt. You can useÂ supabase-kt to interact with your Postgres database, listen to database changes, invoke Deno Edge Functions, build login and user management functionality, and manage large files.\nTo see supported Kotlin targets, check the corresponding module README on GitHub.\nTo migrate from version 2.X to 3.0.0, see the migration guide\nThe Kotlin client library is created and maintained by the Supabase community, and is not an official library. Please be tolerant of areas where the library is still being developed, and â€” as with all the libraries â€” feel free to contribute wherever you find issues.\nHuge thanks to official maintainer, jan-tennert."
  },
  {
    "id": "25",
    "url": "https://supabase.com/docs/guides/resources",
    "title": "Resources | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nResources\nExamplesOfficial GitHub examples, curated content from the community, and more.GlossaryDefinitions for terminology and acronyms used in the Supabase documentation.Migrate to Supabase#Auth0Move your auth users from Auth0 to a Supabase project.Learn moreFirebase AuthMove your auth users from a Firebase project to a Supabase project.Learn moreFirestore DataMigrate the contents of a Firestore collection to a single PostgreSQL table.Learn moreFirebase StorageConvert your Firebase Storage files to Supabase Storage.Learn moreHerokuMigrate your Heroku Postgres database to Supabase.Learn moreRenderMigrate your Render Postgres database to Supabase.Learn moreAmazon RDSMigrate your Amazon RDS database to Supabase.Learn morePostgresMigrate your Postgres database to Supabase.Learn moreMySQLMigrate your MySQL database to Supabase.Learn moreMicrosoft SQL ServerMigrate your Microsoft SQL Server database to Supabase.Learn morePostgres resources#Managing IndexesImprove query performance using various index types in Postgres.Cascade DeletesUnderstand the types of foreign key constraint deletes.Drop all tables in schemaDelete all tables in a given schema.Select first row per groupRetrieve the first row in each distinct group.Print PostgreSQL versionFind out which version of Postgres you are running.Edit this page on GitHub\nResources\nExamples\nGlossary\nMigrate to Supabase#\nAuth0\nFirebase Auth\nFirestore Data\nFirebase Storage\nHeroku\nRender\nAmazon RDS\nPostgres\nMySQL\nMicrosoft SQL Server\nPostgres resources#\nManaging Indexes\nCascade Deletes\nDrop all tables in schema\nSelect first row per group\nPrint PostgreSQL version\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "26",
    "url": "https://supabase.com/docs/guides/platform/migrating-to-supabase/auth0",
    "title": "Migrate from Auth0 to Supabase Auth | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nMigrate from Auth0 to Supabase AuthLearn how to migrate your users from Auth0[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nYou can migrate your users from Auth0 to Supabase Auth.\nChanging authentication providers for a production app is an important operation. It can affect most aspects of your application. Prepare in advance by reading this guide, and develop a plan for handling the key migration steps and possible problems.\nWith advance planning, a smooth and safe Auth migration is possible.\nBefore you begin#\nBefore beginning, consider the answers to the following questions. They will help you need decide if you need to migrate, and which strategy to use:\n\nHow do Auth provider costs scale as your user base grows?\nDoes the new Auth provider provide all needed features? (for example, OAuth, password logins, Security Assertion Markup Language (SAML), Multi-Factor Authentication (MFA))\nIs downtime acceptable during the migration?\nWhat is your timeline to migrate before terminating the old Auth provider?\n\nMigration strategies#\nDepending on your evaluation, you may choose to go with one of the following strategies:\n\nRolling migration\nOne-off migration\n\nStrategyAdvantagesDisadvantagesRolling0 downtimeUsers may need to log in againNeed to maintain 2 different Auth services, which may be more costly in the short-termNeed to maintain separate codepaths for the period of the migrationSome existing users may be inactive and have not signed in with the new provider. This means that you eventually need to backfill these users. However, this is a much smaller-scale one-off migration with lower risks since these users are inactive.One-offNo need to maintain 2 different auth services for an extended period of timeSome downtimeUsers will need to log in again. Risky for active users.\nMigration steps#\nAuth provider migrations require 2 main steps:\n\nExport your user data from the old provider (Auth0)\nImport the data into your new provider (Supabase Auth)\n\nStep 1: Export your user data#\nAuth0 provides two methods for exporting user data:\n\nUse the Auth0 data export feature\nUse the Auth0 management API. This endpoint has a rate limit, so you may need to export your users in several batches.\n\nTo export password hashes and MFA factors, contact Auth0 support.\nStep 2: Import your users into Supabase Auth#\nThe steps for importing your users depends on the login methods that you support.\nSee the following sections for how to import users with:\n\nPassword-based login\nPasswordless login\nOAuth\n\nPassword-based methods#\nFor users who sign in with passwords, we recommend a hybrid approach to reduce downtime:\n\nFor new users, use Supabase Auth for sign up.\nMigrate existing users in a one-off migration.\n\nSign up new users\nSign up new users using Supabase Auth's signin methods.\nMigrate existing users to Supabase Auth\nMigrate existing users to Supabase Auth. This requires two main steps: first, check which users need to be migrated, then create their accounts using the Supabase admin endpoints.\n\n\nGet your Auth 0 user export and password hash export lists.\n\n\nFilter for users who use password login.\n\nUnder the identities field in the user object, these users will have auth0 as a provider. In the same identity object, you can find their Auth0 user_id.\nCheck that the user has a corresponding password hash by comapring their Auth0 user_id to the oid field in the password hash export.\n\n\n\nUse Supabase Auth's admin create user method to recreate the user in Supabase Auth. If the user has a confirmed email address or phone number, set email_confirm or phone_confirm to true.\n_10const { data, error } = await supabase.auth.admin.createUser({_10  email: 'foo@example.com',_10  password_hash: '$2y$10$a9pghn27d7m0ltXvlX8LiOowy7XfFw0hW0G80OjKYQ1jaoejaA7NC',_10  email_confirm: true,_10})\nSupported password hashing algorithmsSupabase supports BCrypt and Argon2 password hashes.\nIf you have a plaintext password instead of a hash, you can provide that instead. Supabase Auth will handle hashing the password for you. (Passwords are always stored hashed.)\n_10const { data, error } = await supabase.auth.admin.createUser({_10  email: 'foo@example.com',_10  password: 'supersecurepassword123!',_10})\n\n\nTo sign in your migrated users, use the Supabase Auth sign in methods.\nTo check for edge cases where users aren't successfully migrated, use a fallback strategy. This ensures that users can continue to sign in seamlessly:\n\nTry to sign in the user with Supabase Auth.\nIf the signin fails, try to sign in with Auth0.\nIf Auth0 signin succeeds, call the admin create user method again to create the user in Supabase Auth.\n\n\n\nPasswordless methods#\nFor passwordless signin via email or phone, check for users with verified email addresses or phone numbers. Create these users in Supabase Auth with email_confirm or phone_confirm set to true:\n_10const { data, error } = await supabase.auth.admin.createUser({_10  email: 'foo@example.com',_10  email_confirm: true,_10})\nCheck your Supabase Auth email configuration and configure your email template for use with magic links. See the Email templates guide to learn more.\nOnce you have imported your users, you can sign them in using the signInWithOtp method.\nOAuth#\nConfigure your OAuth providers in Supabase by following the Social login guides.\nFor both new and existing users, sign in the user using the signInWithOAuth method. This works without pre-migrating existing users, since the user always needs to sign in through the OAuth provider before being redirected to your service.\nAfter the user has completed the OAuth flow successfully, you can check if the user is a new or existing user in Auth0 by mapping their social provider id to Auth0. Auth0 stores the social provider ID in the user ID, which has the format provider_name|provider_id (for example, github|123456). See the Auth0 identity docs to learn more.\nMapping between Auth0 and Supabase Auth#\nEach Auth provider has its own schema for tracking users and user information.\nIn Supabase Auth, your users are stored in your project's database under the auth schema. Every user has an identity (unless the user is an anonymous user), which represents the signin method they can use with Supabase. This is represented by the auth.users and auth.identities table.\nSee the Users and Identities sections to learn more.\nMapping user metadata and custom claims#\nSupabase Auth provides 2 fields which you can use to map user-specific metadata from Auth0:\n\nauth.users.raw_user_meta_data : For storing non-sensitive user metadata that the user can update (e.g full name, age, favorite color).\nauth.users.raw_app_meta_data : For storing non-sensitive user metadata that the user should not be able to update (e.g pricing plan, access control roles).\n\nBoth columns are accessible from the admin user methods. To create a user with custom metadata, you can use the following method:\n_10const { data, error } = await supabase.auth.admin.createUser({_10  email: 'foo@example.com',_10  user_metadata: {_10    full_name: 'Foo Bar',_10  },_10  app_metadata: {_10    role: 'admin',_10  },_10})\nThese fields will be exposed in the user's access token JWT so it is recommended not to store excessive metadata in these fields.\nThese fields are stored as columns in the auth.users table using the jsonb type. Both fields can be updated by using the admin updateUserById method. If you want to allow the user to update their own raw_user_meta_data , you can use the updateUser method.\nIf you have a lot of user-specific metadata to store, it is recommended to create your own table in a private schema that uses the user id as a foreign key:\n_10create table private.user_metadata (_10\tid int generated always as identity,_10\tuser_id uuid references auth.users(id) on delete cascade,_10\tuser_metadata jsonb_10);\nFrequently Asked Questions (FAQ)#\nI have IDs assigned to existing users in my database, how can I maintain these IDs?How can I allow my users to retain their existing password?My users have multi-factor authentication (MFA) enabled, how do I make sure they don't have to set up MFA again?How do I migrate existing SAML Single Sign-On (SSO) connections?How do I migrate my Auth0 organizations to Supabase?\nUseful references#\n\nMigrating 125k users from Auth0 to Supabase\nLoper to Supabase migration\nEdit this page on GitHub\nMigrate from Auth0 to Supabase Auth\nLearn how to migrate your users from Auth0\nYou can migrate your users from Auth0 to Supabase Auth.\nChanging authentication providers for a production app is an important operation. It can affect most aspects of your application. Prepare in advance by reading this guide, and develop a plan for handling the key migration steps and possible problems.\nWith advance planning, a smooth and safe Auth migration is possible.\nBefore you begin#\nBefore beginning, consider the answers to the following questions. They will help you need decide if you need to migrate, and which strategy to use:\nMigration strategies#\nDepending on your evaluation, you may choose to go with one of the following strategies:\nMigration steps#\nAuth provider migrations require 2 main steps:\nStep 1: Export your user data#\nAuth0 provides two methods for exporting user data:\nTo export password hashes and MFA factors, contact Auth0 support.\nStep 2: Import your users into Supabase Auth#\nThe steps for importing your users depends on the login methods that you support.\nSee the following sections for how to import users with:\nPassword-based methods#\nFor users who sign in with passwords, we recommend a hybrid approach to reduce downtime:\nSign up new users\nSign up new users using Supabase Auth's signin methods.\nMigrate existing users to Supabase Auth\nMigrate existing users to Supabase Auth. This requires two main steps: first, check which users need to be migrated, then create their accounts using the Supabase admin endpoints.\nGet your Auth 0 user export and password hash export lists.\nFilter for users who use password login.\nUse Supabase Auth's admin create user method to recreate the user in Supabase Auth. If the user has a confirmed email address or phone number, set email_confirm or phone_confirm to true.\nSupported password hashing algorithms\nSupabase supports BCrypt and Argon2 password hashes.\nIf you have a plaintext password instead of a hash, you can provide that instead. Supabase Auth will handle hashing the password for you. (Passwords are always stored hashed.)\nTo sign in your migrated users, use the Supabase Auth sign in methods.\nTo check for edge cases where users aren't successfully migrated, use a fallback strategy. This ensures that users can continue to sign in seamlessly:\nPasswordless methods#\nFor passwordless signin via email or phone, check for users with verified email addresses or phone numbers. Create these users in Supabase Auth with email_confirm or phone_confirm set to true:\nCheck your Supabase Auth email configuration and configure your email template for use with magic links. See the Email templates guide to learn more.\nOnce you have imported your users, you can sign them in using the signInWithOtp method.\nOAuth#\nConfigure your OAuth providers in Supabase by following the Social login guides.\nFor both new and existing users, sign in the user using the signInWithOAuth method. This works without pre-migrating existing users, since the user always needs to sign in through the OAuth provider before being redirected to your service.\nAfter the user has completed the OAuth flow successfully, you can check if the user is a new or existing user in Auth0 by mapping their social provider id to Auth0. Auth0 stores the social provider ID in the user ID, which has the format provider_name|provider_id (for example, github|123456). See the Auth0 identity docs to learn more.\nMapping between Auth0 and Supabase Auth#\nEach Auth provider has its own schema for tracking users and user information.\nIn Supabase Auth, your users are stored in your project's database under the auth schema. Every user has an identity (unless the user is an anonymous user), which represents the signin method they can use with Supabase. This is represented by the auth.users and auth.identities table.\nSee the Users and Identities sections to learn more.\nMapping user metadata and custom claims#\nSupabase Auth provides 2 fields which you can use to map user-specific metadata from Auth0:\nBoth columns are accessible from the admin user methods. To create a user with custom metadata, you can use the following method:\nThese fields will be exposed in the user's access token JWT so it is recommended not to store excessive metadata in these fields.\nThese fields are stored as columns in the auth.users table using the jsonb type. Both fields can be updated by using the admin updateUserById method. If you want to allow the user to update their own raw_user_meta_data , you can use the updateUser method.\nIf you have a lot of user-specific metadata to store, it is recommended to create your own table in a private schema that uses the user id as a foreign key:\nFrequently Asked Questions (FAQ)#\nUseful references#\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "27",
    "url": "https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-auth",
    "title": "Migrate from Firebase Auth to Supabase | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nMigrate from Firebase Auth to SupabaseMigrate Firebase auth users to Supabase Auth.[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nSupabase provides several tools to help migrate auth users from a Firebase project to a Supabase project. There are two parts to the migration process:\n\nfirestoreusers2json (TypeScript, JavaScript) exports users from an existing Firebase project to a .json file on your local system.\nimport_users (TypeScript, JavaScript) imports users from a saved .json file into your Supabase project (inserting those users into the auth.users table of your Postgres database instance).\n\nSet up the migration tool #\n\n\nClone the firebase-to-supabase repository:\n_10git clone https://github.com/supabase-community/firebase-to-supabase.git\n\n\nIn the /auth directory, create a file named supabase-service.json with the following contents:\n_10{_10  \"host\": \"database.server.com\",_10  \"password\": \"secretpassword\",_10  \"user\": \"postgres\",_10  \"database\": \"postgres\",_10  \"port\": 5432_10}\n\n\nGo to the Database settings for your project in the Supabase Dashboard.\n\n\nUnder Connection parameters, enable Use connection pooling and set the mode to Session. Replace the Host and User fields with the values shown.\n\n\nEnter the password you used when you created your Supabase project in the password entry in the supabase-service.json file.\n\n\nGenerate a Firebase private key #\n\nLog in to your Firebase Console and open your project.\nClick the gear icon next to Project Overview in the sidebar and select Project Settings.\nClick Service Accounts and select Firebase Admin SDK.\nClick Generate new private key.\nRename the downloaded file to firebase-service.json.\n\nSave your Firebase password hash parameters #\n\nLog in to your Firebase Console and open your project.\nSelect Authentication (Build section) in the sidebar.\nSelect Users in the top menu.\nAt the top right of the users list, open the menu (3 dots) and click Password hash parameters.\nCopy and save the parameters for base64_signer_key, base64_salt_separator, rounds, and mem_cost.\n\nSample_10hash_config {_10  algorithm: SCRYPT,_10  base64_signer_key: XXXX/XXX+XXXXXXXXXXXXXXXXX+XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX==,_10  base64_salt_separator: Aa==,_10  rounds: 8,_10  mem_cost: 14,_10}\nCommand line options#\nDump Firestore users to a JSON file #\nnode firestoreusers2json.js [<filename.json>] [<batch_size>]\n\nfilename.json: (optional) output filename (defaults to ./users.json)\nbatchSize: (optional) number of users to fetch in each batch (defaults to 100)\n\nImport JSON users file to Supabase Auth (Postgres: auth.users) #\nnode import_users.js <path_to_json_file> [<batch_size>]\n\npath_to_json_file: full local path and filename of .json input file (of users)\nbatch_size: (optional) number of users to process in a batch (defaults to 100)\n\nNotes#\nFor more advanced migrations, including the use of a middleware server component for verifying a user's existing Firebase password and updating that password in your Supabase project the first time a user logs in, see the firebase-to-supabase repo.\nResources#\n\nSupabase vs Firebase\nFirestore Data Migration\nFirestore Storage Migration\n\nEnterprise#\nContact us if you need more help migrating your project.Edit this page on GitHub\nMigrate from Firebase Auth to Supabase\nMigrate Firebase auth users to Supabase Auth.\nSupabase provides several tools to help migrate auth users from a Firebase project to a Supabase project. There are two parts to the migration process:\nSet up the migration tool #\nClone the firebase-to-supabase repository:\nIn the /auth directory, create a file named supabase-service.json with the following contents:\nGo to the Database settings for your project in the Supabase Dashboard.\nUnder Connection parameters, enable Use connection pooling and set the mode to Session. Replace the Host and User fields with the values shown.\nEnter the password you used when you created your Supabase project in the password entry in the supabase-service.json file.\nGenerate a Firebase private key #\nSave your Firebase password hash parameters #\nCommand line options#\nDump Firestore users to a JSON file #\nnode firestoreusers2json.js [<filename.json>] [<batch_size>]\nImport JSON users file to Supabase Auth (Postgres: auth.users) #\nnode import_users.js <path_to_json_file> [<batch_size>]\nNotes#\nFor more advanced migrations, including the use of a middleware server component for verifying a user's existing Firebase password and updating that password in your Supabase project the first time a user logs in, see the firebase-to-supabase repo.\nResources#\nEnterprise#\nContact us if you need more help migrating your project.\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "28",
    "url": "https://supabase.com/docs/guides/platform/migrating-to-supabase/firestore-data",
    "title": "Migrated from Firebase Firestore to Supabase | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nMigrated from Firebase Firestore to SupabaseMigrate your Firebase Firestore database to a Supabase Postgres database.[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nSupabase provides several tools to convert data from a Firebase Firestore database to a Supabase PostgreSQL database. The process copies the entire contents of a single Firestore collection to a single PostgreSQL table.\nThe Firestore collection is \"flattened\" and converted to a table with basic columns of one of the following types: text, numeric, boolean, or jsonb. If your structure is more complex, you can write a program to split the newly-created json file into multiple, related tables before you import your json file(s) to Supabase.\nSet up the migration tool #\n\n\nClone the firebase-to-supabase repository:\n_10git clone https://github.com/supabase-community/firebase-to-supabase.git\n\n\nIn the /firestore directory, create a file named supabase-service.json with the following contents:\n_10{_10  \"host\": \"database.server.com\",_10  \"password\": \"secretpassword\",_10  \"user\": \"postgres\",_10  \"database\": \"postgres\",_10  \"port\": 5432_10}\n\n\nGo to the Database settings for your project in the Supabase Dashboard.\n\n\nUnder Connection parameters, enable Use connection pooling and set the mode to Session. Replace the Host and User fields with the values shown.\n\n\nEnter the password you used when you created your Supabase project in the password entry in the supabase-service.json file.\n\n\nGenerate a Firebase private key #\n\nLog in to your Firebase Console and open your project.\nClick the gear icon next to Project Overview in the sidebar and select Project Settings.\nClick Service Accounts and select Firebase Admin SDK.\nClick Generate new private key.\nRename the downloaded file to firebase-service.json.\n\nCommand line options#\nList all Firestore collections#\nnode collections.js\nDump Firestore collection to JSON file#\nnode firestore2json.js <collectionName> [<batchSize>] [<limit>]\n\nbatchSize (optional) defaults to 1000\noutput filename is <collectionName>.json\nlimit (optional) defaults to 0 (no limit)\n\nCustomize the JSON file with hooks#\nYou can customize the way your JSON file is written using a custom hook. A common use for this is to \"flatten\" the JSON file, or to split nested data into separate, related database tables. For example, you could take a Firestore document that looks like this:\nFirestore_10[{ \"user\": \"mark\", \"score\": 100, \"items\": [\"hammer\", \"nail\", \"glue\"] }]\nAnd split it into two files (one table for users and one table for items):\nUsers_10[{ \"user\": \"mark\", \"score\": 100 }]\nItems_10[_10  { \"user\": \"mark\", \"item\": \"hammer\" },_10  { \"user\": \"mark\", \"item\": \"nail\" },_10  { \"user\": \"mark\", \"item\": \"glue\" }_10]\nImport JSON file to Supabase (PostgreSQL) #\nnode json2supabase.js <path_to_json_file> [<primary_key_strategy>] [<primary_key_name>]\n\n<path_to_json_file> The full path of the file you created in the previous step (Dump Firestore collection to JSON file ), such as ./my_collection.json\n[<primary_key_strategy>] (optional) Is one of:\n\nnone (default) No primary key is added to the table.\nsmallserial Creates a key using (id SMALLSERIAL PRIMARY KEY) (autoincrementing 2-byte integer).\nserial Creates a key using (id SERIAL PRIMARY KEY) (autoincrementing 4-byte integer).\nbigserial Creates a key using (id BIGSERIAL PRIMARY KEY) (autoincrementing 8-byte integer).\nuuid Creates a key using (id UUID PRIMARY KEY DEFAULT gen_random_uuid()) (randomly generated UUID).\nfirestore_id Creates a key using (id TEXT PRIMARY KEY) (uses existing firestore_id random text as key).\n\n\n[<primary_key_name>] (optional) Name of primary key. Defaults to \"id\".\n\nCustom hooks#\nHooks are used to customize the process of exporting a collection of Firestore documents to JSON. They can be used for:\n\nCustomizing or modifying keys\nCalculating data\nFlattening nested documents into related SQL tables\n\nWrite a custom hook#\nCreate a .js file for your collection#\nIf your Firestore collection is called users, create a file called users.js in the current folder.\nConstruct your .js file#\nThe basic format of a hook file looks like this:\n_10module.exports = (collectionName, doc, recordCounters, writeRecord) => {_10  // modify the doc here_10  return doc_10}\nParameters\n\ncollectionName: The name of the collection you are processing.\ndoc: The current document (JSON object) being processed.\nrecordCounters: An internal object that keeps track of how many records have been processed in each collection.\nwriteRecord: This function automatically handles the process of writing data to other JSON files (useful for \"flatting\" your document into separate JSON files to be written to separate database tables). writeRecord takes the following parameters:\n\nname: Name of the JSON file to write to.\ndoc: The document to write to the file.\nrecordCounters: The same recordCounters object that was passed to this hook (just passes it on).\n\n\n\nExamples#\nAdd a new (unique) numeric key to a collection#\n_10module.exports = (collectionName, doc, recordCounters, writeRecord) => {_10  doc.unique_key = recordCounter[collectionName] + 1_10  return doc_10}\nAdd a timestamp of when this record was dumped from Firestore#\n_10module.exports = (collectionName, doc, recordCounters, writeRecord) => {_10  doc.dump_time = new Date().toISOString()_10  return doc_10}\nFlatten JSON into separate files#\nFlatten the users collection into separate files:\n_14[_14  {_14    \"uid\": \"abc123\",_14    \"name\": \"mark\",_14    \"score\": 100,_14    \"weapons\": [\"toothpick\", \"needle\", \"rock\"]_14  },_14  {_14    \"uid\": \"xyz789\",_14    \"name\": \"chuck\",_14    \"score\": 9999999,_14    \"weapons\": [\"hand\", \"foot\", \"head\"]_14  }_14]\nThe users.js hook file:\n_11module.exports = (collectionName, doc, recordCounters, writeRecord) => {_11  for (let i = 0; i < doc.weapons.length; i++) {_11    const weapon = {_11      uid: doc.uid,_11      weapon: doc.weapons[i],_11    }_11    writeRecord('weapons', weapon, recordCounters)_11  }_11  delete doc.weapons // moved to separate file_11  return doc_11}\nThe result is two separate JSON files:\nusers.json_10[_10  { \"uid\": \"abc123\", \"name\": \"mark\", \"score\": 100 },_10  { \"uid\": \"xyz789\", \"name\": \"chuck\", \"score\": 9999999 }_10]\nweapons.json_10[_10  { \"uid\": \"abc123\", \"weapon\": \"toothpick\" },_10  { \"uid\": \"abc123\", \"weapon\": \"needle\" },_10  { \"uid\": \"abc123\", \"weapon\": \"rock\" },_10  { \"uid\": \"xyz789\", \"weapon\": \"hand\" },_10  { \"uid\": \"xyz789\", \"weapon\": \"foot\" },_10  { \"uid\": \"xyz789\", \"weapon\": \"head\" }_10]\nResources#\n\nSupabase vs Firebase\nFirestore Storage Migration\nFirebase Auth Migration\n\nEnterprise#\nContact us if you need more help migrating your project.Edit this page on GitHub\nMigrated from Firebase Firestore to Supabase\nMigrate your Firebase Firestore database to a Supabase Postgres database.\nSupabase provides several tools to convert data from a Firebase Firestore database to a Supabase PostgreSQL database. The process copies the entire contents of a single Firestore collection to a single PostgreSQL table.\nThe Firestore collection is \"flattened\" and converted to a table with basic columns of one of the following types: text, numeric, boolean, or jsonb. If your structure is more complex, you can write a program to split the newly-created json file into multiple, related tables before you import your json file(s) to Supabase.\nSet up the migration tool #\nClone the firebase-to-supabase repository:\nIn the /firestore directory, create a file named supabase-service.json with the following contents:\nGo to the Database settings for your project in the Supabase Dashboard.\nUnder Connection parameters, enable Use connection pooling and set the mode to Session. Replace the Host and User fields with the values shown.\nEnter the password you used when you created your Supabase project in the password entry in the supabase-service.json file.\nGenerate a Firebase private key #\nCommand line options#\nList all Firestore collections#\nnode collections.js\nDump Firestore collection to JSON file#\nnode firestore2json.js <collectionName> [<batchSize>] [<limit>]\nCustomize the JSON file with hooks#\nYou can customize the way your JSON file is written using a custom hook. A common use for this is to \"flatten\" the JSON file, or to split nested data into separate, related database tables. For example, you could take a Firestore document that looks like this:\nAnd split it into two files (one table for users and one table for items):\nImport JSON file to Supabase (PostgreSQL) #\nnode json2supabase.js <path_to_json_file> [<primary_key_strategy>] [<primary_key_name>]\nCustom hooks#\nHooks are used to customize the process of exporting a collection of Firestore documents to JSON. They can be used for:\nWrite a custom hook#\nCreate a .js file for your collection#\nIf your Firestore collection is called users, create a file called users.js in the current folder.\nConstruct your .js file#\nThe basic format of a hook file looks like this:\nParameters\nExamples#\nAdd a new (unique) numeric key to a collection#\nAdd a timestamp of when this record was dumped from Firestore#\nFlatten JSON into separate files#\nFlatten the users collection into separate files:\nThe users.js hook file:\nThe result is two separate JSON files:\nResources#\nEnterprise#\nContact us if you need more help migrating your project.\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "29",
    "url": "https://supabase.com/docs/guides/platform/migrating-to-supabase/firebase-storage",
    "title": "Migrated from Firebase Storage to Supabase | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nMigrated from Firebase Storage to SupabaseMigrate Firebase Storage files to Supabase Storage.[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nSupabase provides several tools to convert storage files from Firebase Storage to Supabase Storage. Conversion is a two-step process:\n\nFiles are downloaded from a Firebase storage bucket to a local filesystem.\nFiles are uploaded from the local filesystem to a Supabase storage bucket.\n\nSet up the migration tool #\n\n\nClone the firebase-to-supabase repository:\n_10git clone https://github.com/supabase-community/firebase-to-supabase.git\n\n\nIn the /storage directory, rename supabase-keys-sample.js to supabase-keys.js.\n\n\nGo to your Supabase project's API settings in the Dashboard.\n\n\nCopy the Project URL and update the SUPABASE_URL value in supabase-keys.js.\n\n\nUnder Project API keys, copy the service_role key and update the SUPABASE_KEY value in supabase-keys.js.\n\n\nGenerate a Firebase private key #\n\nLog in to your Firebase Console and open your project.\nClick the gear icon next to Project Overview in the sidebar and select Project Settings.\nClick Service Accounts and select Firebase Admin SDK.\nClick Generate new private key.\nRename the downloaded file to firebase-service.json.\n\nCommand line options#\nDownload Firestore Storage bucket to a local filesystem folder #\nnode download.js <prefix> [<folder>] [<batchSize>] [<limit>] [<token>]\n\n<prefix>: The prefix of the files to download. To process the root bucket, use an empty prefix: \"\".\n<folder>: (optional) Name of subfolder for downloaded files. The selected folder is created as a subfolder of the current folder (e.g., ./downloads/). The default is downloads.\n<batchSize>: (optional) The default is 100.\n<limit>: (optional) Stop after processing this many files. For no limit, use 0.\n<token>: (optional) Begin processing at this pageToken.\n\nTo process in batches using multiple command-line executions, you must use the same parameters with a new <token> on subsequent calls. Use the token displayed on the last call to continue the process at a given point.\nUpload files to Supabase Storage bucket #\nnode upload.js <prefix> <folder> <bucket>\n\n<prefix>: The prefix of the files to download. To process all files, use an empty prefix: \"\".\n<folder>: Name of subfolder of files to upload. The selected folder is read as a subfolder of the current folder (e.g., ./downloads/). The default is downloads.\n<bucket>: Name of the bucket to upload to.\n\nIf the bucket doesn't exist, it's created as a non-public bucket. You must set permissions on this new bucket in the Supabase Dashboard before users can download any files.\nResources#\n\nSupabase vs Firebase\nFirestore Data Migration\nFirebase Auth Migration\n\nEnterprise#\nContact us if you need more help migrating your project.Edit this page on GitHub\nMigrated from Firebase Storage to Supabase\nMigrate Firebase Storage files to Supabase Storage.\nSupabase provides several tools to convert storage files from Firebase Storage to Supabase Storage. Conversion is a two-step process:\nSet up the migration tool #\nClone the firebase-to-supabase repository:\nIn the /storage directory, rename supabase-keys-sample.js to supabase-keys.js.\nGo to your Supabase project's API settings in the Dashboard.\nCopy the Project URL and update the SUPABASE_URL value in supabase-keys.js.\nUnder Project API keys, copy the service_role key and update the SUPABASE_KEY value in supabase-keys.js.\nGenerate a Firebase private key #\nCommand line options#\nDownload Firestore Storage bucket to a local filesystem folder #\nnode download.js <prefix> [<folder>] [<batchSize>] [<limit>] [<token>]\nTo process in batches using multiple command-line executions, you must use the same parameters with a new <token> on subsequent calls. Use the token displayed on the last call to continue the process at a given point.\nUpload files to Supabase Storage bucket #\nnode upload.js <prefix> <folder> <bucket>\nIf the bucket doesn't exist, it's created as a non-public bucket. You must set permissions on this new bucket in the Supabase Dashboard before users can download any files.\nResources#\nEnterprise#\nContact us if you need more help migrating your project.\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "30",
    "url": "https://supabase.com/docs/guides/platform/migrating-to-supabase/heroku",
    "title": "Migrate from Heroku to Supabase | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nMigrate from Heroku to SupabaseMigrate your Heroku Postgres database to Supabase.[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nSupabase is one of the best free alternatives to Heroku Postgres. This guide shows how to migrate your Heroku Postgres database to Supabase. This migration requires the pg_dump and psql CLI tools, which are installed automatically as part of the complete PostgreSQL installation package.\nAlternatively, use the Heroku to Supabase migration tool to migrate in just a few clicks.\nQuick demo#\n\nRetrieve your Heroku database credentials #\n\nLog in to your Heroku account and select the project you want to migrate.\nClick Resources in the menu and select your Heroku Postgres database.\nClick Settings in the menu.\nClick View Credentials and save the following information:\n\nHost ($HEROKU_HOST)\nDatabase ($HEROKU_DATABASE)\nUser ($HEROKU_USER)\nPassword ($HEROKU_PASSWORD)\n\n\n\nRetrieve your Supabase connection string #\n\nIf you're new to Supabase, create a project.\nGo to the Database settings for your project in the Supabase Dashboard.\nUnder Connection string, make sure Use connection pooling is enabled. Copy the URI and replace the password placeholder with your database password.\n\nExport your Heroku database to a file #\nUse pg_dump with your Heroku credentials to export your Heroku database to a file (e.g., heroku_dump.sql).\n1pg_dump --clean --if-exists --quote-all-identifiers \\2 -h $HEROKU_HOST -U $HEROKU_USER -d $HEROKU_DATABASE \\3 --no-owner --no-privileges > heroku_dump.sql\nImport the database to your Supabase project #\nUse psql to import the Heroku database file to your Supabase project.\n1psql -d \"$YOUR_CONNECTION_STRING\" -f heroku_dump.sql\nAdditional options#\n\nTo only migrate a single database schema, add the --schema=PATTERN parameter to your pg_dump command.\nTo exclude a schema: --exclude-schema=PATTERN.\nTo only migrate a single table: --table=PATTERN.\nTo exclude a table: --exclude-table=PATTERN.\n\nRun pg_dump --help for a full list of options.\n\n\nIf you're planning to migrate a database larger than 6 GB, we recommend upgrading to at least a Large compute add-on. This will ensure you have the necessary resources to handle the migration efficiently.\n\n\nFor databases smaller than 150 GB, you can increase the size of the disk on paid projects by navigating to Database Settings.\n\n\nIf you're dealing with a database larger than 150 GB, we strongly advise you to contact our support team for assistance in provisioning the required resources and ensuring a smooth migration process.\n\n\nEnterprise#\nContact us if you need more help migrating your project.Edit this page on GitHub\nMigrate from Heroku to Supabase\nMigrate your Heroku Postgres database to Supabase.\nSupabase is one of the best free alternatives to Heroku Postgres. This guide shows how to migrate your Heroku Postgres database to Supabase. This migration requires the pg_dump and psql CLI tools, which are installed automatically as part of the complete PostgreSQL installation package.\nAlternatively, use the Heroku to Supabase migration tool to migrate in just a few clicks.\nQuick demo#\nRetrieve your Heroku database credentials #\nRetrieve your Supabase connection string #\nExport your Heroku database to a file #\nUse pg_dump with your Heroku credentials to export your Heroku database to a file (e.g., heroku_dump.sql).\nImport the database to your Supabase project #\nUse psql to import the Heroku database file to your Supabase project.\nAdditional options#\nRun pg_dump --help for a full list of options.\nIf you're planning to migrate a database larger than 6 GB, we recommend upgrading to at least a Large compute add-on. This will ensure you have the necessary resources to handle the migration efficiently.\nFor databases smaller than 150 GB, you can increase the size of the disk on paid projects by navigating to Database Settings.\nIf you're dealing with a database larger than 150 GB, we strongly advise you to contact our support team for assistance in provisioning the required resources and ensuring a smooth migration process.\nEnterprise#\nContact us if you need more help migrating your project.\nWatch video guide\nIs this helpful? Yes  No Thanks for your feedback!\nIs this helpful?\nNeed some help?\nLatest product updates?\nSomething's not right?\nWe use first-party cookies to improve our services. Learn more Learn moreâ€¢Privacy settings Accept  Opt out Privacy settings\nWe use first-party cookies to improve our services. Learn more"
  },
  {
    "id": "31",
    "url": "https://supabase.com/docs/guides/platform/migrating-to-supabase/render",
    "title": "Migrate from Render to Supabase | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nMigrate from Render to SupabaseMigrate your Render Postgres database to Supabase.[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nRender is a popular Web Hosting service in the online services category that also has a managed Postgres service. Render has a great developer experience, allowing users to deploy straight from GitHub or GitLab. This is the core of their product and they do it really well. However, when it comes to Postgres databases, it may not be the best option.\nSupabase is one of the best free alternative to Render Postgres. Supabase provide all the backend features developers need to build a product: a Postgres database, authentication, instant APIs, edge functions, realtime subscriptions, and storage. Postgres is the core of Supabaseâ€”for example, you can use row-level security and there are more than 40 Postgres extensions available.\nThis guide demonstrates how to migrate from Render to Supabase to get the most out of Postgres while gaining access to all the features you need to build a project.\nRetrieve your Render database credentials #\n\nLog in to your Render account and select the project you want to migrate.\nClick Dashboard in the menu and click in your Postgres database.\nScroll down in the Info tab.\nClick on PSQL Command and edit it adding the content after PSQL_COMMAND=.\n\n\nExample:\n1%env PSQL_COMMAND=PGPASSWORD=RgaMDfTS_password_FTPa7 psql -h dpg-a_server_in.oregon-postgres.render.com -U my_db_pxl0_user my_db_pxl0\nRetrieve your Supabase connection string #\n\n\nIf you're new to Supabase, create a project.\nMake a note of your password, you will need this later. If you forget it, you can reset it here.\n\n\nGo to the Database settings for your project in the Supabase Dashboard.\n\n\nUnder Connection string, make sure Use connection pooling is enabled. Copy the URI and replace the password placeholder with your database password.\n\n\nMigrate the database#\nThe fastest way to migrate your database is with the Supabase migration tool on Google Colab. Alternatively, you can use the pg_dump and psql command line tools, which are included in a full PostgreSQL installation.\nMigrate using ColabMigrate using CLI tools\nSet the environment variables (PSQL_COMMAND, SUPABASE_HOST, SUPABASE_PASSWORD) in the Colab notebook.\nRun the first two steps in the notebook in order. The first sets the variables and the second installs PSQL and the migration script.\nRun the third step to start the migration. This will take a few minutes.\n\n\n\nIf you're planning to migrate a database larger than 6 GB, we recommend upgrading to at least a Large compute add-on. This will ensure you have the necessary resources to handle the migration efficiently.\n\n\nFor databases smaller than 150 GB, you can increase the size of the disk on paid projects by navigating to Database Settings.\n\n\nIf you're dealing with a database larger than 150 GB, we strongly advise you to contact our support team for assistance in provisioning the required resources and ensuring a smooth migration process.\n\n\nEnterprise#\nContact us if you need more help migrating your project.Edit this page on GitHub\nMigrate from Render to Supabase\nMigrate your Render Postgres database to Supabase.\nRender is a popular Web Hosting service in the online services category that also has a managed Postgres service. Render has a great developer experience, allowing users to deploy straight from GitHub or GitLab. This is the core of their product and they do it really well. However, when it comes to Postgres databases, it may not be the best option.\nSupabase is one of the best free alternative to Render Postgres. Supabase provide all the backend features developers need to build a product: a Postgres database, authentication, instant APIs, edge functions, realtime subscriptions, and storage. Postgres is the core of Supabaseâ€”for example, you can use row-level security and there are more than 40 Postgres extensions available.\nThis guide demonstrates how to migrate from Render to Supabase to get the most out of Postgres while gaining access to all the features you need to build a project.\nRetrieve your Render database credentials #\nExample:\nRetrieve your Supabase connection string #\nIf you're new to Supabase, create a project.\nMake a note of your password, you will need this later. If you forget it, you can reset it here.\nGo to the Database settings for your project in the Supabase Dashboard.\nUnder Connection string, make sure Use connection pooling is enabled. Copy the URI and replace the password placeholder with your database password.\nMigrate the database#\nThe fastest way to migrate your database is with the Supabase migration tool on Google Colab. Alternatively, you can use the pg_dump and psql command line tools, which are included in a full PostgreSQL installation.\nIf you're planning to migrate a database larger than 6 GB, we recommend upgrading to at least a Large compute add-on. This will ensure you have the necessary resources to handle the migration efficiently.\nFor databases smaller than 150 GB, you can increase the size of the disk on paid projects by navigating to Database Settings.\nIf you're dealing with a database larger than 150 GB, we strongly advise you to contact our support team for assistance in provisioning the required resources and ensuring a smooth migration process.\nEnterprise#\nContact us if you need more help migrating your project.\nIs this helpful? Yes  No Thanks for your feedback!\nIs this helpful?\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "32",
    "url": "https://supabase.com/docs/guides/platform/migrating-to-supabase/amazon-rds",
    "title": "Migrate from Amazon RDS to Supabase | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nMigrate from Amazon RDS to SupabaseMigrate your Amazon RDS MySQL or MS SQL database to Supabase.[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nThis guide aims to exhibit the process of transferring your Amazon RDS database from any of these engines Postgres, MySQL or MS SQL to Supabase's Postgres database. Although Amazon RDS is a favored managed database service provided by AWS, it may not suffice for all use cases. Supabase, on the other hand, provides an excellent free and open source option that encompasses all the necessary backend features to develop a product: a Postgres database, authentication, instant APIs, edge functions, real-time subscriptions, and storage.\nSupabase's core is Postgres, enabling the use of row-level security and providing access to over 40 Postgres extensions. By migrating from Amazon RDS to Supabase, you can leverage Postgres to its fullest potential and acquire all the features you need to complete your project.\nRetrieve your Amazon RDS database credentials #\n\nLog in to your Amazon RDS account.\nSelect the region where your RDS database is located.\nNavigate to the Databases tab.\nSelect the database that you want to migrate.\nIn the Connectivity & Security tab, note down the Endpoint and the port number.\nIn the Configuration tab, note down the Database name and the Username.\nIf you do not have the password, create a new one and note it down.\n\n\nRetrieve your Supabase host #\n\nIf you're new to Supabase, create a project. Make a note of your password, you will need this later. If you forget it, you can reset it here.\nGo to the Database settings for your project in the Supabase Dashboard.\nUnder Connection Info, note your Host ($SUPABASE_HOST).\n\n\nMigrate the database#\nThe fastest way to migrate your database is with the Supabase migration tool on\nGoogle Colab.\nAlternatively, you can use pgloader, a flexible and powerful data migration tool that supports a wide range of source database engines, including MySQL and MS SQL, and migrates the data to a Postgres database. For databases using the Postgres engine, we recommend using the pg_dump and psql command line tools, which are included in a full PostgreSQL installation.\nMigrate using ColabMigrate from MySQL with pgloaderMigrate from MSSQL\nSelect the Database Engine from the Source database in the dropdown\nSet the environment variables (HOST, USER, SOURCE_DB,PASSWORD, SUPABASE_URL, and SUPABASE_PASSWORD) in the Colab notebook.\nRun the first two steps in the notebook in order. The first sets engine and installs the necessary files.\nRun the third step to start the migration. This will take a few minutes.\n\n\n\nIf you're planning to migrate a database larger than 6 GB, we recommend upgrading to at least a Large compute add-on. This will ensure you have the necessary resources to handle the migration efficiently.\n\n\nFor databases smaller than 150 GB, you can increase the size of the disk on paid projects by navigating to Database Settings.\n\n\nIf you're dealing with a database larger than 150 GB, we strongly advise you to contact our support team for assistance in provisioning the required resources and ensuring a smooth migration process.\n\n\nEnterprise#\nContact us if you need more help migrating your project.Edit this page on GitHub\nMigrate from Amazon RDS to Supabase\nMigrate your Amazon RDS MySQL or MS SQL database to Supabase.\nThis guide aims to exhibit the process of transferring your Amazon RDS database from any of these engines Postgres, MySQL or MS SQL to Supabase's Postgres database. Although Amazon RDS is a favored managed database service provided by AWS, it may not suffice for all use cases. Supabase, on the other hand, provides an excellent free and open source option that encompasses all the necessary backend features to develop a product: a Postgres database, authentication, instant APIs, edge functions, real-time subscriptions, and storage.\nSupabase's core is Postgres, enabling the use of row-level security and providing access to over 40 Postgres extensions. By migrating from Amazon RDS to Supabase, you can leverage Postgres to its fullest potential and acquire all the features you need to complete your project.\nRetrieve your Amazon RDS database credentials #\n\nRetrieve your Supabase host #\n\nMigrate the database#\nThe fastest way to migrate your database is with the Supabase migration tool on\nGoogle Colab.\nAlternatively, you can use pgloader, a flexible and powerful data migration tool that supports a wide range of source database engines, including MySQL and MS SQL, and migrates the data to a Postgres database. For databases using the Postgres engine, we recommend using the pg_dump and psql command line tools, which are included in a full PostgreSQL installation.\nIf you're planning to migrate a database larger than 6 GB, we recommend upgrading to at least a Large compute add-on. This will ensure you have the necessary resources to handle the migration efficiently.\nFor databases smaller than 150 GB, you can increase the size of the disk on paid projects by navigating to Database Settings.\nIf you're dealing with a database larger than 150 GB, we strongly advise you to contact our support team for assistance in provisioning the required resources and ensuring a smooth migration process.\nEnterprise#\nContact us if you need more help migrating your project.\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "33",
    "url": "https://supabase.com/docs/guides/platform/migrating-to-supabase/postgres",
    "title": "Migrate from Postgres to Supabase | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nMigrate from Postgres to SupabaseMigrate your existing Postgres database to Supabase.[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nThis is a guide for migrating your Postgres database to Supabase.\nSupabase is a robust and open-source platform. Supabase provide all the backend features developers need to build a product: a Postgres database, authentication, instant APIs, edge functions, realtime subscriptions, and storage. Postgres is the core of Supabaseâ€”for example, you can use row-level security and there are more than 40 Postgres extensions available.\nThis guide demonstrates how to migrate your Postgres database to Supabase to get the most out of Postgres while gaining access to all the features you need to build a project.\nRetrieve your Postgres database credentials #\n\nLog in to your provider to get the connection details for your Postgres database.\nClick on PSQL Command and edit it adding the content after PSQL_COMMAND=.\n\nExample:\n_10%env PSQL_COMMAND=PGPASSWORD=RgaMDfTS_password_FTPa7 psql -h dpg-a_server_in.oregon-postgres.provider.com -U my_db_pxl0_user my_db_pxl0\nRetrieve your Supabase connection string #\n\n\nIf you're new to Supabase, create a project.\nMake a note of your password, you will need this later. If you forget it, you can reset it here.\n\n\nGo to the Database settings for your project in the Supabase Dashboard.\n\n\nUnder Connection string, make sure Use connection pooling is enabled. Copy the URI and replace the password placeholder with your database password.\n\n\n\nMigrate the database#\nThe fastest way to migrate your database is with the Supabase migration tool on Google Colab. Alternatively, you can use the pg_dump and psql command line tools, which are included in a full PostgreSQL installation.\nMigrate using ColabMigrate using CLI tools\nSet the environment variables (PSQL_COMMAND, SUPABASE_HOST, SUPABASE_PASSWORD) in the Colab notebook.\nRun the first two steps in the notebook in order. The first sets the variables and the second installs PSQL and the migration script.\nRun the third step to start the migration. This will take a few minutes.\n\n\n\nIf you're planning to migrate a database larger than 6 GB, we recommend upgrading to at least a Large compute add-on. This will ensure you have the necessary resources to handle the migration efficiently.\n\n\nFor databases smaller than 150 GB, you can increase the size of the disk on paid projects by navigating to Database Settings.\n\n\nIf you're dealing with a database larger than 150 GB, we strongly advise you to contact our support team for assistance in provisioning the required resources and ensuring a smooth migration process.\n\n\nEnterprise#\nContact us if you need more help migrating your project.Edit this page on GitHub\nMigrate from Postgres to Supabase\nMigrate your existing Postgres database to Supabase.\nThis is a guide for migrating your Postgres database to Supabase.\nSupabase is a robust and open-source platform. Supabase provide all the backend features developers need to build a product: a Postgres database, authentication, instant APIs, edge functions, realtime subscriptions, and storage. Postgres is the core of Supabaseâ€”for example, you can use row-level security and there are more than 40 Postgres extensions available.\nThis guide demonstrates how to migrate your Postgres database to Supabase to get the most out of Postgres while gaining access to all the features you need to build a project.\nRetrieve your Postgres database credentials #\nExample:\nRetrieve your Supabase connection string #\nIf you're new to Supabase, create a project.\nMake a note of your password, you will need this later. If you forget it, you can reset it here.\nGo to the Database settings for your project in the Supabase Dashboard.\nUnder Connection string, make sure Use connection pooling is enabled. Copy the URI and replace the password placeholder with your database password.\n\nMigrate the database#\nThe fastest way to migrate your database is with the Supabase migration tool on Google Colab. Alternatively, you can use the pg_dump and psql command line tools, which are included in a full PostgreSQL installation.\nIf you're planning to migrate a database larger than 6 GB, we recommend upgrading to at least a Large compute add-on. This will ensure you have the necessary resources to handle the migration efficiently.\nFor databases smaller than 150 GB, you can increase the size of the disk on paid projects by navigating to Database Settings.\nIf you're dealing with a database larger than 150 GB, we strongly advise you to contact our support team for assistance in provisioning the required resources and ensuring a smooth migration process.\nEnterprise#\nContact us if you need more help migrating your project.\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "34",
    "url": "https://supabase.com/docs/guides/platform/migrating-to-supabase/vercel-postgres",
    "title": "Migrate from Vercel Postgres to Supabase | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nMigrate from Vercel Postgres to SupabaseMigrate your existing Vercel Postgres database to Supabase.[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nThis guide demonstrates how to migrate your Vercel Postgres database to Supabase to get the most out of Postgres while gaining access to all the features you need to build a project.\nRetrieve your Vercel Postgres database credentials #\n\nLog in to your Vercel Dashboard https://vercel.com/login.\nClick on the Storage tab.\nClick on your Postgres Database.\nUnder the Quickstart section, select psql then click Show Secret to reveal your database password.\nCopy the string after psql  to the clipboard.\n\nExample:\n_10psql \"postgres://default:xxxxxxxxxxxx@yy-yyyyy-yyyyyy-yyyyyyy.us-west-2.aws.neon.tech:5432/verceldb?sslmode=require\"\nCopy this part to your clipboard:\n_10\"postgres://default:xxxxxxxxxxxx@yy-yyyyy-yyyyyy-yyyyyyy.us-west-2.aws.neon.tech:5432/verceldb?sslmode=require\"\nSet your OLD_DB_URL environment variable#\nSet the OLD_DB_URL environment variable at the command line using your Vercel Postgres Database credentials.\nExample:\n_10export OLD_DB_URL=\"postgres://default:xxxxxxxxxxxx@yy-yyyyy-yyyyyy-yyyyyyy.us-west-2.aws.neon.tech:5432/verceldb?sslmode=require\"\nRetrieve your Supabase connection string #\n\n\nIf you're new to Supabase, create a project.\nMake a note of your password, you will need this later. If you forget it, you can reset it here.\n\n\nGo to the Database settings for your project in the Supabase Dashboard.\n\n\nUnder Connection string, select URI, make sure Display connection pooler is checked, and Mode: Session is set.\n\n\nClick the Copy button to the right of your connection string to copy it to the clipboard.\n\n\nSet your NEW_DB_URL environment variable#\nSet the NEW_DB_URL environment variable at the command line using your Supabase connection string. You will need to replace [YOUR-PASSWORD] with your actual database password.\nExample:\n_10export NEW_DB_URL=\"postgresql://postgres.xxxxxxxxxxxxxxxxxxxx:[YOUR-PASSWORD]@aws-0-us-west-1.pooler.supabase.com:5432/postgres\"\nMigrate the database#\nYou will need the pg_dump and psql command line tools, which are included in a full PostgreSQL installation.\n\n\nExport your database to a file in console\nUse pg_dump with your Postgres credentials to export your database to a file (e.g., dump.sql).\n\n\n_10pg_dump \"$OLD_DB_URL\" \\_10  --clean \\_10  --if-exists \\_10  --quote-all-identifiers \\_10  --no-owner \\_10  --no-privileges \\_10  > dump.sql\n\n\nImport the database to your Supabase project\nUse psql to import the Postgres database file to your Supabase project.\n_10psql -d \"$NEW_DB_URL\" -f dump.sql\n\n\nAdditional options\n\nTo only migrate a single database schema, add the --schema=PATTERN parameter to your pg_dump command.\nTo exclude a schema: --exclude-schema=PATTERN.\nTo only migrate a single table: --table=PATTERN.\nTo exclude a table: --exclude-table=PATTERN.\n\nRun pg_dump --help for a full list of options.\n\n\nIf you're planning to migrate a database larger than 6 GB, we recommend upgrading to at least a Large compute add-on. This will ensure you have the necessary resources to handle the migration efficiently.\n\n\nFor databases smaller than 150 GB, you can increase the size of the disk on paid projects by navigating to Database Settings.\n\n\nIf you're dealing with a database larger than 150 GB, we strongly advise you to contact our support team for assistance in provisioning the required resources and ensuring a smooth migration process.\n\n\nEnterprise#\nContact us if you need more help migrating your project.Edit this page on GitHub\nMigrate from Vercel Postgres to Supabase\nMigrate your existing Vercel Postgres database to Supabase.\nThis guide demonstrates how to migrate your Vercel Postgres database to Supabase to get the most out of Postgres while gaining access to all the features you need to build a project.\nRetrieve your Vercel Postgres database credentials #\nExample:\nCopy this part to your clipboard:\nSet your OLD_DB_URL environment variable#\nSet the OLD_DB_URL environment variable at the command line using your Vercel Postgres Database credentials.\nExample:\nRetrieve your Supabase connection string #\nIf you're new to Supabase, create a project.\nMake a note of your password, you will need this later. If you forget it, you can reset it here.\nGo to the Database settings for your project in the Supabase Dashboard.\nUnder Connection string, select URI, make sure Display connection pooler is checked, and Mode: Session is set.\nClick the Copy button to the right of your connection string to copy it to the clipboard.\nSet your NEW_DB_URL environment variable#\nSet the NEW_DB_URL environment variable at the command line using your Supabase connection string. You will need to replace [YOUR-PASSWORD] with your actual database password.\nExample:\nMigrate the database#\nYou will need the pg_dump and psql command line tools, which are included in a full PostgreSQL installation.\nExport your database to a file in console\nUse pg_dump with your Postgres credentials to export your database to a file (e.g., dump.sql).\nImport the database to your Supabase project\nUse psql to import the Postgres database file to your Supabase project.\nAdditional options\nRun pg_dump --help for a full list of options.\nIf you're planning to migrate a database larger than 6 GB, we recommend upgrading to at least a Large compute add-on. This will ensure you have the necessary resources to handle the migration efficiently.\nFor databases smaller than 150 GB, you can increase the size of the disk on paid projects by navigating to Database Settings.\nIf you're dealing with a database larger than 150 GB, we strongly advise you to contact our support team for assistance in provisioning the required resources and ensuring a smooth migration process.\nEnterprise#\nContact us if you need more help migrating your project.\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "35",
    "url": "https://supabase.com/docs/guides/platform/migrating-to-supabase/neon",
    "title": "Migrate from Neon to Supabase | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nMigrate from Neon to SupabaseMigrate your existing Neon database to Supabase.[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nThis guide demonstrates how to migrate your Neon database to Supabase to get the most out of Postgres while gaining access to all the features you need to build a project.\nRetrieve your Neon database credentials #\n\nLog in to your Neon Console https://console.neon.tech/login.\nSelect Projects on the left.\nClick on your project in the list.\nFrom your Project Dashboard find your Connection string and click Copy snippet to copy it to the clipboard (do not check \"pooled connection\").\n\nExample:\n1postgresql://neondb_owner:xxxxxxxxxxxxxxx-random-word-yyyyyyyy.us-west-2.aws.neon.tech/neondb?sslmode=require\nSet your OLD_DB_URL environment variable#\nSet the OLD_DB_URL environment variable at the command line using your Neon database credentials from the clipboard.\nExample:\n1export OLD_DB_URL=\"postgresql://neondb_owner:xxxxxxxxxxxxxxx-random-word-yyyyyyyy.us-west-2.aws.neon.tech/neondb?sslmode=require\"\nRetrieve your Supabase connection string #\n\n\nIf you're new to Supabase, create a project.\nMake a note of your password, you will need this later. If you forget it, you can reset it here.\n\n\nGo to the Database settings for your project in the Supabase Dashboard.\n\n\nUnder Connection string, select URI, make sure Display connection pooler is checked, and Mode: Session is set.\n\n\nClick the Copy button to the right of your connection string to copy it to the clipboard.\n\n\nSet your NEW_DB_URL environment variable#\nSet the NEW_DB_URL environment variable at the command line using your Supabase connection string. You will need to replace [YOUR-PASSWORD] with your actual database password.\nExample:\n1export NEW_DB_URL=\"postgresql://postgres.xxxxxxxxxxxxxxxxxxxx:[YOUR-PASSWORD]@aws-0-us-west-1.pooler.supabase.com:5432/postgres\"\nMigrate the database#\nYou will need the pg_dump and psql command line tools, which are included in a full PostgreSQL installation.\n\n\nExport your database to a file in console\nUse pg_dump with your Postgres credentials to export your database to a file (e.g., dump.sql).\n\n\n1pg_dump \"$OLD_DB_URL\" \\2  --clean \\3  --if-exists \\4  --quote-all-identifiers \\5  --no-owner \\6  --no-privileges \\7  > dump.sql\n\n\nImport the database to your Supabase project\nUse psql to import the Postgres database file to your Supabase project.\n1psql -d \"$NEW_DB_URL\" -f dump.sql\n\n\nAdditional options\n\nTo only migrate a single database schema, add the --schema=PATTERN parameter to your pg_dump command.\nTo exclude a schema: --exclude-schema=PATTERN.\nTo only migrate a single table: --table=PATTERN.\nTo exclude a table: --exclude-table=PATTERN.\n\nRun pg_dump --help for a full list of options.\n\n\nIf you're planning to migrate a database larger than 6 GB, we recommend upgrading to at least a Large compute add-on. This will ensure you have the necessary resources to handle the migration efficiently.\n\n\nFor databases smaller than 150 GB, you can increase the size of the disk on paid projects by navigating to Database Settings.\n\n\nIf you're dealing with a database larger than 150 GB, we strongly advise you to contact our support team for assistance in provisioning the required resources and ensuring a smooth migration process.\n\n\nEnterprise#\nContact us if you need more help migrating your project.Edit this page on GitHub\nMigrate from Neon to Supabase\nMigrate your existing Neon database to Supabase.\nThis guide demonstrates how to migrate your Neon database to Supabase to get the most out of Postgres while gaining access to all the features you need to build a project.\nRetrieve your Neon database credentials #\nExample:\nSet your OLD_DB_URL environment variable#\nSet the OLD_DB_URL environment variable at the command line using your Neon database credentials from the clipboard.\nExample:\nRetrieve your Supabase connection string #\nIf you're new to Supabase, create a project.\nMake a note of your password, you will need this later. If you forget it, you can reset it here.\nGo to the Database settings for your project in the Supabase Dashboard.\nUnder Connection string, select URI, make sure Display connection pooler is checked, and Mode: Session is set.\nClick the Copy button to the right of your connection string to copy it to the clipboard.\nSet your NEW_DB_URL environment variable#\nSet the NEW_DB_URL environment variable at the command line using your Supabase connection string. You will need to replace [YOUR-PASSWORD] with your actual database password.\nExample:\nMigrate the database#\nYou will need the pg_dump and psql command line tools, which are included in a full PostgreSQL installation.\nExport your database to a file in console\nUse pg_dump with your Postgres credentials to export your database to a file (e.g., dump.sql).\nImport the database to your Supabase project\nUse psql to import the Postgres database file to your Supabase project.\nAdditional options\nRun pg_dump --help for a full list of options.\nIf you're planning to migrate a database larger than 6 GB, we recommend upgrading to at least a Large compute add-on. This will ensure you have the necessary resources to handle the migration efficiently.\nFor databases smaller than 150 GB, you can increase the size of the disk on paid projects by navigating to Database Settings.\nIf you're dealing with a database larger than 150 GB, we strongly advise you to contact our support team for assistance in provisioning the required resources and ensuring a smooth migration process.\nEnterprise#\nContact us if you need more help migrating your project."
  },
  {
    "id": "36",
    "url": "https://supabase.com/docs/guides/platform/migrating-to-supabase/mysql",
    "title": "Migrate from MySQL to Supabase | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nMigrate from MySQL to SupabaseMigrate your MySQL database to Supabase Postgres database.[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nThis guide aims to exhibit the process of transferring your MySQL database to Supabase's Postgres database. Supabase is a robust and open-source platform offering a wide range of backend features, including a PostgreSQL database, authentication, instant APIs, edge functions, real-time subscriptions, and storage. Migrating your MySQL database to Supabase's PostgreSQL enables you to leverage PostgreSQL's capabilities and access all the features you need for your project.\nRetrieve your mySQL database credentials#\nBefore you begin the migration, you need to collect essential information about your MySQL database. Follow these steps:\n\n\nLog in to your MySQL database provider.\n\n\nLocate and note the following database details:\n\nHostname or IP address\nDatabase name\nUsername\nPassword\n\n\n\nRetrieve your Supabase host #\n\n\nIf you're new to Supabase, create a project.\nMake a note of your password, you will need this later. If you forget it, you can reset it here.\n\n\nGo to the Database settings for your project in the Supabase Dashboard.\n\n\nUnder Connection Info, note your Host ($SUPABASE_HOST).\n\n\n\nMigrate the database#\nThe fastest way to migrate your database is with the Supabase migration tool on\nGoogle Colab.\nAlternatively, you can use pgloader, a flexible and powerful data migration tool that supports a wide range of source database engines, including MySQL and MS SQL, and migrates the data to a Postgres database. For databases using the Postgres engine, we recommend using the pg_dump and psql command line tools, which are included in a full PostgreSQL installation.\nMigrate using ColabMigrate from MySQL with pgloader\nSelect the Database Engine from the Source database in the dropdown\nSet the environment variables (HOST, USER, SOURCE_DB,PASSWORD, SUPABASE_URL, and SUPABASE_PASSWORD) in the Colab notebook.\nRun the first two steps in the notebook in order. The first sets engine and installs the necessary files.\nRun the third step to start the migration. This will take a few minutes.\n\n\n\nIf you're planning to migrate a database larger than 6 GB, we recommend upgrading to at least a Large compute add-on. This will ensure you have the necessary resources to handle the migration efficiently.\n\n\nFor databases smaller than 150 GB, you can increase the size of the disk on paid projects by navigating to Database Settings.\n\n\nIf you're dealing with a database larger than 150 GB, we strongly advise you to contact our support team for assistance in provisioning the required resources and ensuring a smooth migration process.\n\n\nEnterprise#\nContact us if you need more help migrating your project.Edit this page on GitHub\nMigrate from MySQL to Supabase\nMigrate your MySQL database to Supabase Postgres database.\nThis guide aims to exhibit the process of transferring your MySQL database to Supabase's Postgres database. Supabase is a robust and open-source platform offering a wide range of backend features, including a PostgreSQL database, authentication, instant APIs, edge functions, real-time subscriptions, and storage. Migrating your MySQL database to Supabase's PostgreSQL enables you to leverage PostgreSQL's capabilities and access all the features you need for your project.\nRetrieve your mySQL database credentials#\nBefore you begin the migration, you need to collect essential information about your MySQL database. Follow these steps:\nLog in to your MySQL database provider.\nLocate and note the following database details:\nRetrieve your Supabase host #\nIf you're new to Supabase, create a project.\nMake a note of your password, you will need this later. If you forget it, you can reset it here.\nGo to the Database settings for your project in the Supabase Dashboard.\nUnder Connection Info, note your Host ($SUPABASE_HOST).\n\nMigrate the database#\nThe fastest way to migrate your database is with the Supabase migration tool on\nGoogle Colab.\nAlternatively, you can use pgloader, a flexible and powerful data migration tool that supports a wide range of source database engines, including MySQL and MS SQL, and migrates the data to a Postgres database. For databases using the Postgres engine, we recommend using the pg_dump and psql command line tools, which are included in a full PostgreSQL installation.\nIf you're planning to migrate a database larger than 6 GB, we recommend upgrading to at least a Large compute add-on. This will ensure you have the necessary resources to handle the migration efficiently.\nFor databases smaller than 150 GB, you can increase the size of the disk on paid projects by navigating to Database Settings.\nIf you're dealing with a database larger than 150 GB, we strongly advise you to contact our support team for assistance in provisioning the required resources and ensuring a smooth migration process.\nEnterprise#\nContact us if you need more help migrating your project.\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "37",
    "url": "https://supabase.com/docs/guides/platform/migrating-to-supabase/mssql",
    "title": "Migrate from MSSQL to Supabase | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nMigrate from MSSQL to SupabaseMigrate your Microsoft SQL Server database to Supabase.[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nThis guide aims to demonstrate the process of transferring your Microsoft SQL Server database to Supabase's PostgreSQL database. Supabase is a powerful and open-source platform offering a wide range of backend features, including a PostgreSQL database, authentication, instant APIs, edge functions, real-time subscriptions, and storage. Migrating your MSSQL database to Supabase's Postgres enables you to leverage Postgres's capabilities and access all the features you need for your project.\nRetrieve your MSSQL database credentials#\nBefore you begin the migration, you need to collect essential information about your MSSQL database. Follow these steps:\n\nLog in to your MSSQL database provider.\nLocate and note the following database details:\n\nHostname or IP address\nDatabase name\nUsername\nPassword\n\n\n\nRetrieve your Supabase host #\n\n\nIf you're new to Supabase, create a project.\nMake a note of your password, you will need this later. If you forget it, you can reset it here.\n\n\nGo to the Database settings for your project in the Supabase Dashboard.\n\n\nUnder Connection Info, note your Host ($SUPABASE_HOST).\n\n\n\nMigrate the database#\nThe fastest way to migrate your database is with the Supabase migration tool on\nGoogle Colab.\nAlternatively, you can use pgloader, a flexible and powerful data migration tool that supports a wide range of source database engines, including MySQL and MS SQL, and migrates the data to a Postgres database. For databases using the Postgres engine, we recommend using the pg_dump and psql command line tools, which are included in a full PostgreSQL installation.\nMigrate using ColabMigrate from MSSQL\nSelect the Database Engine from the Source database in the dropdown.\nSet the environment variables (HOST, USER, SOURCE_DB,PASSWORD, SUPABASE_URL, and SUPABASE_PASSWORD) in the Colab notebook.\nRun the first two steps in the notebook in order. The first sets engine and installs the necessary files.\nRun the third step to start the migration. This will take a few minutes.\n\n\n\nIf you're planning to migrate a database larger than 6 GB, we recommend upgrading to at least a Large compute add-on. This will ensure you have the necessary resources to handle the migration efficiently.\n\n\nFor databases smaller than 150 GB, you can increase the size of the disk on paid projects by navigating to Database Settings.\n\n\nIf you're dealing with a database larger than 150 GB, we strongly advise you to contact our support team for assistance in provisioning the required resources and ensuring a smooth migration process.\n\n\nEnterprise#\nContact us if you need more help migrating your project.Edit this page on GitHub\nMigrate from MSSQL to Supabase\nMigrate your Microsoft SQL Server database to Supabase.\nThis guide aims to demonstrate the process of transferring your Microsoft SQL Server database to Supabase's PostgreSQL database. Supabase is a powerful and open-source platform offering a wide range of backend features, including a PostgreSQL database, authentication, instant APIs, edge functions, real-time subscriptions, and storage. Migrating your MSSQL database to Supabase's Postgres enables you to leverage Postgres's capabilities and access all the features you need for your project.\nRetrieve your MSSQL database credentials#\nBefore you begin the migration, you need to collect essential information about your MSSQL database. Follow these steps:\nRetrieve your Supabase host #\nIf you're new to Supabase, create a project.\nMake a note of your password, you will need this later. If you forget it, you can reset it here.\nGo to the Database settings for your project in the Supabase Dashboard.\nUnder Connection Info, note your Host ($SUPABASE_HOST).\n\nMigrate the database#\nThe fastest way to migrate your database is with the Supabase migration tool on\nGoogle Colab.\nAlternatively, you can use pgloader, a flexible and powerful data migration tool that supports a wide range of source database engines, including MySQL and MS SQL, and migrates the data to a Postgres database. For databases using the Postgres engine, we recommend using the pg_dump and psql command line tools, which are included in a full PostgreSQL installation.\nIf you're planning to migrate a database larger than 6 GB, we recommend upgrading to at least a Large compute add-on. This will ensure you have the necessary resources to handle the migration efficiently.\nFor databases smaller than 150 GB, you can increase the size of the disk on paid projects by navigating to Database Settings.\nIf you're dealing with a database larger than 150 GB, we strongly advise you to contact our support team for assistance in provisioning the required resources and ensuring a smooth migration process.\nEnterprise#\nContact us if you need more help migrating your project.\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "38",
    "url": "https://supabase.com/docs/reference/api/introduction",
    "title": "Management API Reference | Supabase Docs",
    "content": "Search docs...\nSearch docs...\n[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nManagement API\nManage your Supabase organizations and projects programmatically.Authentication#All API requests require a Supabase Personal token to be included in the Authorization header: Authorization Bearer <supabase_personal_token>.\nTo generate or manage your API token, visit your account page.\nYour API tokens carry the same privileges as your user account, so be sure to keep it secret._10  curl https://api.supabase.com/v1/projects \\_10  -H \"Authorization: Bearer sbp_bdd0â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢4f23\"All API requests must be authenticated and made over HTTPS.Rate limits#The rate limit for Management API is 60 requests per one minute per user, and applies cumulatively across all requests made with your personal access tokens.If you exceed this limit, all Management API calls for the next minute will be blocked, resulting in a HTTP 429 response.The Management API is subject to our fair-use policy.\nAll resources created via the API are subject to the pricing detailed on our Pricing pages.Additional links\nOpenAPI Docs\nOpenAPI Spec\nReport bugs and issues\nCreates a new SSO providerpost/v1/projects/{ref}/config/auth/sso/providersPath parametersrefRequiredstringProject refDetailsBodytypeRequiredenumAccepted valuesmetadata_xmlOptionalstringmetadata_urlOptionalstringdomainsOptionalArray<string>attribute_mappingOptionalobjectObject schemaResponse codes201403404Response (201)exampleschema{\n  \"id\": \"lorem\",\n  \"saml\": {\n    \"id\": \"lorem\",\n    \"entity_id\": \"lorem\",\n    \"metadata_url\": \"lorem\",\n    \"metadata_xml\": \"lorem\",\n    \"attribute_mapping\": {\n      \"keys\": {\n        \"property1\": {\n          \"default\": {},\n          \"name\": \"lorem\",\n          \"names\": [\n            \"lorem\"\n          ],\n          \"array\": true\n        },\n        \"property2\": {\n          \"default\": {},\n          \"name\": \"lorem\",\n          \"names\": [\n            \"lorem\"\n          ],\n          \"array\": true\n        }\n      }\n    }\n  },\n  \"domains\": [\n    {\n      \"id\": \"lorem\",\n      \"domain\": \"lorem\",\n      \"created_at\": \"lorem\",\n      \"updated_at\": \"lorem\"\n    }\n  ],\n  \"created_at\": \"lorem\",\n  \"updated_at\": \"lorem\"\n}  Removes a SSO provider by its UUIDdelete/v1/projects/{ref}/config/auth/sso/providers/{provider_id}Path parametersrefRequiredstringProject refDetailsprovider_idRequiredstringResponse codes200403404Response (200)exampleschema{\n  \"id\": \"lorem\",\n  \"saml\": {\n    \"id\": \"lorem\",\n    \"entity_id\": \"lorem\",\n    \"metadata_url\": \"lorem\",\n    \"metadata_xml\": \"lorem\",\n    \"attribute_mapping\": {\n      \"keys\": {\n        \"property1\": {\n          \"default\": {},\n          \"name\": \"lorem\",\n          \"names\": [\n            \"lorem\"\n          ],\n          \"array\": true\n        },\n        \"property2\": {\n          \"default\": {},\n          \"name\": \"lorem\",\n          \"names\": [\n            \"lorem\"\n          ],\n          \"array\": true\n        }\n      }\n    }\n  },\n  \"domains\": [\n    {\n      \"id\": \"lorem\",\n      \"domain\": \"lorem\",\n      \"created_at\": \"lorem\",\n      \"updated_at\": \"lorem\"\n    }\n  ],\n  \"created_at\": \"lorem\",\n  \"updated_at\": \"lorem\"\n}  Gets a SSO provider by its UUIDget/v1/projects/{ref}/config/auth/sso/providers/{provider_id}Path parametersrefRequiredstringProject refDetailsprovider_idRequiredstringResponse codes200403404Response (200)exampleschema{\n  \"id\": \"lorem\",\n  \"saml\": {\n    \"id\": \"lorem\",\n    \"entity_id\": \"lorem\",\n    \"metadata_url\": \"lorem\",\n    \"metadata_xml\": \"lorem\",\n    \"attribute_mapping\": {\n      \"keys\": {\n        \"property1\": {\n          \"default\": {},\n          \"name\": \"lorem\",\n          \"names\": [\n            \"lorem\"\n          ],\n          \"array\": true\n        },\n        \"property2\": {\n          \"default\": {},\n          \"name\": \"lorem\",\n          \"names\": [\n            \"lorem\"\n          ],\n          \"array\": true\n        }\n      }\n    }\n  },\n  \"domains\": [\n    {\n      \"id\": \"lorem\",\n      \"domain\": \"lorem\",\n      \"created_at\": \"lorem\",\n      \"updated_at\": \"lorem\"\n    }\n  ],\n  \"created_at\": \"lorem\",\n  \"updated_at\": \"lorem\"\n}  Gets project's auth configget/v1/projects/{ref}/config/authPath parametersrefRequiredstringProject refDetailsResponse codes200403500Response (200)exampleschema{\n  \"api_max_request_duration\": 42,\n  \"db_max_pool_size\": 42,\n  \"jwt_exp\": 42,\n  \"mailer_otp_exp\": 42,\n  \"mailer_otp_length\": 42,\n  \"mfa_max_enrolled_factors\": 42,\n  \"mfa_phone_otp_length\": 42,\n  \"mfa_phone_max_frequency\": 42,\n  \"password_min_length\": 42,\n  \"rate_limit_anonymous_users\": 42,\n  \"rate_limit_email_sent\": 42,\n  \"rate_limit_sms_sent\": 42,\n  \"rate_limit_token_refresh\": 42,\n  \"rate_limit_verify\": 42,\n  \"rate_limit_otp\": 42,\n  \"security_refresh_token_reuse_interval\": 42,\n  \"sessions_inactivity_timeout\": 42,\n  \"sessions_timebox\": 42,\n  \"sms_max_frequency\": 42,\n  \"sms_otp_exp\": 42,\n  \"sms_otp_length\": 42,\n  \"smtp_max_frequency\": 42,\n  \"disable_signup\": true,\n  \"external_anonymous_users_enabled\": true,\n  \"external_apple_additional_client_ids\": \"lorem\",\n  \"external_apple_client_id\": \"lorem\",\n  \"external_apple_enabled\": true,\n  \"external_apple_secret\": \"lorem\",\n  \"external_azure_client_id\": \"lorem\",\n  \"external_azure_enabled\": true,\n  \"external_azure_secret\": \"lorem\",\n  \"external_azure_url\": \"lorem\",\n  \"external_bitbucket_client_id\": \"lorem\",\n  \"external_bitbucket_enabled\": true,\n  \"external_bitbucket_secret\": \"lorem\",\n  \"external_discord_client_id\": \"lorem\",\n  \"external_discord_enabled\": true,\n  \"external_discord_secret\": \"lorem\",\n  \"external_email_enabled\": true,\n  \"external_facebook_client_id\": \"lorem\",\n  \"external_facebook_enabled\": true,\n  \"external_facebook_secret\": \"lorem\",\n  \"external_figma_client_id\": \"lorem\",\n  \"external_figma_enabled\": true,\n  \"external_figma_secret\": \"lorem\",\n  \"external_github_client_id\": \"lorem\",\n  \"external_github_enabled\": true,\n  \"external_github_secret\": \"lorem\",\n  \"external_gitlab_client_id\": \"lorem\",\n  \"external_gitlab_enabled\": true,\n  \"external_gitlab_secret\": \"lorem\",\n  \"external_gitlab_url\": \"lorem\",\n  \"external_google_additional_client_ids\": \"lorem\",\n  \"external_google_client_id\": \"lorem\",\n  \"external_google_enabled\": true,\n  \"external_google_secret\": \"lorem\",\n  \"external_google_skip_nonce_check\": true,\n  \"external_kakao_client_id\": \"lorem\",\n  \"external_kakao_enabled\": true,\n  \"external_kakao_secret\": \"lorem\",\n  \"external_keycloak_client_id\": \"lorem\",\n  \"external_keycloak_enabled\": true,\n  \"external_keycloak_secret\": \"lorem\",\n  \"external_keycloak_url\": \"lorem\",\n  \"external_linkedin_oidc_client_id\": \"lorem\",\n  \"external_linkedin_oidc_enabled\": true,\n  \"external_linkedin_oidc_secret\": \"lorem\",\n  \"external_slack_oidc_client_id\": \"lorem\",\n  \"external_slack_oidc_enabled\": true,\n  \"external_slack_oidc_secret\": \"lorem\",\n  \"external_notion_client_id\": \"lorem\",\n  \"external_notion_enabled\": true,\n  \"external_notion_secret\": \"lorem\",\n  \"external_phone_enabled\": true,\n  \"external_slack_client_id\": \"lorem\",\n  \"external_slack_enabled\": true,\n  \"external_slack_secret\": \"lorem\",\n  \"external_spotify_client_id\": \"lorem\",\n  \"external_spotify_enabled\": true,\n  \"external_spotify_secret\": \"lorem\",\n  \"external_twitch_client_id\": \"lorem\",\n  \"external_twitch_enabled\": true,\n  \"external_twitch_secret\": \"lorem\",\n  \"external_twitter_client_id\": \"lorem\",\n  \"external_twitter_enabled\": true,\n  \"external_twitter_secret\": \"lorem\",\n  \"external_workos_client_id\": \"lorem\",\n  \"external_workos_enabled\": true,\n  \"external_workos_secret\": \"lorem\",\n  \"external_workos_url\": \"lorem\",\n  \"external_zoom_client_id\": \"lorem\",\n  \"external_zoom_enabled\": true,\n  \"external_zoom_secret\": \"lorem\",\n  \"hook_custom_access_token_enabled\": true,\n  \"hook_custom_access_token_uri\": \"lorem\",\n  \"hook_custom_access_token_secrets\": \"lorem\",\n  \"hook_mfa_verification_attempt_enabled\": true,\n  \"hook_mfa_verification_attempt_uri\": \"lorem\",\n  \"hook_mfa_verification_attempt_secrets\": \"lorem\",\n  \"hook_password_verification_attempt_enabled\": true,\n  \"hook_password_verification_attempt_uri\": \"lorem\",\n  \"hook_password_verification_attempt_secrets\": \"lorem\",\n  \"hook_send_sms_enabled\": true,\n  \"hook_send_sms_uri\": \"lorem\",\n  \"hook_send_sms_secrets\": \"lorem\",\n  \"hook_send_email_enabled\": true,\n  \"hook_send_email_uri\": \"lorem\",\n  \"hook_send_email_secrets\": \"lorem\",\n  \"mailer_allow_unverified_email_sign_ins\": true,\n  \"mailer_autoconfirm\": true,\n  \"mailer_secure_email_change_enabled\": true,\n  \"mailer_subjects_confirmation\": \"lorem\",\n  \"mailer_subjects_email_change\": \"lorem\",\n  \"mailer_subjects_invite\": \"lorem\",\n  \"mailer_subjects_magic_link\": \"lorem\",\n  \"mailer_subjects_reauthentication\": \"lorem\",\n  \"mailer_subjects_recovery\": \"lorem\",\n  \"mailer_templates_confirmation_content\": \"lorem\",\n  \"mailer_templates_email_change_content\": \"lorem\",\n  \"mailer_templates_invite_content\": \"lorem\",\n  \"mailer_templates_magic_link_content\": \"lorem\",\n  \"mailer_templates_reauthentication_content\": \"lorem\",\n  \"mailer_templates_recovery_content\": \"lorem\",\n  \"mfa_totp_enroll_enabled\": true,\n  \"mfa_totp_verify_enabled\": true,\n  \"mfa_phone_enroll_enabled\": true,\n  \"mfa_phone_verify_enabled\": true,\n  \"mfa_web_authn_enroll_enabled\": true,\n  \"mfa_web_authn_verify_enabled\": true,\n  \"mfa_phone_template\": \"lorem\",\n  \"password_hibp_enabled\": true,\n  \"password_required_characters\": \"lorem\",\n  \"refresh_token_rotation_enabled\": true,\n  \"saml_enabled\": true,\n  \"saml_external_url\": \"lorem\",\n  \"saml_allow_encrypted_assertions\": true,\n  \"security_captcha_enabled\": true,\n  \"security_captcha_provider\": \"lorem\",\n  \"security_captcha_secret\": \"lorem\",\n  \"security_manual_linking_enabled\": true,\n  \"security_update_password_require_reauthentication\": true,\n  \"sessions_single_per_user\": true,\n  \"sessions_tags\": \"lorem\",\n  \"site_url\": \"lorem\",\n  \"sms_autoconfirm\": true,\n  \"sms_messagebird_access_key\": \"lorem\",\n  \"sms_messagebird_originator\": \"lorem\",\n  \"sms_provider\": \"lorem\",\n  \"sms_template\": \"lorem\",\n  \"sms_test_otp\": \"lorem\",\n  \"sms_test_otp_valid_until\": \"lorem\",\n  \"sms_textlocal_api_key\": \"lorem\",\n  \"sms_textlocal_sender\": \"lorem\",\n  \"sms_twilio_account_sid\": \"lorem\",\n  \"sms_twilio_auth_token\": \"lorem\",\n  \"sms_twilio_content_sid\": \"lorem\",\n  \"sms_twilio_message_service_sid\": \"lorem\",\n  \"sms_twilio_verify_account_sid\": \"lorem\",\n  \"sms_twilio_verify_auth_token\": \"lorem\",\n  \"sms_twilio_verify_message_service_sid\": \"lorem\",\n  \"sms_vonage_api_key\": \"lorem\",\n  \"sms_vonage_api_secret\": \"lorem\",\n  \"sms_vonage_from\": \"lorem\",\n  \"smtp_admin_email\": \"lorem\",\n  \"smtp_host\": \"lorem\",\n  \"smtp_pass\": \"lorem\",\n  \"smtp_port\": \"lorem\",\n  \"smtp_sender_name\": \"lorem\",\n  \"smtp_user\": \"lorem\",\n  \"uri_allow_list\": \"lorem\"\n}  Lists all SSO providersget/v1/projects/{ref}/config/auth/sso/providersPath parametersrefRequiredstringProject refDetailsResponse codes200403404Response (200)exampleschema{\n  \"items\": [\n    {\n      \"id\": \"lorem\",\n      \"saml\": {\n        \"id\": \"lorem\",\n        \"entity_id\": \"lorem\",\n        \"metadata_url\": \"lorem\",\n        \"metadata_xml\": \"lorem\",\n        \"attribute_mapping\": {\n          \"keys\": {\n            \"property1\": {\n              \"default\": {},\n              \"name\": \"lorem\",\n              \"names\": [\n                \"lorem\"\n              ],\n              \"array\": true\n            },\n            \"property2\": {\n              \"default\": {},\n              \"name\": \"lorem\",\n              \"names\": [\n                \"lorem\"\n              ],\n              \"array\": true\n            }\n          }\n        }\n      },\n      \"domains\": [\n        {\n          \"id\": \"lorem\",\n          \"domain\": \"lorem\",\n          \"created_at\": \"lorem\",\n          \"updated_at\": \"lorem\"\n        }\n      ],\n      \"created_at\": \"lorem\",\n      \"updated_at\": \"lorem\"\n    }\n  ]\n}  Updates a SSO provider by its UUIDput/v1/projects/{ref}/config/auth/sso/providers/{provider_id}Path parametersrefRequiredstringProject refDetailsprovider_idRequiredstringBodymetadata_xmlOptionalstringmetadata_urlOptionalstringdomainsOptionalArray<string>attribute_mappingOptionalobjectObject schemaResponse codes200403404Response (200)exampleschema{\n  \"id\": \"lorem\",\n  \"saml\": {\n    \"id\": \"lorem\",\n    \"entity_id\": \"lorem\",\n    \"metadata_url\": \"lorem\",\n    \"metadata_xml\": \"lorem\",\n    \"attribute_mapping\": {\n      \"keys\": {\n        \"property1\": {\n          \"default\": {},\n          \"name\": \"lorem\",\n          \"names\": [\n            \"lorem\"\n          ],\n          \"array\": true\n        },\n        \"property2\": {\n          \"default\": {},\n          \"name\": \"lorem\",\n          \"names\": [\n            \"lorem\"\n          ],\n          \"array\": true\n        }\n      }\n    }\n  },\n  \"domains\": [\n    {\n      \"id\": \"lorem\",\n      \"domain\": \"lorem\",\n      \"created_at\": \"lorem\",\n      \"updated_at\": \"lorem\"\n    }\n  ],\n  \"created_at\": \"lorem\",\n  \"updated_at\": \"lorem\"\n}  Updates a project's auth configpatch/v1/projects/{ref}/config/authPath parametersrefRequiredstringProject refDetailsBodyjwt_expOptionalintegersmtp_max_frequencyOptionalintegermfa_max_enrolled_factorsOptionalintegersessions_timeboxOptionalintegersessions_inactivity_timeoutOptionalintegerrate_limit_anonymous_usersOptionalintegerrate_limit_email_sentOptionalintegerrate_limit_sms_sentOptionalintegerrate_limit_verifyOptionalintegerrate_limit_token_refreshOptionalintegerrate_limit_otpOptionalintegerpassword_min_lengthOptionalintegersecurity_refresh_token_reuse_intervalOptionalintegermailer_otp_expOptionalintegermailer_otp_lengthOptionalintegersms_max_frequencyOptionalintegersms_otp_expOptionalintegersms_otp_lengthOptionalintegerdb_max_pool_sizeOptionalintegerapi_max_request_durationOptionalintegermfa_phone_max_frequencyOptionalintegermfa_phone_otp_lengthOptionalintegersite_urlOptionalstringDetailsdisable_signupOptionalbooleansmtp_admin_emailOptionalstringsmtp_hostOptionalstringsmtp_portOptionalstringsmtp_userOptionalstringsmtp_passOptionalstringsmtp_sender_nameOptionalstringmailer_allow_unverified_email_sign_insOptionalbooleanmailer_autoconfirmOptionalbooleanmailer_subjects_inviteOptionalstringmailer_subjects_confirmationOptionalstringmailer_subjects_recoveryOptionalstringmailer_subjects_email_changeOptionalstringmailer_subjects_magic_linkOptionalstringmailer_subjects_reauthenticationOptionalstringmailer_templates_invite_contentOptionalstringmailer_templates_confirmation_contentOptionalstringmailer_templates_recovery_contentOptionalstringmailer_templates_email_change_contentOptionalstringmailer_templates_magic_link_contentOptionalstringmailer_templates_reauthentication_contentOptionalstringuri_allow_listOptionalstringexternal_anonymous_users_enabledOptionalbooleanexternal_email_enabledOptionalbooleanexternal_phone_enabledOptionalbooleansaml_enabledOptionalbooleansaml_external_urlOptionalstringDetailssecurity_captcha_enabledOptionalbooleansecurity_captcha_providerOptionalstringsecurity_captcha_secretOptionalstringsessions_single_per_userOptionalbooleansessions_tagsOptionalstringDetailsmailer_secure_email_change_enabledOptionalbooleanrefresh_token_rotation_enabledOptionalbooleanpassword_hibp_enabledOptionalbooleanpassword_required_charactersOptionalenumAccepted valuessecurity_manual_linking_enabledOptionalbooleansecurity_update_password_require_reauthenticationOptionalbooleansms_autoconfirmOptionalbooleansms_providerOptionalstringsms_messagebird_access_keyOptionalstringsms_messagebird_originatorOptionalstringsms_test_otpOptionalstringDetailssms_test_otp_valid_untilOptionalstringsms_textlocal_api_keyOptionalstringsms_textlocal_senderOptionalstringsms_twilio_account_sidOptionalstringsms_twilio_auth_tokenOptionalstringsms_twilio_content_sidOptionalstringsms_twilio_message_service_sidOptionalstringsms_twilio_verify_account_sidOptionalstringsms_twilio_verify_auth_tokenOptionalstringsms_twilio_verify_message_service_sidOptionalstringsms_vonage_api_keyOptionalstringsms_vonage_api_secretOptionalstringsms_vonage_fromOptionalstringsms_templateOptionalstringhook_mfa_verification_attempt_enabledOptionalbooleanhook_mfa_verification_attempt_uriOptionalstringhook_mfa_verification_attempt_secretsOptionalstringhook_password_verification_attempt_enabledOptionalbooleanhook_password_verification_attempt_uriOptionalstringhook_password_verification_attempt_secretsOptionalstringhook_custom_access_token_enabledOptionalbooleanhook_custom_access_token_uriOptionalstringhook_custom_access_token_secretsOptionalstringhook_send_sms_enabledOptionalbooleanhook_send_sms_uriOptionalstringhook_send_sms_secretsOptionalstringhook_send_email_enabledOptionalbooleanhook_send_email_uriOptionalstringhook_send_email_secretsOptionalstringexternal_apple_enabledOptionalbooleanexternal_apple_client_idOptionalstringexternal_apple_secretOptionalstringexternal_apple_additional_client_idsOptionalstringexternal_azure_enabledOptionalbooleanexternal_azure_client_idOptionalstringexternal_azure_secretOptionalstringexternal_azure_urlOptionalstringexternal_bitbucket_enabledOptionalbooleanexternal_bitbucket_client_idOptionalstringexternal_bitbucket_secretOptionalstringexternal_discord_enabledOptionalbooleanexternal_discord_client_idOptionalstringexternal_discord_secretOptionalstringexternal_facebook_enabledOptionalbooleanexternal_facebook_client_idOptionalstringexternal_facebook_secretOptionalstringexternal_figma_enabledOptionalbooleanexternal_figma_client_idOptionalstringexternal_figma_secretOptionalstringexternal_github_enabledOptionalbooleanexternal_github_client_idOptionalstringexternal_github_secretOptionalstringexternal_gitlab_enabledOptionalbooleanexternal_gitlab_client_idOptionalstringexternal_gitlab_secretOptionalstringexternal_gitlab_urlOptionalstringexternal_google_enabledOptionalbooleanexternal_google_client_idOptionalstringexternal_google_secretOptionalstringexternal_google_additional_client_idsOptionalstringexternal_google_skip_nonce_checkOptionalbooleanexternal_kakao_enabledOptionalbooleanexternal_kakao_client_idOptionalstringexternal_kakao_secretOptionalstringexternal_keycloak_enabledOptionalbooleanexternal_keycloak_client_idOptionalstringexternal_keycloak_secretOptionalstringexternal_keycloak_urlOptionalstringexternal_linkedin_oidc_enabledOptionalbooleanexternal_linkedin_oidc_client_idOptionalstringexternal_linkedin_oidc_secretOptionalstringexternal_slack_oidc_enabledOptionalbooleanexternal_slack_oidc_client_idOptionalstringexternal_slack_oidc_secretOptionalstringexternal_notion_enabledOptionalbooleanexternal_notion_client_idOptionalstringexternal_notion_secretOptionalstringexternal_slack_enabledOptionalbooleanexternal_slack_client_idOptionalstringexternal_slack_secretOptionalstringexternal_spotify_enabledOptionalbooleanexternal_spotify_client_idOptionalstringexternal_spotify_secretOptionalstringexternal_twitch_enabledOptionalbooleanexternal_twitch_client_idOptionalstringexternal_twitch_secretOptionalstringexternal_twitter_enabledOptionalbooleanexternal_twitter_client_idOptionalstringexternal_twitter_secretOptionalstringexternal_workos_enabledOptionalbooleanexternal_workos_client_idOptionalstringexternal_workos_secretOptionalstringexternal_workos_urlOptionalstringexternal_zoom_enabledOptionalbooleanexternal_zoom_client_idOptionalstringexternal_zoom_secretOptionalstringmfa_totp_enroll_enabledOptionalbooleanmfa_totp_verify_enabledOptionalbooleanmfa_web_authn_enroll_enabledOptionalbooleanmfa_web_authn_verify_enabledOptionalbooleanmfa_phone_enroll_enabledOptionalbooleanmfa_phone_verify_enabledOptionalbooleanmfa_phone_templateOptionalstringResponse codes200403500Response (200)exampleschema{\n  \"api_max_request_duration\": 42,\n  \"db_max_pool_size\": 42,\n  \"jwt_exp\": 42,\n  \"mailer_otp_exp\": 42,\n  \"mailer_otp_length\": 42,\n  \"mfa_max_enrolled_factors\": 42,\n  \"mfa_phone_otp_length\": 42,\n  \"mfa_phone_max_frequency\": 42,\n  \"password_min_length\": 42,\n  \"rate_limit_anonymous_users\": 42,\n  \"rate_limit_email_sent\": 42,\n  \"rate_limit_sms_sent\": 42,\n  \"rate_limit_token_refresh\": 42,\n  \"rate_limit_verify\": 42,\n  \"rate_limit_otp\": 42,\n  \"security_refresh_token_reuse_interval\": 42,\n  \"sessions_inactivity_timeout\": 42,\n  \"sessions_timebox\": 42,\n  \"sms_max_frequency\": 42,\n  \"sms_otp_exp\": 42,\n  \"sms_otp_length\": 42,\n  \"smtp_max_frequency\": 42,\n  \"disable_signup\": true,\n  \"external_anonymous_users_enabled\": true,\n  \"external_apple_additional_client_ids\": \"lorem\",\n  \"external_apple_client_id\": \"lorem\",\n  \"external_apple_enabled\": true,\n  \"external_apple_secret\": \"lorem\",\n  \"external_azure_client_id\": \"lorem\",\n  \"external_azure_enabled\": true,\n  \"external_azure_secret\": \"lorem\",\n  \"external_azure_url\": \"lorem\",\n  \"external_bitbucket_client_id\": \"lorem\",\n  \"external_bitbucket_enabled\": true,\n  \"external_bitbucket_secret\": \"lorem\",\n  \"external_discord_client_id\": \"lorem\",\n  \"external_discord_enabled\": true,\n  \"external_discord_secret\": \"lorem\",\n  \"external_email_enabled\": true,\n  \"external_facebook_client_id\": \"lorem\",\n  \"external_facebook_enabled\": true,\n  \"external_facebook_secret\": \"lorem\",\n  \"external_figma_client_id\": \"lorem\",\n  \"external_figma_enabled\": true,\n  \"external_figma_secret\": \"lorem\",\n  \"external_github_client_id\": \"lorem\",\n  \"external_github_enabled\": true,\n  \"external_github_secret\": \"lorem\",\n  \"external_gitlab_client_id\": \"lorem\",\n  \"external_gitlab_enabled\": true,\n  \"external_gitlab_secret\": \"lorem\",\n  \"external_gitlab_url\": \"lorem\",\n  \"external_google_additional_client_ids\": \"lorem\",\n  \"external_google_client_id\": \"lorem\",\n  \"external_google_enabled\": true,\n  \"external_google_secret\": \"lorem\",\n  \"external_google_skip_nonce_check\": true,\n  \"external_kakao_client_id\": \"lorem\",\n  \"external_kakao_enabled\": true,\n  \"external_kakao_secret\": \"lorem\",\n  \"external_keycloak_client_id\": \"lorem\",\n  \"external_keycloak_enabled\": true,\n  \"external_keycloak_secret\": \"lorem\",\n  \"external_keycloak_url\": \"lorem\",\n  \"external_linkedin_oidc_client_id\": \"lorem\",\n  \"external_linkedin_oidc_enabled\": true,\n  \"external_linkedin_oidc_secret\": \"lorem\",\n  \"external_slack_oidc_client_id\": \"lorem\",\n  \"external_slack_oidc_enabled\": true,\n  \"external_slack_oidc_secret\": \"lorem\",\n  \"external_notion_client_id\": \"lorem\",\n  \"external_notion_enabled\": true,\n  \"external_notion_secret\": \"lorem\",\n  \"external_phone_enabled\": true,\n  \"external_slack_client_id\": \"lorem\",\n  \"external_slack_enabled\": true,\n  \"external_slack_secret\": \"lorem\",\n  \"external_spotify_client_id\": \"lorem\",\n  \"external_spotify_enabled\": true,\n  \"external_spotify_secret\": \"lorem\",\n  \"external_twitch_client_id\": \"lorem\",\n  \"external_twitch_enabled\": true,\n  \"external_twitch_secret\": \"lorem\",\n  \"external_twitter_client_id\": \"lorem\",\n  \"external_twitter_enabled\": true,\n  \"external_twitter_secret\": \"lorem\",\n  \"external_workos_client_id\": \"lorem\",\n  \"external_workos_enabled\": true,\n  \"external_workos_secret\": \"lorem\",\n  \"external_workos_url\": \"lorem\",\n  \"external_zoom_client_id\": \"lorem\",\n  \"external_zoom_enabled\": true,\n  \"external_zoom_secret\": \"lorem\",\n  \"hook_custom_access_token_enabled\": true,\n  \"hook_custom_access_token_uri\": \"lorem\",\n  \"hook_custom_access_token_secrets\": \"lorem\",\n  \"hook_mfa_verification_attempt_enabled\": true,\n  \"hook_mfa_verification_attempt_uri\": \"lorem\",\n  \"hook_mfa_verification_attempt_secrets\": \"lorem\",\n  \"hook_password_verification_attempt_enabled\": true,\n  \"hook_password_verification_attempt_uri\": \"lorem\",\n  \"hook_password_verification_attempt_secrets\": \"lorem\",\n  \"hook_send_sms_enabled\": true,\n  \"hook_send_sms_uri\": \"lorem\",\n  \"hook_send_sms_secrets\": \"lorem\",\n  \"hook_send_email_enabled\": true,\n  \"hook_send_email_uri\": \"lorem\",\n  \"hook_send_email_secrets\": \"lorem\",\n  \"mailer_allow_unverified_email_sign_ins\": true,\n  \"mailer_autoconfirm\": true,\n  \"mailer_secure_email_change_enabled\": true,\n  \"mailer_subjects_confirmation\": \"lorem\",\n  \"mailer_subjects_email_change\": \"lorem\",\n  \"mailer_subjects_invite\": \"lorem\",\n  \"mailer_subjects_magic_link\": \"lorem\",\n  \"mailer_subjects_reauthentication\": \"lorem\",\n  \"mailer_subjects_recovery\": \"lorem\",\n  \"mailer_templates_confirmation_content\": \"lorem\",\n  \"mailer_templates_email_change_content\": \"lorem\",\n  \"mailer_templates_invite_content\": \"lorem\",\n  \"mailer_templates_magic_link_content\": \"lorem\",\n  \"mailer_templates_reauthentication_content\": \"lorem\",\n  \"mailer_templates_recovery_content\": \"lorem\",\n  \"mfa_totp_enroll_enabled\": true,\n  \"mfa_totp_verify_enabled\": true,\n  \"mfa_phone_enroll_enabled\": true,\n  \"mfa_phone_verify_enabled\": true,\n  \"mfa_web_authn_enroll_enabled\": true,\n  \"mfa_web_authn_verify_enabled\": true,\n  \"mfa_phone_template\": \"lorem\",\n  \"password_hibp_enabled\": true,\n  \"password_required_characters\": \"lorem\",\n  \"refresh_token_rotation_enabled\": true,\n  \"saml_enabled\": true,\n  \"saml_external_url\": \"lorem\",\n  \"saml_allow_encrypted_assertions\": true,\n  \"security_captcha_enabled\": true,\n  \"security_captcha_provider\": \"lorem\",\n  \"security_captcha_secret\": \"lorem\",\n  \"security_manual_linking_enabled\": true,\n  \"security_update_password_require_reauthentication\": true,\n  \"sessions_single_per_user\": true,\n  \"sessions_tags\": \"lorem\",\n  \"site_url\": \"lorem\",\n  \"sms_autoconfirm\": true,\n  \"sms_messagebird_access_key\": \"lorem\",\n  \"sms_messagebird_originator\": \"lorem\",\n  \"sms_provider\": \"lorem\",\n  \"sms_template\": \"lorem\",\n  \"sms_test_otp\": \"lorem\",\n  \"sms_test_otp_valid_until\": \"lorem\",\n  \"sms_textlocal_api_key\": \"lorem\",\n  \"sms_textlocal_sender\": \"lorem\",\n  \"sms_twilio_account_sid\": \"lorem\",\n  \"sms_twilio_auth_token\": \"lorem\",\n  \"sms_twilio_content_sid\": \"lorem\",\n  \"sms_twilio_message_service_sid\": \"lorem\",\n  \"sms_twilio_verify_account_sid\": \"lorem\",\n  \"sms_twilio_verify_auth_token\": \"lorem\",\n  \"sms_twilio_verify_message_service_sid\": \"lorem\",\n  \"sms_vonage_api_key\": \"lorem\",\n  \"sms_vonage_api_secret\": \"lorem\",\n  \"sms_vonage_from\": \"lorem\",\n  \"smtp_admin_email\": \"lorem\",\n  \"smtp_host\": \"lorem\",\n  \"smtp_pass\": \"lorem\",\n  \"smtp_port\": \"lorem\",\n  \"smtp_sender_name\": \"lorem\",\n  \"smtp_user\": \"lorem\",\n  \"uri_allow_list\": \"lorem\"\n}  Disables project's readonly mode for the next 15 minutespost/v1/projects/{ref}/readonly/temporary-disablePath parametersrefRequiredstringProject refDetailsResponse codes201500Response (201)schema{}  [Beta] Enables Database Webhooks on the projectpost/v1/projects/{ref}/database/webhooks/enablePath parametersrefRequiredstringProject refDetailsResponse codes201403500Response (201)schema{}  Generate TypeScript typesget/v1/projects/{ref}/types/typescriptReturns the TypeScript types of your schema for use with supabase-js.Path parametersrefRequiredstringProject refDetailsQuery parametersincluded_schemasOptionalstringResponse codes200403500Response (200)exampleschema{\n  \"types\": \"lorem\"\n}  Gets a specific SQL snippetget/v1/snippets/{id}Path parametersidRequiredstringResponse codes200500Response (200)exampleschema{\n  \"id\": \"lorem\",\n  \"inserted_at\": \"lorem\",\n  \"updated_at\": \"lorem\",\n  \"type\": \"sql\",\n  \"visibility\": \"user\",\n  \"name\": \"lorem\",\n  \"description\": \"lorem\",\n  \"project\": {\n    \"id\": 42,\n    \"name\": \"lorem\"\n  },\n  \"owner\": {\n    \"id\": 42,\n    \"username\": \"lorem\"\n  },\n  \"updated_by\": {\n    \"id\": 42,\n    \"username\": \"lorem\"\n  },\n  \"content\": {\n    \"favorite\": true,\n    \"schema_version\": \"lorem\",\n    \"sql\": \"lorem\"\n  }\n}  Gets project's Postgres configget/v1/projects/{ref}/config/database/postgresPath parametersrefRequiredstringProject refDetailsResponse codes200500Response (200)exampleschema{\n  \"effective_cache_size\": \"lorem\",\n  \"logical_decoding_work_mem\": \"lorem\",\n  \"maintenance_work_mem\": \"lorem\",\n  \"max_connections\": 1,\n  \"max_locks_per_transaction\": 10,\n  \"max_parallel_maintenance_workers\": 0,\n  \"max_parallel_workers\": 0,\n  \"max_parallel_workers_per_gather\": 0,\n  \"max_replication_slots\": 42,\n  \"max_slot_wal_keep_size\": \"lorem\",\n  \"max_standby_archive_delay\": \"lorem\",\n  \"max_standby_streaming_delay\": \"lorem\",\n  \"max_wal_size\": \"lorem\",\n  \"max_wal_senders\": 42,\n  \"max_worker_processes\": 0,\n  \"shared_buffers\": \"lorem\",\n  \"statement_timeout\": \"lorem\",\n  \"track_commit_timestamp\": true,\n  \"wal_keep_size\": \"lorem\",\n  \"wal_sender_timeout\": \"lorem\",\n  \"work_mem\": \"lorem\",\n  \"session_replication_role\": \"origin\"\n}  Get project's pgbouncer configget/v1/projects/{ref}/config/database/pgbouncerPath parametersrefRequiredstringProject refDetailsResponse codes200500Response (200)exampleschema{\n  \"pool_mode\": \"transaction\",\n  \"default_pool_size\": 42,\n  \"ignore_startup_parameters\": \"lorem\",\n  \"max_client_conn\": 42,\n  \"connection_string\": \"lorem\"\n}  Returns project's readonly mode statusget/v1/projects/{ref}/readonlyPath parametersrefRequiredstringProject refDetailsResponse codes200500Response (200)exampleschema{\n  \"enabled\": true,\n  \"override_enabled\": true,\n  \"override_active_until\": \"lorem\"\n}  [Beta] Get project's SSL enforcement configuration.get/v1/projects/{ref}/ssl-enforcementPath parametersrefRequiredstringProject refDetailsResponse codes200403500Response (200)exampleschema{\n  \"currentConfig\": {\n    \"database\": true\n  },\n  \"appliedSuccessfully\": true\n}  Gets project's supavisor configget/v1/projects/{ref}/config/database/poolerPath parametersrefRequiredstringProject refDetailsResponse codes200500Response (200)exampleschema[\n  {\n    \"db_port\": 42,\n    \"default_pool_size\": 42,\n    \"max_client_conn\": 42,\n    \"identifier\": \"lorem\",\n    \"database_type\": \"PRIMARY\",\n    \"is_using_scram_auth\": true,\n    \"db_user\": \"lorem\",\n    \"db_host\": \"lorem\",\n    \"db_name\": \"lorem\",\n    \"connectionString\": \"lorem\",\n    \"pool_mode\": \"transaction\"\n  }\n]  Lists all backupsget/v1/projects/{ref}/database/backupsPath parametersrefRequiredstringProject refDetailsResponse codes200500Response (200)exampleschema{\n  \"region\": \"lorem\",\n  \"walg_enabled\": true,\n  \"pitr_enabled\": true,\n  \"backups\": [\n    {\n      \"status\": \"COMPLETED\",\n      \"is_physical_backup\": true,\n      \"inserted_at\": \"lorem\"\n    }\n  ],\n  \"physical_backup_data\": {\n    \"earliest_physical_backup_date_unix\": 42,\n    \"latest_physical_backup_date_unix\": 42\n  }\n}  Lists SQL snippets for the logged in userget/v1/snippetsQuery parametersproject_refOptionalstringResponse codes200500Response (200)exampleschema{\n  \"data\": [\n    {\n      \"id\": \"lorem\",\n      \"inserted_at\": \"lorem\",\n      \"updated_at\": \"lorem\",\n      \"type\": \"sql\",\n      \"visibility\": \"user\",\n      \"name\": \"lorem\",\n      \"description\": \"lorem\",\n      \"project\": {\n        \"id\": 42,\n        \"name\": \"lorem\"\n      },\n      \"owner\": {\n        \"id\": 42,\n        \"username\": \"lorem\"\n      },\n      \"updated_by\": {\n        \"id\": 42,\n        \"username\": \"lorem\"\n      }\n    }\n  ]\n}  [Beta] Remove a read replicapost/v1/projects/{ref}/read-replicas/removePath parametersrefRequiredstringProject refDetailsBodydatabase_identifierRequiredstringResponse codes201403500Response (201)schema{}  Restores a PITR backup for a databasepost/v1/projects/{ref}/database/backups/restore-pitrPath parametersrefRequiredstringProject refDetailsBodyrecovery_time_target_unixRequiredintegerResponse codes201Response (201)schema{}  [Beta] Run sql querypost/v1/projects/{ref}/database/queryPath parametersrefRequiredstringProject refDetailsBodyqueryRequiredstringResponse codes201403500Response (201)exampleschema{}  [Beta] Set up a read replicapost/v1/projects/{ref}/read-replicas/setupPath parametersrefRequiredstringProject refDetailsBodyread_replica_regionRequiredenumAccepted valuesResponse codes201403500Response (201)schema{}  Updates project's Postgres configput/v1/projects/{ref}/config/database/postgresPath parametersrefRequiredstringProject refDetailsBodyeffective_cache_sizeOptionalstringlogical_decoding_work_memOptionalstringmaintenance_work_memOptionalstringmax_connectionsOptionalintegermax_locks_per_transactionOptionalintegermax_parallel_maintenance_workersOptionalintegermax_parallel_workersOptionalintegermax_parallel_workers_per_gatherOptionalintegermax_replication_slotsOptionalintegermax_slot_wal_keep_sizeOptionalstringmax_standby_archive_delayOptionalstringmax_standby_streaming_delayOptionalstringmax_wal_sizeOptionalstringmax_wal_sendersOptionalintegermax_worker_processesOptionalintegershared_buffersOptionalstringstatement_timeoutOptionalstringtrack_commit_timestampOptionalbooleanwal_keep_sizeOptionalstringwal_sender_timeoutOptionalstringwork_memOptionalstringrestart_databaseOptionalbooleansession_replication_roleOptionalenumAccepted valuesResponse codes200403500Response (200)exampleschema{\n  \"effective_cache_size\": \"lorem\",\n  \"logical_decoding_work_mem\": \"lorem\",\n  \"maintenance_work_mem\": \"lorem\",\n  \"max_connections\": 1,\n  \"max_locks_per_transaction\": 10,\n  \"max_parallel_maintenance_workers\": 0,\n  \"max_parallel_workers\": 0,\n  \"max_parallel_workers_per_gather\": 0,\n  \"max_replication_slots\": 42,\n  \"max_slot_wal_keep_size\": \"lorem\",\n  \"max_standby_archive_delay\": \"lorem\",\n  \"max_standby_streaming_delay\": \"lorem\",\n  \"max_wal_size\": \"lorem\",\n  \"max_wal_senders\": 42,\n  \"max_worker_processes\": 0,\n  \"shared_buffers\": \"lorem\",\n  \"statement_timeout\": \"lorem\",\n  \"track_commit_timestamp\": true,\n  \"wal_keep_size\": \"lorem\",\n  \"wal_sender_timeout\": \"lorem\",\n  \"work_mem\": \"lorem\",\n  \"session_replication_role\": \"origin\"\n}  [Beta] Update project's SSL enforcement configuration.put/v1/projects/{ref}/ssl-enforcementPath parametersrefRequiredstringProject refDetailsBodyrequestedConfigRequiredobjectObject schemaResponse codes200403500Response (200)exampleschema{\n  \"currentConfig\": {\n    \"database\": true\n  },\n  \"appliedSuccessfully\": true\n}  Updates project's supavisor configpatch/v1/projects/{ref}/config/database/poolerPath parametersrefRequiredstringProject refDetailsBodydefault_pool_sizeOptionalintegerpool_modeOptionalDeprecatedenumAccepted valuesResponse codes200403500Response (200)exampleschema{\n  \"default_pool_size\": 42,\n  \"pool_mode\": \"transaction\"\n}  [Beta] Activates a custom hostname for a project.post/v1/projects/{ref}/custom-hostname/activatePath parametersrefRequiredstringProject refDetailsResponse codes201403500Response (201)exampleschema{\n  \"status\": \"1_not_started\",\n  \"custom_hostname\": \"lorem\",\n  \"data\": {\n    \"success\": true,\n    \"errors\": [\n      {}\n    ],\n    \"messages\": [\n      {}\n    ],\n    \"result\": {\n      \"id\": \"lorem\",\n      \"hostname\": \"lorem\",\n      \"ssl\": {\n        \"status\": \"lorem\",\n        \"validation_records\": [\n          {\n            \"txt_name\": \"lorem\",\n            \"txt_value\": \"lorem\"\n          }\n        ],\n        \"validation_errors\": [\n          {\n            \"message\": \"lorem\"\n          }\n        ]\n      },\n      \"ownership_verification\": {\n        \"type\": \"lorem\",\n        \"name\": \"lorem\",\n        \"value\": \"lorem\"\n      },\n      \"custom_origin_server\": \"lorem\",\n      \"verification_errors\": [\n        \"lorem\"\n      ],\n      \"status\": \"lorem\"\n    }\n  }\n}  [Beta] Activates a vanity subdomain for a project.post/v1/projects/{ref}/vanity-subdomain/activatePath parametersrefRequiredstringProject refDetailsBodyvanity_subdomainRequiredstringResponse codes201403500Response (201)exampleschema{\n  \"custom_domain\": \"lorem\"\n}  [Beta] Checks vanity subdomain availabilitypost/v1/projects/{ref}/vanity-subdomain/check-availabilityPath parametersrefRequiredstringProject refDetailsBodyvanity_subdomainRequiredstringResponse codes201403500Response (201)exampleschema{\n  \"available\": true\n}  [Beta] Deletes a project's vanity subdomain configurationdelete/v1/projects/{ref}/vanity-subdomainPath parametersrefRequiredstringProject refDetailsResponse codes200403500Response (200)schema{}  [Beta] Gets project's custom hostname configget/v1/projects/{ref}/custom-hostnamePath parametersrefRequiredstringProject refDetailsResponse codes200403500Response (200)exampleschema{\n  \"status\": \"1_not_started\",\n  \"custom_hostname\": \"lorem\",\n  \"data\": {\n    \"success\": true,\n    \"errors\": [\n      {}\n    ],\n    \"messages\": [\n      {}\n    ],\n    \"result\": {\n      \"id\": \"lorem\",\n      \"hostname\": \"lorem\",\n      \"ssl\": {\n        \"status\": \"lorem\",\n        \"validation_records\": [\n          {\n            \"txt_name\": \"lorem\",\n            \"txt_value\": \"lorem\"\n          }\n        ],\n        \"validation_errors\": [\n          {\n            \"message\": \"lorem\"\n          }\n        ]\n      },\n      \"ownership_verification\": {\n        \"type\": \"lorem\",\n        \"name\": \"lorem\",\n        \"value\": \"lorem\"\n      },\n      \"custom_origin_server\": \"lorem\",\n      \"verification_errors\": [\n        \"lorem\"\n      ],\n      \"status\": \"lorem\"\n    }\n  }\n}  [Beta] Gets current vanity subdomain configget/v1/projects/{ref}/vanity-subdomainPath parametersrefRequiredstringProject refDetailsResponse codes200403500Response (200)exampleschema{\n  \"status\": \"not-used\",\n  \"custom_domain\": \"lorem\"\n}  [Beta] Updates project's custom hostname configurationpost/v1/projects/{ref}/custom-hostname/initializePath parametersrefRequiredstringProject refDetailsBodycustom_hostnameRequiredstringResponse codes201403500Response (201)exampleschema{\n  \"status\": \"1_not_started\",\n  \"custom_hostname\": \"lorem\",\n  \"data\": {\n    \"success\": true,\n    \"errors\": [\n      {}\n    ],\n    \"messages\": [\n      {}\n    ],\n    \"result\": {\n      \"id\": \"lorem\",\n      \"hostname\": \"lorem\",\n      \"ssl\": {\n        \"status\": \"lorem\",\n        \"validation_records\": [\n          {\n            \"txt_name\": \"lorem\",\n            \"txt_value\": \"lorem\"\n          }\n        ],\n        \"validation_errors\": [\n          {\n            \"message\": \"lorem\"\n          }\n        ]\n      },\n      \"ownership_verification\": {\n        \"type\": \"lorem\",\n        \"name\": \"lorem\",\n        \"value\": \"lorem\"\n      },\n      \"custom_origin_server\": \"lorem\",\n      \"verification_errors\": [\n        \"lorem\"\n      ],\n      \"status\": \"lorem\"\n    }\n  }\n}  [Beta] Attempts to verify the DNS configuration for project's custom hostname configurationpost/v1/projects/{ref}/custom-hostname/reverifyPath parametersrefRequiredstringProject refDetailsResponse codes201403500Response (201)exampleschema{\n  \"status\": \"1_not_started\",\n  \"custom_hostname\": \"lorem\",\n  \"data\": {\n    \"success\": true,\n    \"errors\": [\n      {}\n    ],\n    \"messages\": [\n      {}\n    ],\n    \"result\": {\n      \"id\": \"lorem\",\n      \"hostname\": \"lorem\",\n      \"ssl\": {\n        \"status\": \"lorem\",\n        \"validation_records\": [\n          {\n            \"txt_name\": \"lorem\",\n            \"txt_value\": \"lorem\"\n          }\n        ],\n        \"validation_errors\": [\n          {\n            \"message\": \"lorem\"\n          }\n        ]\n      },\n      \"ownership_verification\": {\n        \"type\": \"lorem\",\n        \"name\": \"lorem\",\n        \"value\": \"lorem\"\n      },\n      \"custom_origin_server\": \"lorem\",\n      \"verification_errors\": [\n        \"lorem\"\n      ],\n      \"status\": \"lorem\"\n    }\n  }\n}  Create a functionpost/v1/projects/{ref}/functionsCreates a function and adds it to the specified project.Path parametersrefRequiredstringProject refDetailsQuery parametersslugOptionalstringDetailsnameOptionalstringverify_jwtOptionalbooleanimport_mapOptionalbooleanentrypoint_pathOptionalstringimport_map_pathOptionalstringBodyslugRequiredstringDetailsnameRequiredstringbodyRequiredstringverify_jwtOptionalbooleanslugRequiredstringDetailsnameRequiredstringbodyRequiredstringverify_jwtOptionalbooleanResponse codes201403500Response (201)exampleschema{\n  \"version\": 42,\n  \"created_at\": 42,\n  \"updated_at\": 42,\n  \"id\": \"lorem\",\n  \"slug\": \"lorem\",\n  \"name\": \"lorem\",\n  \"status\": \"ACTIVE\",\n  \"verify_jwt\": true,\n  \"import_map\": true,\n  \"entrypoint_path\": \"lorem\",\n  \"import_map_path\": \"lorem\"\n}  Delete a functiondelete/v1/projects/{ref}/functions/{function_slug}Deletes a function with the specified slug from the specified project.Path parametersrefRequiredstringProject refDetailsfunction_slugRequiredstringFunction slugDetailsResponse codes200403500Response (200)schema{}  Retrieve a functionget/v1/projects/{ref}/functions/{function_slug}Retrieves a function with the specified slug and project.Path parametersrefRequiredstringProject refDetailsfunction_slugRequiredstringFunction slugDetailsResponse codes200403500Response (200)exampleschema{\n  \"version\": 42,\n  \"created_at\": 42,\n  \"updated_at\": 42,\n  \"id\": \"lorem\",\n  \"slug\": \"lorem\",\n  \"name\": \"lorem\",\n  \"status\": \"ACTIVE\",\n  \"verify_jwt\": true,\n  \"import_map\": true,\n  \"entrypoint_path\": \"lorem\",\n  \"import_map_path\": \"lorem\"\n}  Retrieve a function bodyget/v1/projects/{ref}/functions/{function_slug}/bodyRetrieves a function body for the specified slug and project.Path parametersrefRequiredstringProject refDetailsfunction_slugRequiredstringFunction slugDetailsResponse codes200403500Response (200)schema{}  List all functionsget/v1/projects/{ref}/functionsReturns all functions you've previously added to the specified project.Path parametersrefRequiredstringProject refDetailsResponse codes200403500Response (200)exampleschema[\n  {\n    \"version\": 42,\n    \"created_at\": 42,\n    \"updated_at\": 42,\n    \"id\": \"lorem\",\n    \"slug\": \"lorem\",\n    \"name\": \"lorem\",\n    \"status\": \"ACTIVE\",\n    \"verify_jwt\": true,\n    \"import_map\": true,\n    \"entrypoint_path\": \"lorem\",\n    \"import_map_path\": \"lorem\"\n  }\n]  Update a functionpatch/v1/projects/{ref}/functions/{function_slug}Updates a function with the specified slug and project.Path parametersrefRequiredstringProject refDetailsfunction_slugRequiredstringFunction slugDetailsQuery parametersslugOptionalstringDetailsnameOptionalstringverify_jwtOptionalbooleanimport_mapOptionalbooleanentrypoint_pathOptionalstringimport_map_pathOptionalstringBodynameOptionalstringbodyOptionalstringverify_jwtOptionalbooleannameOptionalstringbodyOptionalstringverify_jwtOptionalbooleanResponse codes200403500Response (200)exampleschema{\n  \"version\": 42,\n  \"created_at\": 42,\n  \"updated_at\": 42,\n  \"id\": \"lorem\",\n  \"slug\": \"lorem\",\n  \"name\": \"lorem\",\n  \"status\": \"ACTIVE\",\n  \"verify_jwt\": true,\n  \"import_map\": true,\n  \"entrypoint_path\": \"lorem\",\n  \"import_map_path\": \"lorem\"\n}  Create a database branchpost/v1/projects/{ref}/branchesCreates a database branch from the specified project.Path parametersrefRequiredstringProject refDetailsBodydesired_instance_sizeOptionalenumAccepted valuesrelease_channelOptionalenumAccepted valuespostgres_engineOptionalenumAccepted valuesbranch_nameRequiredstringgit_branchOptionalstringpersistentOptionalbooleanregionOptionalstringResponse codes201500Response (201)exampleschema{\n  \"pr_number\": 42,\n  \"latest_check_run_id\": 42,\n  \"id\": \"lorem\",\n  \"name\": \"lorem\",\n  \"project_ref\": \"lorem\",\n  \"parent_project_ref\": \"lorem\",\n  \"is_default\": true,\n  \"git_branch\": \"lorem\",\n  \"reset_on_push\": true,\n  \"persistent\": true,\n  \"status\": \"CREATING_PROJECT\",\n  \"created_at\": \"lorem\",\n  \"updated_at\": \"lorem\"\n}  Delete a database branchdelete/v1/branches/{branch_id}Deletes the specified database branchPath parametersbranch_idRequiredstringBranch IDResponse codes200500Response (200)exampleschema{\n  \"message\": \"lorem\"\n}  Disables preview branchingdelete/v1/projects/{ref}/branchesDisables preview branching for the specified projectPath parametersrefRequiredstringProject refDetailsResponse codes200500Response (200)schema{}  Get database branch configget/v1/branches/{branch_id}Fetches configurations of the specified database branchPath parametersbranch_idRequiredstringBranch IDResponse codes200500Response (200)exampleschema{\n  \"db_port\": 42,\n  \"ref\": \"lorem\",\n  \"postgres_version\": \"lorem\",\n  \"postgres_engine\": \"lorem\",\n  \"release_channel\": \"lorem\",\n  \"status\": \"ACTIVE_HEALTHY\",\n  \"db_host\": \"lorem\",\n  \"db_user\": \"lorem\",\n  \"db_pass\": \"lorem\",\n  \"jwt_secret\": \"lorem\"\n}  List all database branchesget/v1/projects/{ref}/branchesReturns all database branches of the specified project.Path parametersrefRequiredstringProject refDetailsResponse codes200500Response (200)exampleschema[\n  {\n    \"pr_number\": 42,\n    \"latest_check_run_id\": 42,\n    \"id\": \"lorem\",\n    \"name\": \"lorem\",\n    \"project_ref\": \"lorem\",\n    \"parent_project_ref\": \"lorem\",\n    \"is_default\": true,\n    \"git_branch\": \"lorem\",\n    \"reset_on_push\": true,\n    \"persistent\": true,\n    \"status\": \"CREATING_PROJECT\",\n    \"created_at\": \"lorem\",\n    \"updated_at\": \"lorem\"\n  }\n]  Resets a database branchpost/v1/branches/{branch_id}/resetResets the specified database branchPath parametersbranch_idRequiredstringBranch IDResponse codes201500Response (201)exampleschema{\n  \"workflow_run_id\": \"lorem\",\n  \"message\": \"lorem\"\n}  Update database branch configpatch/v1/branches/{branch_id}Updates the configuration of the specified database branchPath parametersbranch_idRequiredstringBranch IDBodybranch_nameOptionalstringgit_branchOptionalstringreset_on_pushOptionalbooleanpersistentOptionalbooleanstatusOptionalenumAccepted valuesResponse codes200500Response (200)exampleschema{\n  \"pr_number\": 42,\n  \"latest_check_run_id\": 42,\n  \"id\": \"lorem\",\n  \"name\": \"lorem\",\n  \"project_ref\": \"lorem\",\n  \"parent_project_ref\": \"lorem\",\n  \"is_default\": true,\n  \"git_branch\": \"lorem\",\n  \"reset_on_push\": true,\n  \"persistent\": true,\n  \"status\": \"CREATING_PROJECT\",\n  \"created_at\": \"lorem\",\n  \"updated_at\": \"lorem\"\n}  [Beta] Authorize user through oauthget/v1/oauth/authorizeQuery parametersclient_idRequiredstringresponse_typeRequiredenumAccepted valuesredirect_uriRequiredstringscopeOptionalstringstateOptionalstringresponse_modeOptionalstringcode_challengeOptionalstringcode_challenge_methodOptionalenumAccepted valuesResponse codes303[Beta] Exchange auth code for user's access and refresh tokenpost/v1/oauth/tokenBodygrant_typeRequiredenumAccepted valuesclient_idRequiredstringclient_secretRequiredstringcodeOptionalstringcode_verifierOptionalstringredirect_uriOptionalstringrefresh_tokenOptionalstringResponse codes201Response (201)exampleschema{\n  \"expires_in\": 42,\n  \"token_type\": \"Bearer\",\n  \"access_token\": \"lorem\",\n  \"refresh_token\": \"lorem\"\n}  Create an organizationpost/v1/organizationsBodynameRequiredstringResponse codes201500Response (201)exampleschema{\n  \"id\": \"lorem\",\n  \"name\": \"lorem\"\n}  Gets information about the organizationget/v1/organizations/{slug}Path parametersslugRequiredstringResponse codes200Response (200)exampleschema{\n  \"plan\": \"free\",\n  \"opt_in_tags\": [\n    \"AI_SQL_GENERATOR_OPT_IN\"\n  ],\n  \"allowed_release_channels\": [\n    \"internal\"\n  ],\n  \"id\": \"lorem\",\n  \"name\": \"lorem\"\n}  List all organizationsget/v1/organizationsReturns a list of organizations that you currently belong to.Response codes200500Response (200)exampleschema[\n  {\n    \"id\": \"lorem\",\n    \"name\": \"lorem\"\n  }\n]  List members of an organizationget/v1/organizations/{slug}/membersPath parametersslugRequiredstringResponse codes200Response (200)exampleschema[\n  {\n    \"user_id\": \"lorem\",\n    \"user_name\": \"lorem\",\n    \"email\": \"lorem\",\n    \"role_name\": \"lorem\",\n    \"mfa_enabled\": true\n  }\n]  Create a projectpost/v1/projectsBodydb_passRequiredstringnameRequiredstringorganization_idRequiredstringplanOptionalDeprecatedenumAccepted valuesregionRequiredenumAccepted valueskps_enabledOptionalDeprecatedbooleandesired_instance_sizeOptionalenumAccepted valuestemplate_urlOptionalstringrelease_channelOptionalenumAccepted valuespostgres_engineOptionalenumAccepted valuesResponse codes201Response (201)exampleschema{\n  \"id\": \"lorem\",\n  \"organization_id\": \"lorem\",\n  \"name\": \"lorem\",\n  \"region\": \"us-east-1\",\n  \"created_at\": \"2023-03-29T16:32:59Z\",\n  \"database\": {\n    \"host\": \"lorem\",\n    \"version\": \"lorem\",\n    \"postgres_engine\": \"lorem\",\n    \"release_channel\": \"lorem\"\n  },\n  \"status\": \"ACTIVE_HEALTHY\"\n}  Deletes the given projectdelete/v1/projects/{ref}Path parametersrefRequiredstringProject refDetailsResponse codes200403Response (200)exampleschema{\n  \"id\": 42,\n  \"ref\": \"lorem\",\n  \"name\": \"lorem\"\n}  [Beta] Remove network bans.delete/v1/projects/{ref}/network-bansPath parametersrefRequiredstringProject refDetailsBodyipv4_addressesRequiredArray<string>Response codes200403500Response (200)schema{}  [Beta] Gets project's network restrictionsget/v1/projects/{ref}/network-restrictionsPath parametersrefRequiredstringProject refDetailsResponse codes200403500Response (200)exampleschema{\n  \"entitlement\": \"disallowed\",\n  \"config\": {\n    \"dbAllowedCidrs\": [\n      \"lorem\"\n    ],\n    \"dbAllowedCidrsV6\": [\n      \"lorem\"\n    ]\n  },\n  \"old_config\": {\n    \"dbAllowedCidrs\": [\n      \"lorem\"\n    ],\n    \"dbAllowedCidrsV6\": [\n      \"lorem\"\n    ]\n  },\n  \"status\": \"stored\"\n}  [Beta] Returns the project's eligibility for upgradesget/v1/projects/{ref}/upgrade/eligibilityPath parametersrefRequiredstringProject refDetailsResponse codes200403500Response (200)exampleschema{\n  \"current_app_version_release_channel\": \"internal\",\n  \"duration_estimate_hours\": 42,\n  \"eligible\": true,\n  \"current_app_version\": \"lorem\",\n  \"latest_app_version\": \"lorem\",\n  \"target_upgrade_versions\": [\n    {\n      \"postgres_version\": \"15\",\n      \"release_channel\": \"internal\",\n      \"app_version\": \"lorem\"\n    }\n  ],\n  \"potential_breaking_changes\": [\n    \"lorem\"\n  ],\n  \"legacy_auth_custom_roles\": [\n    \"lorem\"\n  ],\n  \"extension_dependent_objects\": [\n    \"lorem\"\n  ]\n}  [Beta] Gets the latest status of the project's upgradeget/v1/projects/{ref}/upgrade/statusPath parametersrefRequiredstringProject refDetailsQuery parameterstracking_idOptionalstringResponse codes200403500Response (200)exampleschema{\n  \"databaseUpgradeStatus\": {\n    \"target_version\": 42,\n    \"status\": 0,\n    \"initiated_at\": \"lorem\",\n    \"latest_status_at\": \"lorem\",\n    \"error\": \"1_upgraded_instance_launch_failed\",\n    \"progress\": \"0_requested\"\n  }\n}  Gets a specific project that belongs to the authenticated userget/v1/projects/{ref}Path parametersrefRequiredstringProject refDetailsResponse codes200500Response (200)exampleschema{\n  \"id\": \"lorem\",\n  \"organization_id\": \"lorem\",\n  \"name\": \"lorem\",\n  \"region\": \"us-east-1\",\n  \"created_at\": \"2023-03-29T16:32:59Z\",\n  \"database\": {\n    \"host\": \"lorem\",\n    \"version\": \"lorem\",\n    \"postgres_engine\": \"lorem\",\n    \"release_channel\": \"lorem\"\n  },\n  \"status\": \"ACTIVE_HEALTHY\"\n}  Gets project's service health statusget/v1/projects/{ref}/healthPath parametersrefRequiredstringProject refDetailsQuery parameterstimeout_msOptionalintegerservicesRequiredArray<enum>Response codes200403500Response (200)exampleschema[\n  {\n    \"info\": {\n      \"name\": \"GoTrue\"\n    },\n    \"name\": \"auth\",\n    \"healthy\": true,\n    \"status\": \"COMING_UP\",\n    \"error\": \"lorem\"\n  }\n]  [Beta] Gets project's network banspost/v1/projects/{ref}/network-bans/retrievePath parametersrefRequiredstringProject refDetailsResponse codes201403500Response (201)exampleschema{\n  \"banned_ipv4_addresses\": [\n    \"lorem\"\n  ]\n}  List all projectsget/v1/projectsReturns a list of all projects you've previously created.Response codes200Response (200)exampleschema[\n  {\n    \"id\": \"lorem\",\n    \"organization_id\": \"lorem\",\n    \"name\": \"lorem\",\n    \"region\": \"us-east-1\",\n    \"created_at\": \"2023-03-29T16:32:59Z\",\n    \"database\": {\n      \"host\": \"lorem\",\n      \"version\": \"lorem\",\n      \"postgres_engine\": \"lorem\",\n      \"release_channel\": \"lorem\"\n    },\n    \"status\": \"ACTIVE_HEALTHY\"\n  }\n]  [Beta] Updates project's network restrictionspost/v1/projects/{ref}/network-restrictions/applyPath parametersrefRequiredstringProject refDetailsBodydbAllowedCidrsOptionalArray<string>dbAllowedCidrsV6OptionalArray<string>Response codes201403500Response (201)exampleschema{\n  \"entitlement\": \"disallowed\",\n  \"config\": {\n    \"dbAllowedCidrs\": [\n      \"lorem\"\n    ],\n    \"dbAllowedCidrsV6\": [\n      \"lorem\"\n    ]\n  },\n  \"old_config\": {\n    \"dbAllowedCidrs\": [\n      \"lorem\"\n    ],\n    \"dbAllowedCidrsV6\": [\n      \"lorem\"\n    ]\n  },\n  \"status\": \"stored\"\n}  [Beta] Upgrades the project's Postgres versionpost/v1/projects/{ref}/upgradePath parametersrefRequiredstringProject refDetailsBodyrelease_channelRequiredenumAccepted valuestarget_versionRequiredstringResponse codes201403500Response (201)exampleschema{\n  \"tracking_id\": \"lorem\"\n}  Gets project's postgrest configget/v1/projects/{ref}/postgrestPath parametersrefRequiredstringProject refDetailsResponse codes200403500Response (200)exampleschema{\n  \"max_rows\": 42,\n  \"db_pool\": 42,\n  \"db_schema\": \"lorem\",\n  \"db_extra_search_path\": \"lorem\",\n  \"jwt_secret\": \"lorem\"\n}  Updates project's postgrest configpatch/v1/projects/{ref}/postgrestPath parametersrefRequiredstringProject refDetailsBodymax_rowsOptionalintegerdb_poolOptionalintegerdb_extra_search_pathOptionalstringdb_schemaOptionalstringResponse codes200403500Response (200)exampleschema{\n  \"max_rows\": 42,\n  \"db_pool\": 42,\n  \"db_schema\": \"lorem\",\n  \"db_extra_search_path\": \"lorem\"\n}  Bulk create secretspost/v1/projects/{ref}/secretsCreates multiple secrets and adds them to the specified project.Path parametersrefRequiredstringProject refDetailsBodyArray of objectObject schemaResponse codes201403500Response (201)schema{}  Bulk delete secretsdelete/v1/projects/{ref}/secretsDeletes all secrets with the given names from the specified projectPath parametersrefRequiredstringProject refDetailsBodyArray of stringResponse codes200403500Response (200)exampleschema{}  [Beta] Gets project's pgsodium configget/v1/projects/{ref}/pgsodiumPath parametersrefRequiredstringProject refDetailsResponse codes200403500Response (200)exampleschema{\n  \"root_key\": \"lorem\"\n}  Get project api keysget/v1/projects/{ref}/api-keysPath parametersrefRequiredstringProject refDetailsResponse codes200Response (200)exampleschema[\n  {\n    \"name\": \"lorem\",\n    \"api_key\": \"lorem\",\n    \"id\": \"lorem\",\n    \"type\": {},\n    \"prefix\": \"lorem\",\n    \"description\": \"lorem\",\n    \"hash\": \"lorem\",\n    \"secret_jwt_template\": {\n      \"role\": \"lorem\"\n    },\n    \"inserted_at\": \"lorem\",\n    \"updated_at\": \"lorem\"\n  }\n]  List all secretsget/v1/projects/{ref}/secretsReturns all secrets you've previously added to the specified project.Path parametersrefRequiredstringProject refDetailsResponse codes200403500Response (200)exampleschema[\n  {\n    \"name\": \"lorem\",\n    \"value\": \"lorem\"\n  }\n]  [Beta] Updates project's pgsodium config. Updating the root_key can cause all data encrypted with the older key to become inaccessible.put/v1/projects/{ref}/pgsodiumPath parametersrefRequiredstringProject refDetailsBodyroot_keyRequiredstringResponse codes200403500Response (200)exampleschema{\n  \"root_key\": \"lorem\"\n}  Gets project's storage configget/v1/projects/{ref}/config/storagePath parametersrefRequiredstringProject refDetailsResponse codes200403500Response (200)exampleschema{\n  \"fileSizeLimit\": 42,\n  \"features\": {\n    \"imageTransformation\": {\n      \"enabled\": true\n    }\n  }\n}  Lists all bucketsget/v1/projects/{ref}/storage/bucketsPath parametersrefRequiredstringProject refDetailsResponse codes200403500Response (200)exampleschema[\n  {\n    \"id\": \"lorem\",\n    \"name\": \"lorem\",\n    \"owner\": \"lorem\",\n    \"created_at\": \"lorem\",\n    \"updated_at\": \"lorem\",\n    \"public\": true\n  }\n]  Updates project's storage configpatch/v1/projects/{ref}/config/storagePath parametersrefRequiredstringProject refDetailsBodyfileSizeLimitOptionalintegerfeaturesOptionalobjectObject schemaResponse codes200403500Response (200)schema{}\n[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nManagement API\nManage your Supabase organizations and projects programmatically.Authentication#All API requests require a Supabase Personal token to be included in the Authorization header: Authorization Bearer <supabase_personal_token>.\nTo generate or manage your API token, visit your account page.\nYour API tokens carry the same privileges as your user account, so be sure to keep it secret._10  curl https://api.supabase.com/v1/projects \\_10  -H \"Authorization: Bearer sbp_bdd0â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢4f23\"All API requests must be authenticated and made over HTTPS.Rate limits#The rate limit for Management API is 60 requests per one minute per user, and applies cumulatively across all requests made with your personal access tokens.If you exceed this limit, all Management API calls for the next minute will be blocked, resulting in a HTTP 429 response.The Management API is subject to our fair-use policy.\nAll resources created via the API are subject to the pricing detailed on our Pricing pages.Additional links\nOpenAPI Docs\nOpenAPI Spec\nReport bugs and issues\nManagement API\nManage your Supabase organizations and projects programmatically.\nAuthentication#\nAll API requests require a Supabase Personal token to be included in the Authorization header: Authorization Bearer <supabase_personal_token>.\nTo generate or manage your API token, visit your account page.\nYour API tokens carry the same privileges as your user account, so be sure to keep it secret.\nAll API requests must be authenticated and made over HTTPS.\nRate limits#\nThe rate limit for Management API is 60 requests per one minute per user, and applies cumulatively across all requests made with your personal access tokens.\nIf you exceed this limit, all Management API calls for the next minute will be blocked, resulting in a HTTP 429 response.\nThe Management API is subject to our fair-use policy.\nAll resources created via the API are subject to the pricing detailed on our Pricing pages.\nAdditional links\nCreates a new SSO providerpost/v1/projects/{ref}/config/auth/sso/providersPath parametersrefRequiredstringProject refDetailsBodytypeRequiredenumAccepted valuesmetadata_xmlOptionalstringmetadata_urlOptionalstringdomainsOptionalArray<string>attribute_mappingOptionalobjectObject schemaResponse codes201403404Response (201)exampleschema{\n  \"id\": \"lorem\",\n  \"saml\": {\n    \"id\": \"lorem\",\n    \"entity_id\": \"lorem\",\n    \"metadata_url\": \"lorem\",\n    \"metadata_xml\": \"lorem\",\n    \"attribute_mapping\": {\n      \"keys\": {\n        \"property1\": {\n          \"default\": {},\n          \"name\": \"lorem\",\n          \"names\": [\n            \"lorem\"\n          ],\n          \"array\": true\n        },\n        \"property2\": {\n          \"default\": {},\n          \"name\": \"lorem\",\n          \"names\": [\n            \"lorem\"\n          ],\n          \"array\": true\n        }\n      }\n    }\n  },\n  \"domains\": [\n    {\n      \"id\": \"lorem\",\n      \"domain\": \"lorem\",\n      \"created_at\": \"lorem\",\n      \"updated_at\": \"lorem\"\n    }\n  ],\n  \"created_at\": \"lorem\",\n  \"updated_at\": \"lorem\"\n}\nCreates a new SSO provider\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nBodytypeRequiredenumAccepted valuesmetadata_xmlOptionalstringmetadata_urlOptionalstringdomainsOptionalArray<string>attribute_mappingOptionalobjectObject schema\nBody\nResponse codes201403404\nResponse codes\nResponse (201)\nRemoves a SSO provider by its UUIDdelete/v1/projects/{ref}/config/auth/sso/providers/{provider_id}Path parametersrefRequiredstringProject refDetailsprovider_idRequiredstringResponse codes200403404Response (200)exampleschema{\n  \"id\": \"lorem\",\n  \"saml\": {\n    \"id\": \"lorem\",\n    \"entity_id\": \"lorem\",\n    \"metadata_url\": \"lorem\",\n    \"metadata_xml\": \"lorem\",\n    \"attribute_mapping\": {\n      \"keys\": {\n        \"property1\": {\n          \"default\": {},\n          \"name\": \"lorem\",\n          \"names\": [\n            \"lorem\"\n          ],\n          \"array\": true\n        },\n        \"property2\": {\n          \"default\": {},\n          \"name\": \"lorem\",\n          \"names\": [\n            \"lorem\"\n          ],\n          \"array\": true\n        }\n      }\n    }\n  },\n  \"domains\": [\n    {\n      \"id\": \"lorem\",\n      \"domain\": \"lorem\",\n      \"created_at\": \"lorem\",\n      \"updated_at\": \"lorem\"\n    }\n  ],\n  \"created_at\": \"lorem\",\n  \"updated_at\": \"lorem\"\n}\nRemoves a SSO provider by its UUID\nPath parametersrefRequiredstringProject refDetailsprovider_idRequiredstring\nPath parameters\nProject ref\nResponse codes200403404\nResponse codes\nResponse (200)\nGets a SSO provider by its UUIDget/v1/projects/{ref}/config/auth/sso/providers/{provider_id}Path parametersrefRequiredstringProject refDetailsprovider_idRequiredstringResponse codes200403404Response (200)exampleschema{\n  \"id\": \"lorem\",\n  \"saml\": {\n    \"id\": \"lorem\",\n    \"entity_id\": \"lorem\",\n    \"metadata_url\": \"lorem\",\n    \"metadata_xml\": \"lorem\",\n    \"attribute_mapping\": {\n      \"keys\": {\n        \"property1\": {\n          \"default\": {},\n          \"name\": \"lorem\",\n          \"names\": [\n            \"lorem\"\n          ],\n          \"array\": true\n        },\n        \"property2\": {\n          \"default\": {},\n          \"name\": \"lorem\",\n          \"names\": [\n            \"lorem\"\n          ],\n          \"array\": true\n        }\n      }\n    }\n  },\n  \"domains\": [\n    {\n      \"id\": \"lorem\",\n      \"domain\": \"lorem\",\n      \"created_at\": \"lorem\",\n      \"updated_at\": \"lorem\"\n    }\n  ],\n  \"created_at\": \"lorem\",\n  \"updated_at\": \"lorem\"\n}\nGets a SSO provider by its UUID\nPath parametersrefRequiredstringProject refDetailsprovider_idRequiredstring\nPath parameters\nProject ref\nResponse codes200403404\nResponse codes\nResponse (200)\nGets project's auth configget/v1/projects/{ref}/config/authPath parametersrefRequiredstringProject refDetailsResponse codes200403500Response (200)exampleschema{\n  \"api_max_request_duration\": 42,\n  \"db_max_pool_size\": 42,\n  \"jwt_exp\": 42,\n  \"mailer_otp_exp\": 42,\n  \"mailer_otp_length\": 42,\n  \"mfa_max_enrolled_factors\": 42,\n  \"mfa_phone_otp_length\": 42,\n  \"mfa_phone_max_frequency\": 42,\n  \"password_min_length\": 42,\n  \"rate_limit_anonymous_users\": 42,\n  \"rate_limit_email_sent\": 42,\n  \"rate_limit_sms_sent\": 42,\n  \"rate_limit_token_refresh\": 42,\n  \"rate_limit_verify\": 42,\n  \"rate_limit_otp\": 42,\n  \"security_refresh_token_reuse_interval\": 42,\n  \"sessions_inactivity_timeout\": 42,\n  \"sessions_timebox\": 42,\n  \"sms_max_frequency\": 42,\n  \"sms_otp_exp\": 42,\n  \"sms_otp_length\": 42,\n  \"smtp_max_frequency\": 42,\n  \"disable_signup\": true,\n  \"external_anonymous_users_enabled\": true,\n  \"external_apple_additional_client_ids\": \"lorem\",\n  \"external_apple_client_id\": \"lorem\",\n  \"external_apple_enabled\": true,\n  \"external_apple_secret\": \"lorem\",\n  \"external_azure_client_id\": \"lorem\",\n  \"external_azure_enabled\": true,\n  \"external_azure_secret\": \"lorem\",\n  \"external_azure_url\": \"lorem\",\n  \"external_bitbucket_client_id\": \"lorem\",\n  \"external_bitbucket_enabled\": true,\n  \"external_bitbucket_secret\": \"lorem\",\n  \"external_discord_client_id\": \"lorem\",\n  \"external_discord_enabled\": true,\n  \"external_discord_secret\": \"lorem\",\n  \"external_email_enabled\": true,\n  \"external_facebook_client_id\": \"lorem\",\n  \"external_facebook_enabled\": true,\n  \"external_facebook_secret\": \"lorem\",\n  \"external_figma_client_id\": \"lorem\",\n  \"external_figma_enabled\": true,\n  \"external_figma_secret\": \"lorem\",\n  \"external_github_client_id\": \"lorem\",\n  \"external_github_enabled\": true,\n  \"external_github_secret\": \"lorem\",\n  \"external_gitlab_client_id\": \"lorem\",\n  \"external_gitlab_enabled\": true,\n  \"external_gitlab_secret\": \"lorem\",\n  \"external_gitlab_url\": \"lorem\",\n  \"external_google_additional_client_ids\": \"lorem\",\n  \"external_google_client_id\": \"lorem\",\n  \"external_google_enabled\": true,\n  \"external_google_secret\": \"lorem\",\n  \"external_google_skip_nonce_check\": true,\n  \"external_kakao_client_id\": \"lorem\",\n  \"external_kakao_enabled\": true,\n  \"external_kakao_secret\": \"lorem\",\n  \"external_keycloak_client_id\": \"lorem\",\n  \"external_keycloak_enabled\": true,\n  \"external_keycloak_secret\": \"lorem\",\n  \"external_keycloak_url\": \"lorem\",\n  \"external_linkedin_oidc_client_id\": \"lorem\",\n  \"external_linkedin_oidc_enabled\": true,\n  \"external_linkedin_oidc_secret\": \"lorem\",\n  \"external_slack_oidc_client_id\": \"lorem\",\n  \"external_slack_oidc_enabled\": true,\n  \"external_slack_oidc_secret\": \"lorem\",\n  \"external_notion_client_id\": \"lorem\",\n  \"external_notion_enabled\": true,\n  \"external_notion_secret\": \"lorem\",\n  \"external_phone_enabled\": true,\n  \"external_slack_client_id\": \"lorem\",\n  \"external_slack_enabled\": true,\n  \"external_slack_secret\": \"lorem\",\n  \"external_spotify_client_id\": \"lorem\",\n  \"external_spotify_enabled\": true,\n  \"external_spotify_secret\": \"lorem\",\n  \"external_twitch_client_id\": \"lorem\",\n  \"external_twitch_enabled\": true,\n  \"external_twitch_secret\": \"lorem\",\n  \"external_twitter_client_id\": \"lorem\",\n  \"external_twitter_enabled\": true,\n  \"external_twitter_secret\": \"lorem\",\n  \"external_workos_client_id\": \"lorem\",\n  \"external_workos_enabled\": true,\n  \"external_workos_secret\": \"lorem\",\n  \"external_workos_url\": \"lorem\",\n  \"external_zoom_client_id\": \"lorem\",\n  \"external_zoom_enabled\": true,\n  \"external_zoom_secret\": \"lorem\",\n  \"hook_custom_access_token_enabled\": true,\n  \"hook_custom_access_token_uri\": \"lorem\",\n  \"hook_custom_access_token_secrets\": \"lorem\",\n  \"hook_mfa_verification_attempt_enabled\": true,\n  \"hook_mfa_verification_attempt_uri\": \"lorem\",\n  \"hook_mfa_verification_attempt_secrets\": \"lorem\",\n  \"hook_password_verification_attempt_enabled\": true,\n  \"hook_password_verification_attempt_uri\": \"lorem\",\n  \"hook_password_verification_attempt_secrets\": \"lorem\",\n  \"hook_send_sms_enabled\": true,\n  \"hook_send_sms_uri\": \"lorem\",\n  \"hook_send_sms_secrets\": \"lorem\",\n  \"hook_send_email_enabled\": true,\n  \"hook_send_email_uri\": \"lorem\",\n  \"hook_send_email_secrets\": \"lorem\",\n  \"mailer_allow_unverified_email_sign_ins\": true,\n  \"mailer_autoconfirm\": true,\n  \"mailer_secure_email_change_enabled\": true,\n  \"mailer_subjects_confirmation\": \"lorem\",\n  \"mailer_subjects_email_change\": \"lorem\",\n  \"mailer_subjects_invite\": \"lorem\",\n  \"mailer_subjects_magic_link\": \"lorem\",\n  \"mailer_subjects_reauthentication\": \"lorem\",\n  \"mailer_subjects_recovery\": \"lorem\",\n  \"mailer_templates_confirmation_content\": \"lorem\",\n  \"mailer_templates_email_change_content\": \"lorem\",\n  \"mailer_templates_invite_content\": \"lorem\",\n  \"mailer_templates_magic_link_content\": \"lorem\",\n  \"mailer_templates_reauthentication_content\": \"lorem\",\n  \"mailer_templates_recovery_content\": \"lorem\",\n  \"mfa_totp_enroll_enabled\": true,\n  \"mfa_totp_verify_enabled\": true,\n  \"mfa_phone_enroll_enabled\": true,\n  \"mfa_phone_verify_enabled\": true,\n  \"mfa_web_authn_enroll_enabled\": true,\n  \"mfa_web_authn_verify_enabled\": true,\n  \"mfa_phone_template\": \"lorem\",\n  \"password_hibp_enabled\": true,\n  \"password_required_characters\": \"lorem\",\n  \"refresh_token_rotation_enabled\": true,\n  \"saml_enabled\": true,\n  \"saml_external_url\": \"lorem\",\n  \"saml_allow_encrypted_assertions\": true,\n  \"security_captcha_enabled\": true,\n  \"security_captcha_provider\": \"lorem\",\n  \"security_captcha_secret\": \"lorem\",\n  \"security_manual_linking_enabled\": true,\n  \"security_update_password_require_reauthentication\": true,\n  \"sessions_single_per_user\": true,\n  \"sessions_tags\": \"lorem\",\n  \"site_url\": \"lorem\",\n  \"sms_autoconfirm\": true,\n  \"sms_messagebird_access_key\": \"lorem\",\n  \"sms_messagebird_originator\": \"lorem\",\n  \"sms_provider\": \"lorem\",\n  \"sms_template\": \"lorem\",\n  \"sms_test_otp\": \"lorem\",\n  \"sms_test_otp_valid_until\": \"lorem\",\n  \"sms_textlocal_api_key\": \"lorem\",\n  \"sms_textlocal_sender\": \"lorem\",\n  \"sms_twilio_account_sid\": \"lorem\",\n  \"sms_twilio_auth_token\": \"lorem\",\n  \"sms_twilio_content_sid\": \"lorem\",\n  \"sms_twilio_message_service_sid\": \"lorem\",\n  \"sms_twilio_verify_account_sid\": \"lorem\",\n  \"sms_twilio_verify_auth_token\": \"lorem\",\n  \"sms_twilio_verify_message_service_sid\": \"lorem\",\n  \"sms_vonage_api_key\": \"lorem\",\n  \"sms_vonage_api_secret\": \"lorem\",\n  \"sms_vonage_from\": \"lorem\",\n  \"smtp_admin_email\": \"lorem\",\n  \"smtp_host\": \"lorem\",\n  \"smtp_pass\": \"lorem\",\n  \"smtp_port\": \"lorem\",\n  \"smtp_sender_name\": \"lorem\",\n  \"smtp_user\": \"lorem\",\n  \"uri_allow_list\": \"lorem\"\n}\nGets project's auth config\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes200403500\nResponse codes\nResponse (200)\nLists all SSO providersget/v1/projects/{ref}/config/auth/sso/providersPath parametersrefRequiredstringProject refDetailsResponse codes200403404Response (200)exampleschema{\n  \"items\": [\n    {\n      \"id\": \"lorem\",\n      \"saml\": {\n        \"id\": \"lorem\",\n        \"entity_id\": \"lorem\",\n        \"metadata_url\": \"lorem\",\n        \"metadata_xml\": \"lorem\",\n        \"attribute_mapping\": {\n          \"keys\": {\n            \"property1\": {\n              \"default\": {},\n              \"name\": \"lorem\",\n              \"names\": [\n                \"lorem\"\n              ],\n              \"array\": true\n            },\n            \"property2\": {\n              \"default\": {},\n              \"name\": \"lorem\",\n              \"names\": [\n                \"lorem\"\n              ],\n              \"array\": true\n            }\n          }\n        }\n      },\n      \"domains\": [\n        {\n          \"id\": \"lorem\",\n          \"domain\": \"lorem\",\n          \"created_at\": \"lorem\",\n          \"updated_at\": \"lorem\"\n        }\n      ],\n      \"created_at\": \"lorem\",\n      \"updated_at\": \"lorem\"\n    }\n  ]\n}\nLists all SSO providers\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes200403404\nResponse codes\nResponse (200)\nUpdates a SSO provider by its UUIDput/v1/projects/{ref}/config/auth/sso/providers/{provider_id}Path parametersrefRequiredstringProject refDetailsprovider_idRequiredstringBodymetadata_xmlOptionalstringmetadata_urlOptionalstringdomainsOptionalArray<string>attribute_mappingOptionalobjectObject schemaResponse codes200403404Response (200)exampleschema{\n  \"id\": \"lorem\",\n  \"saml\": {\n    \"id\": \"lorem\",\n    \"entity_id\": \"lorem\",\n    \"metadata_url\": \"lorem\",\n    \"metadata_xml\": \"lorem\",\n    \"attribute_mapping\": {\n      \"keys\": {\n        \"property1\": {\n          \"default\": {},\n          \"name\": \"lorem\",\n          \"names\": [\n            \"lorem\"\n          ],\n          \"array\": true\n        },\n        \"property2\": {\n          \"default\": {},\n          \"name\": \"lorem\",\n          \"names\": [\n            \"lorem\"\n          ],\n          \"array\": true\n        }\n      }\n    }\n  },\n  \"domains\": [\n    {\n      \"id\": \"lorem\",\n      \"domain\": \"lorem\",\n      \"created_at\": \"lorem\",\n      \"updated_at\": \"lorem\"\n    }\n  ],\n  \"created_at\": \"lorem\",\n  \"updated_at\": \"lorem\"\n}\nUpdates a SSO provider by its UUID\nPath parametersrefRequiredstringProject refDetailsprovider_idRequiredstring\nPath parameters\nProject ref\nBodymetadata_xmlOptionalstringmetadata_urlOptionalstringdomainsOptionalArray<string>attribute_mappingOptionalobjectObject schema\nBody\nResponse codes200403404\nResponse codes\nResponse (200)\nUpdates a project's auth configpatch/v1/projects/{ref}/config/authPath parametersrefRequiredstringProject refDetailsBodyjwt_expOptionalintegersmtp_max_frequencyOptionalintegermfa_max_enrolled_factorsOptionalintegersessions_timeboxOptionalintegersessions_inactivity_timeoutOptionalintegerrate_limit_anonymous_usersOptionalintegerrate_limit_email_sentOptionalintegerrate_limit_sms_sentOptionalintegerrate_limit_verifyOptionalintegerrate_limit_token_refreshOptionalintegerrate_limit_otpOptionalintegerpassword_min_lengthOptionalintegersecurity_refresh_token_reuse_intervalOptionalintegermailer_otp_expOptionalintegermailer_otp_lengthOptionalintegersms_max_frequencyOptionalintegersms_otp_expOptionalintegersms_otp_lengthOptionalintegerdb_max_pool_sizeOptionalintegerapi_max_request_durationOptionalintegermfa_phone_max_frequencyOptionalintegermfa_phone_otp_lengthOptionalintegersite_urlOptionalstringDetailsdisable_signupOptionalbooleansmtp_admin_emailOptionalstringsmtp_hostOptionalstringsmtp_portOptionalstringsmtp_userOptionalstringsmtp_passOptionalstringsmtp_sender_nameOptionalstringmailer_allow_unverified_email_sign_insOptionalbooleanmailer_autoconfirmOptionalbooleanmailer_subjects_inviteOptionalstringmailer_subjects_confirmationOptionalstringmailer_subjects_recoveryOptionalstringmailer_subjects_email_changeOptionalstringmailer_subjects_magic_linkOptionalstringmailer_subjects_reauthenticationOptionalstringmailer_templates_invite_contentOptionalstringmailer_templates_confirmation_contentOptionalstringmailer_templates_recovery_contentOptionalstringmailer_templates_email_change_contentOptionalstringmailer_templates_magic_link_contentOptionalstringmailer_templates_reauthentication_contentOptionalstringuri_allow_listOptionalstringexternal_anonymous_users_enabledOptionalbooleanexternal_email_enabledOptionalbooleanexternal_phone_enabledOptionalbooleansaml_enabledOptionalbooleansaml_external_urlOptionalstringDetailssecurity_captcha_enabledOptionalbooleansecurity_captcha_providerOptionalstringsecurity_captcha_secretOptionalstringsessions_single_per_userOptionalbooleansessions_tagsOptionalstringDetailsmailer_secure_email_change_enabledOptionalbooleanrefresh_token_rotation_enabledOptionalbooleanpassword_hibp_enabledOptionalbooleanpassword_required_charactersOptionalenumAccepted valuessecurity_manual_linking_enabledOptionalbooleansecurity_update_password_require_reauthenticationOptionalbooleansms_autoconfirmOptionalbooleansms_providerOptionalstringsms_messagebird_access_keyOptionalstringsms_messagebird_originatorOptionalstringsms_test_otpOptionalstringDetailssms_test_otp_valid_untilOptionalstringsms_textlocal_api_keyOptionalstringsms_textlocal_senderOptionalstringsms_twilio_account_sidOptionalstringsms_twilio_auth_tokenOptionalstringsms_twilio_content_sidOptionalstringsms_twilio_message_service_sidOptionalstringsms_twilio_verify_account_sidOptionalstringsms_twilio_verify_auth_tokenOptionalstringsms_twilio_verify_message_service_sidOptionalstringsms_vonage_api_keyOptionalstringsms_vonage_api_secretOptionalstringsms_vonage_fromOptionalstringsms_templateOptionalstringhook_mfa_verification_attempt_enabledOptionalbooleanhook_mfa_verification_attempt_uriOptionalstringhook_mfa_verification_attempt_secretsOptionalstringhook_password_verification_attempt_enabledOptionalbooleanhook_password_verification_attempt_uriOptionalstringhook_password_verification_attempt_secretsOptionalstringhook_custom_access_token_enabledOptionalbooleanhook_custom_access_token_uriOptionalstringhook_custom_access_token_secretsOptionalstringhook_send_sms_enabledOptionalbooleanhook_send_sms_uriOptionalstringhook_send_sms_secretsOptionalstringhook_send_email_enabledOptionalbooleanhook_send_email_uriOptionalstringhook_send_email_secretsOptionalstringexternal_apple_enabledOptionalbooleanexternal_apple_client_idOptionalstringexternal_apple_secretOptionalstringexternal_apple_additional_client_idsOptionalstringexternal_azure_enabledOptionalbooleanexternal_azure_client_idOptionalstringexternal_azure_secretOptionalstringexternal_azure_urlOptionalstringexternal_bitbucket_enabledOptionalbooleanexternal_bitbucket_client_idOptionalstringexternal_bitbucket_secretOptionalstringexternal_discord_enabledOptionalbooleanexternal_discord_client_idOptionalstringexternal_discord_secretOptionalstringexternal_facebook_enabledOptionalbooleanexternal_facebook_client_idOptionalstringexternal_facebook_secretOptionalstringexternal_figma_enabledOptionalbooleanexternal_figma_client_idOptionalstringexternal_figma_secretOptionalstringexternal_github_enabledOptionalbooleanexternal_github_client_idOptionalstringexternal_github_secretOptionalstringexternal_gitlab_enabledOptionalbooleanexternal_gitlab_client_idOptionalstringexternal_gitlab_secretOptionalstringexternal_gitlab_urlOptionalstringexternal_google_enabledOptionalbooleanexternal_google_client_idOptionalstringexternal_google_secretOptionalstringexternal_google_additional_client_idsOptionalstringexternal_google_skip_nonce_checkOptionalbooleanexternal_kakao_enabledOptionalbooleanexternal_kakao_client_idOptionalstringexternal_kakao_secretOptionalstringexternal_keycloak_enabledOptionalbooleanexternal_keycloak_client_idOptionalstringexternal_keycloak_secretOptionalstringexternal_keycloak_urlOptionalstringexternal_linkedin_oidc_enabledOptionalbooleanexternal_linkedin_oidc_client_idOptionalstringexternal_linkedin_oidc_secretOptionalstringexternal_slack_oidc_enabledOptionalbooleanexternal_slack_oidc_client_idOptionalstringexternal_slack_oidc_secretOptionalstringexternal_notion_enabledOptionalbooleanexternal_notion_client_idOptionalstringexternal_notion_secretOptionalstringexternal_slack_enabledOptionalbooleanexternal_slack_client_idOptionalstringexternal_slack_secretOptionalstringexternal_spotify_enabledOptionalbooleanexternal_spotify_client_idOptionalstringexternal_spotify_secretOptionalstringexternal_twitch_enabledOptionalbooleanexternal_twitch_client_idOptionalstringexternal_twitch_secretOptionalstringexternal_twitter_enabledOptionalbooleanexternal_twitter_client_idOptionalstringexternal_twitter_secretOptionalstringexternal_workos_enabledOptionalbooleanexternal_workos_client_idOptionalstringexternal_workos_secretOptionalstringexternal_workos_urlOptionalstringexternal_zoom_enabledOptionalbooleanexternal_zoom_client_idOptionalstringexternal_zoom_secretOptionalstringmfa_totp_enroll_enabledOptionalbooleanmfa_totp_verify_enabledOptionalbooleanmfa_web_authn_enroll_enabledOptionalbooleanmfa_web_authn_verify_enabledOptionalbooleanmfa_phone_enroll_enabledOptionalbooleanmfa_phone_verify_enabledOptionalbooleanmfa_phone_templateOptionalstringResponse codes200403500Response (200)exampleschema{\n  \"api_max_request_duration\": 42,\n  \"db_max_pool_size\": 42,\n  \"jwt_exp\": 42,\n  \"mailer_otp_exp\": 42,\n  \"mailer_otp_length\": 42,\n  \"mfa_max_enrolled_factors\": 42,\n  \"mfa_phone_otp_length\": 42,\n  \"mfa_phone_max_frequency\": 42,\n  \"password_min_length\": 42,\n  \"rate_limit_anonymous_users\": 42,\n  \"rate_limit_email_sent\": 42,\n  \"rate_limit_sms_sent\": 42,\n  \"rate_limit_token_refresh\": 42,\n  \"rate_limit_verify\": 42,\n  \"rate_limit_otp\": 42,\n  \"security_refresh_token_reuse_interval\": 42,\n  \"sessions_inactivity_timeout\": 42,\n  \"sessions_timebox\": 42,\n  \"sms_max_frequency\": 42,\n  \"sms_otp_exp\": 42,\n  \"sms_otp_length\": 42,\n  \"smtp_max_frequency\": 42,\n  \"disable_signup\": true,\n  \"external_anonymous_users_enabled\": true,\n  \"external_apple_additional_client_ids\": \"lorem\",\n  \"external_apple_client_id\": \"lorem\",\n  \"external_apple_enabled\": true,\n  \"external_apple_secret\": \"lorem\",\n  \"external_azure_client_id\": \"lorem\",\n  \"external_azure_enabled\": true,\n  \"external_azure_secret\": \"lorem\",\n  \"external_azure_url\": \"lorem\",\n  \"external_bitbucket_client_id\": \"lorem\",\n  \"external_bitbucket_enabled\": true,\n  \"external_bitbucket_secret\": \"lorem\",\n  \"external_discord_client_id\": \"lorem\",\n  \"external_discord_enabled\": true,\n  \"external_discord_secret\": \"lorem\",\n  \"external_email_enabled\": true,\n  \"external_facebook_client_id\": \"lorem\",\n  \"external_facebook_enabled\": true,\n  \"external_facebook_secret\": \"lorem\",\n  \"external_figma_client_id\": \"lorem\",\n  \"external_figma_enabled\": true,\n  \"external_figma_secret\": \"lorem\",\n  \"external_github_client_id\": \"lorem\",\n  \"external_github_enabled\": true,\n  \"external_github_secret\": \"lorem\",\n  \"external_gitlab_client_id\": \"lorem\",\n  \"external_gitlab_enabled\": true,\n  \"external_gitlab_secret\": \"lorem\",\n  \"external_gitlab_url\": \"lorem\",\n  \"external_google_additional_client_ids\": \"lorem\",\n  \"external_google_client_id\": \"lorem\",\n  \"external_google_enabled\": true,\n  \"external_google_secret\": \"lorem\",\n  \"external_google_skip_nonce_check\": true,\n  \"external_kakao_client_id\": \"lorem\",\n  \"external_kakao_enabled\": true,\n  \"external_kakao_secret\": \"lorem\",\n  \"external_keycloak_client_id\": \"lorem\",\n  \"external_keycloak_enabled\": true,\n  \"external_keycloak_secret\": \"lorem\",\n  \"external_keycloak_url\": \"lorem\",\n  \"external_linkedin_oidc_client_id\": \"lorem\",\n  \"external_linkedin_oidc_enabled\": true,\n  \"external_linkedin_oidc_secret\": \"lorem\",\n  \"external_slack_oidc_client_id\": \"lorem\",\n  \"external_slack_oidc_enabled\": true,\n  \"external_slack_oidc_secret\": \"lorem\",\n  \"external_notion_client_id\": \"lorem\",\n  \"external_notion_enabled\": true,\n  \"external_notion_secret\": \"lorem\",\n  \"external_phone_enabled\": true,\n  \"external_slack_client_id\": \"lorem\",\n  \"external_slack_enabled\": true,\n  \"external_slack_secret\": \"lorem\",\n  \"external_spotify_client_id\": \"lorem\",\n  \"external_spotify_enabled\": true,\n  \"external_spotify_secret\": \"lorem\",\n  \"external_twitch_client_id\": \"lorem\",\n  \"external_twitch_enabled\": true,\n  \"external_twitch_secret\": \"lorem\",\n  \"external_twitter_client_id\": \"lorem\",\n  \"external_twitter_enabled\": true,\n  \"external_twitter_secret\": \"lorem\",\n  \"external_workos_client_id\": \"lorem\",\n  \"external_workos_enabled\": true,\n  \"external_workos_secret\": \"lorem\",\n  \"external_workos_url\": \"lorem\",\n  \"external_zoom_client_id\": \"lorem\",\n  \"external_zoom_enabled\": true,\n  \"external_zoom_secret\": \"lorem\",\n  \"hook_custom_access_token_enabled\": true,\n  \"hook_custom_access_token_uri\": \"lorem\",\n  \"hook_custom_access_token_secrets\": \"lorem\",\n  \"hook_mfa_verification_attempt_enabled\": true,\n  \"hook_mfa_verification_attempt_uri\": \"lorem\",\n  \"hook_mfa_verification_attempt_secrets\": \"lorem\",\n  \"hook_password_verification_attempt_enabled\": true,\n  \"hook_password_verification_attempt_uri\": \"lorem\",\n  \"hook_password_verification_attempt_secrets\": \"lorem\",\n  \"hook_send_sms_enabled\": true,\n  \"hook_send_sms_uri\": \"lorem\",\n  \"hook_send_sms_secrets\": \"lorem\",\n  \"hook_send_email_enabled\": true,\n  \"hook_send_email_uri\": \"lorem\",\n  \"hook_send_email_secrets\": \"lorem\",\n  \"mailer_allow_unverified_email_sign_ins\": true,\n  \"mailer_autoconfirm\": true,\n  \"mailer_secure_email_change_enabled\": true,\n  \"mailer_subjects_confirmation\": \"lorem\",\n  \"mailer_subjects_email_change\": \"lorem\",\n  \"mailer_subjects_invite\": \"lorem\",\n  \"mailer_subjects_magic_link\": \"lorem\",\n  \"mailer_subjects_reauthentication\": \"lorem\",\n  \"mailer_subjects_recovery\": \"lorem\",\n  \"mailer_templates_confirmation_content\": \"lorem\",\n  \"mailer_templates_email_change_content\": \"lorem\",\n  \"mailer_templates_invite_content\": \"lorem\",\n  \"mailer_templates_magic_link_content\": \"lorem\",\n  \"mailer_templates_reauthentication_content\": \"lorem\",\n  \"mailer_templates_recovery_content\": \"lorem\",\n  \"mfa_totp_enroll_enabled\": true,\n  \"mfa_totp_verify_enabled\": true,\n  \"mfa_phone_enroll_enabled\": true,\n  \"mfa_phone_verify_enabled\": true,\n  \"mfa_web_authn_enroll_enabled\": true,\n  \"mfa_web_authn_verify_enabled\": true,\n  \"mfa_phone_template\": \"lorem\",\n  \"password_hibp_enabled\": true,\n  \"password_required_characters\": \"lorem\",\n  \"refresh_token_rotation_enabled\": true,\n  \"saml_enabled\": true,\n  \"saml_external_url\": \"lorem\",\n  \"saml_allow_encrypted_assertions\": true,\n  \"security_captcha_enabled\": true,\n  \"security_captcha_provider\": \"lorem\",\n  \"security_captcha_secret\": \"lorem\",\n  \"security_manual_linking_enabled\": true,\n  \"security_update_password_require_reauthentication\": true,\n  \"sessions_single_per_user\": true,\n  \"sessions_tags\": \"lorem\",\n  \"site_url\": \"lorem\",\n  \"sms_autoconfirm\": true,\n  \"sms_messagebird_access_key\": \"lorem\",\n  \"sms_messagebird_originator\": \"lorem\",\n  \"sms_provider\": \"lorem\",\n  \"sms_template\": \"lorem\",\n  \"sms_test_otp\": \"lorem\",\n  \"sms_test_otp_valid_until\": \"lorem\",\n  \"sms_textlocal_api_key\": \"lorem\",\n  \"sms_textlocal_sender\": \"lorem\",\n  \"sms_twilio_account_sid\": \"lorem\",\n  \"sms_twilio_auth_token\": \"lorem\",\n  \"sms_twilio_content_sid\": \"lorem\",\n  \"sms_twilio_message_service_sid\": \"lorem\",\n  \"sms_twilio_verify_account_sid\": \"lorem\",\n  \"sms_twilio_verify_auth_token\": \"lorem\",\n  \"sms_twilio_verify_message_service_sid\": \"lorem\",\n  \"sms_vonage_api_key\": \"lorem\",\n  \"sms_vonage_api_secret\": \"lorem\",\n  \"sms_vonage_from\": \"lorem\",\n  \"smtp_admin_email\": \"lorem\",\n  \"smtp_host\": \"lorem\",\n  \"smtp_pass\": \"lorem\",\n  \"smtp_port\": \"lorem\",\n  \"smtp_sender_name\": \"lorem\",\n  \"smtp_user\": \"lorem\",\n  \"uri_allow_list\": \"lorem\"\n}\nUpdates a project's auth config\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nBodyjwt_expOptionalintegersmtp_max_frequencyOptionalintegermfa_max_enrolled_factorsOptionalintegersessions_timeboxOptionalintegersessions_inactivity_timeoutOptionalintegerrate_limit_anonymous_usersOptionalintegerrate_limit_email_sentOptionalintegerrate_limit_sms_sentOptionalintegerrate_limit_verifyOptionalintegerrate_limit_token_refreshOptionalintegerrate_limit_otpOptionalintegerpassword_min_lengthOptionalintegersecurity_refresh_token_reuse_intervalOptionalintegermailer_otp_expOptionalintegermailer_otp_lengthOptionalintegersms_max_frequencyOptionalintegersms_otp_expOptionalintegersms_otp_lengthOptionalintegerdb_max_pool_sizeOptionalintegerapi_max_request_durationOptionalintegermfa_phone_max_frequencyOptionalintegermfa_phone_otp_lengthOptionalintegersite_urlOptionalstringDetailsdisable_signupOptionalbooleansmtp_admin_emailOptionalstringsmtp_hostOptionalstringsmtp_portOptionalstringsmtp_userOptionalstringsmtp_passOptionalstringsmtp_sender_nameOptionalstringmailer_allow_unverified_email_sign_insOptionalbooleanmailer_autoconfirmOptionalbooleanmailer_subjects_inviteOptionalstringmailer_subjects_confirmationOptionalstringmailer_subjects_recoveryOptionalstringmailer_subjects_email_changeOptionalstringmailer_subjects_magic_linkOptionalstringmailer_subjects_reauthenticationOptionalstringmailer_templates_invite_contentOptionalstringmailer_templates_confirmation_contentOptionalstringmailer_templates_recovery_contentOptionalstringmailer_templates_email_change_contentOptionalstringmailer_templates_magic_link_contentOptionalstringmailer_templates_reauthentication_contentOptionalstringuri_allow_listOptionalstringexternal_anonymous_users_enabledOptionalbooleanexternal_email_enabledOptionalbooleanexternal_phone_enabledOptionalbooleansaml_enabledOptionalbooleansaml_external_urlOptionalstringDetailssecurity_captcha_enabledOptionalbooleansecurity_captcha_providerOptionalstringsecurity_captcha_secretOptionalstringsessions_single_per_userOptionalbooleansessions_tagsOptionalstringDetailsmailer_secure_email_change_enabledOptionalbooleanrefresh_token_rotation_enabledOptionalbooleanpassword_hibp_enabledOptionalbooleanpassword_required_charactersOptionalenumAccepted valuessecurity_manual_linking_enabledOptionalbooleansecurity_update_password_require_reauthenticationOptionalbooleansms_autoconfirmOptionalbooleansms_providerOptionalstringsms_messagebird_access_keyOptionalstringsms_messagebird_originatorOptionalstringsms_test_otpOptionalstringDetailssms_test_otp_valid_untilOptionalstringsms_textlocal_api_keyOptionalstringsms_textlocal_senderOptionalstringsms_twilio_account_sidOptionalstringsms_twilio_auth_tokenOptionalstringsms_twilio_content_sidOptionalstringsms_twilio_message_service_sidOptionalstringsms_twilio_verify_account_sidOptionalstringsms_twilio_verify_auth_tokenOptionalstringsms_twilio_verify_message_service_sidOptionalstringsms_vonage_api_keyOptionalstringsms_vonage_api_secretOptionalstringsms_vonage_fromOptionalstringsms_templateOptionalstringhook_mfa_verification_attempt_enabledOptionalbooleanhook_mfa_verification_attempt_uriOptionalstringhook_mfa_verification_attempt_secretsOptionalstringhook_password_verification_attempt_enabledOptionalbooleanhook_password_verification_attempt_uriOptionalstringhook_password_verification_attempt_secretsOptionalstringhook_custom_access_token_enabledOptionalbooleanhook_custom_access_token_uriOptionalstringhook_custom_access_token_secretsOptionalstringhook_send_sms_enabledOptionalbooleanhook_send_sms_uriOptionalstringhook_send_sms_secretsOptionalstringhook_send_email_enabledOptionalbooleanhook_send_email_uriOptionalstringhook_send_email_secretsOptionalstringexternal_apple_enabledOptionalbooleanexternal_apple_client_idOptionalstringexternal_apple_secretOptionalstringexternal_apple_additional_client_idsOptionalstringexternal_azure_enabledOptionalbooleanexternal_azure_client_idOptionalstringexternal_azure_secretOptionalstringexternal_azure_urlOptionalstringexternal_bitbucket_enabledOptionalbooleanexternal_bitbucket_client_idOptionalstringexternal_bitbucket_secretOptionalstringexternal_discord_enabledOptionalbooleanexternal_discord_client_idOptionalstringexternal_discord_secretOptionalstringexternal_facebook_enabledOptionalbooleanexternal_facebook_client_idOptionalstringexternal_facebook_secretOptionalstringexternal_figma_enabledOptionalbooleanexternal_figma_client_idOptionalstringexternal_figma_secretOptionalstringexternal_github_enabledOptionalbooleanexternal_github_client_idOptionalstringexternal_github_secretOptionalstringexternal_gitlab_enabledOptionalbooleanexternal_gitlab_client_idOptionalstringexternal_gitlab_secretOptionalstringexternal_gitlab_urlOptionalstringexternal_google_enabledOptionalbooleanexternal_google_client_idOptionalstringexternal_google_secretOptionalstringexternal_google_additional_client_idsOptionalstringexternal_google_skip_nonce_checkOptionalbooleanexternal_kakao_enabledOptionalbooleanexternal_kakao_client_idOptionalstringexternal_kakao_secretOptionalstringexternal_keycloak_enabledOptionalbooleanexternal_keycloak_client_idOptionalstringexternal_keycloak_secretOptionalstringexternal_keycloak_urlOptionalstringexternal_linkedin_oidc_enabledOptionalbooleanexternal_linkedin_oidc_client_idOptionalstringexternal_linkedin_oidc_secretOptionalstringexternal_slack_oidc_enabledOptionalbooleanexternal_slack_oidc_client_idOptionalstringexternal_slack_oidc_secretOptionalstringexternal_notion_enabledOptionalbooleanexternal_notion_client_idOptionalstringexternal_notion_secretOptionalstringexternal_slack_enabledOptionalbooleanexternal_slack_client_idOptionalstringexternal_slack_secretOptionalstringexternal_spotify_enabledOptionalbooleanexternal_spotify_client_idOptionalstringexternal_spotify_secretOptionalstringexternal_twitch_enabledOptionalbooleanexternal_twitch_client_idOptionalstringexternal_twitch_secretOptionalstringexternal_twitter_enabledOptionalbooleanexternal_twitter_client_idOptionalstringexternal_twitter_secretOptionalstringexternal_workos_enabledOptionalbooleanexternal_workos_client_idOptionalstringexternal_workos_secretOptionalstringexternal_workos_urlOptionalstringexternal_zoom_enabledOptionalbooleanexternal_zoom_client_idOptionalstringexternal_zoom_secretOptionalstringmfa_totp_enroll_enabledOptionalbooleanmfa_totp_verify_enabledOptionalbooleanmfa_web_authn_enroll_enabledOptionalbooleanmfa_web_authn_verify_enabledOptionalbooleanmfa_phone_enroll_enabledOptionalbooleanmfa_phone_verify_enabledOptionalbooleanmfa_phone_templateOptionalstring\nBody\nResponse codes200403500\nResponse codes\nResponse (200)\nDisables project's readonly mode for the next 15 minutespost/v1/projects/{ref}/readonly/temporary-disablePath parametersrefRequiredstringProject refDetailsResponse codes201500Response (201)schema{}\nDisables project's readonly mode for the next 15 minutes\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes201500\nResponse codes\nResponse (201)\n[Beta] Enables Database Webhooks on the projectpost/v1/projects/{ref}/database/webhooks/enablePath parametersrefRequiredstringProject refDetailsResponse codes201403500Response (201)schema{}\n[Beta] Enables Database Webhooks on the project\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes201403500\nResponse codes\nResponse (201)\nGenerate TypeScript typesget/v1/projects/{ref}/types/typescriptReturns the TypeScript types of your schema for use with supabase-js.Path parametersrefRequiredstringProject refDetailsQuery parametersincluded_schemasOptionalstringResponse codes200403500Response (200)exampleschema{\n  \"types\": \"lorem\"\n}\nGenerate TypeScript types\nReturns the TypeScript types of your schema for use with supabase-js.\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nQuery parametersincluded_schemasOptionalstring\nQuery parameters\nResponse codes200403500\nResponse codes\nResponse (200)\nGets a specific SQL snippetget/v1/snippets/{id}Path parametersidRequiredstringResponse codes200500Response (200)exampleschema{\n  \"id\": \"lorem\",\n  \"inserted_at\": \"lorem\",\n  \"updated_at\": \"lorem\",\n  \"type\": \"sql\",\n  \"visibility\": \"user\",\n  \"name\": \"lorem\",\n  \"description\": \"lorem\",\n  \"project\": {\n    \"id\": 42,\n    \"name\": \"lorem\"\n  },\n  \"owner\": {\n    \"id\": 42,\n    \"username\": \"lorem\"\n  },\n  \"updated_by\": {\n    \"id\": 42,\n    \"username\": \"lorem\"\n  },\n  \"content\": {\n    \"favorite\": true,\n    \"schema_version\": \"lorem\",\n    \"sql\": \"lorem\"\n  }\n}\nGets a specific SQL snippet\nPath parametersidRequiredstring\nPath parameters\nResponse codes200500\nResponse codes\nResponse (200)\nGets project's Postgres configget/v1/projects/{ref}/config/database/postgresPath parametersrefRequiredstringProject refDetailsResponse codes200500Response (200)exampleschema{\n  \"effective_cache_size\": \"lorem\",\n  \"logical_decoding_work_mem\": \"lorem\",\n  \"maintenance_work_mem\": \"lorem\",\n  \"max_connections\": 1,\n  \"max_locks_per_transaction\": 10,\n  \"max_parallel_maintenance_workers\": 0,\n  \"max_parallel_workers\": 0,\n  \"max_parallel_workers_per_gather\": 0,\n  \"max_replication_slots\": 42,\n  \"max_slot_wal_keep_size\": \"lorem\",\n  \"max_standby_archive_delay\": \"lorem\",\n  \"max_standby_streaming_delay\": \"lorem\",\n  \"max_wal_size\": \"lorem\",\n  \"max_wal_senders\": 42,\n  \"max_worker_processes\": 0,\n  \"shared_buffers\": \"lorem\",\n  \"statement_timeout\": \"lorem\",\n  \"track_commit_timestamp\": true,\n  \"wal_keep_size\": \"lorem\",\n  \"wal_sender_timeout\": \"lorem\",\n  \"work_mem\": \"lorem\",\n  \"session_replication_role\": \"origin\"\n}\nGets project's Postgres config\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes200500\nResponse codes\nResponse (200)\nGet project's pgbouncer configget/v1/projects/{ref}/config/database/pgbouncerPath parametersrefRequiredstringProject refDetailsResponse codes200500Response (200)exampleschema{\n  \"pool_mode\": \"transaction\",\n  \"default_pool_size\": 42,\n  \"ignore_startup_parameters\": \"lorem\",\n  \"max_client_conn\": 42,\n  \"connection_string\": \"lorem\"\n}\nGet project's pgbouncer config\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes200500\nResponse codes\nResponse (200)\nReturns project's readonly mode statusget/v1/projects/{ref}/readonlyPath parametersrefRequiredstringProject refDetailsResponse codes200500Response (200)exampleschema{\n  \"enabled\": true,\n  \"override_enabled\": true,\n  \"override_active_until\": \"lorem\"\n}\nReturns project's readonly mode status\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes200500\nResponse codes\nResponse (200)\n[Beta] Get project's SSL enforcement configuration.get/v1/projects/{ref}/ssl-enforcementPath parametersrefRequiredstringProject refDetailsResponse codes200403500Response (200)exampleschema{\n  \"currentConfig\": {\n    \"database\": true\n  },\n  \"appliedSuccessfully\": true\n}\n[Beta] Get project's SSL enforcement configuration.\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes200403500\nResponse codes\nResponse (200)\nGets project's supavisor configget/v1/projects/{ref}/config/database/poolerPath parametersrefRequiredstringProject refDetailsResponse codes200500Response (200)exampleschema[\n  {\n    \"db_port\": 42,\n    \"default_pool_size\": 42,\n    \"max_client_conn\": 42,\n    \"identifier\": \"lorem\",\n    \"database_type\": \"PRIMARY\",\n    \"is_using_scram_auth\": true,\n    \"db_user\": \"lorem\",\n    \"db_host\": \"lorem\",\n    \"db_name\": \"lorem\",\n    \"connectionString\": \"lorem\",\n    \"pool_mode\": \"transaction\"\n  }\n]\nGets project's supavisor config\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes200500\nResponse codes\nResponse (200)\nLists all backupsget/v1/projects/{ref}/database/backupsPath parametersrefRequiredstringProject refDetailsResponse codes200500Response (200)exampleschema{\n  \"region\": \"lorem\",\n  \"walg_enabled\": true,\n  \"pitr_enabled\": true,\n  \"backups\": [\n    {\n      \"status\": \"COMPLETED\",\n      \"is_physical_backup\": true,\n      \"inserted_at\": \"lorem\"\n    }\n  ],\n  \"physical_backup_data\": {\n    \"earliest_physical_backup_date_unix\": 42,\n    \"latest_physical_backup_date_unix\": 42\n  }\n}\nLists all backups\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes200500\nResponse codes\nResponse (200)\nLists SQL snippets for the logged in userget/v1/snippetsQuery parametersproject_refOptionalstringResponse codes200500Response (200)exampleschema{\n  \"data\": [\n    {\n      \"id\": \"lorem\",\n      \"inserted_at\": \"lorem\",\n      \"updated_at\": \"lorem\",\n      \"type\": \"sql\",\n      \"visibility\": \"user\",\n      \"name\": \"lorem\",\n      \"description\": \"lorem\",\n      \"project\": {\n        \"id\": 42,\n        \"name\": \"lorem\"\n      },\n      \"owner\": {\n        \"id\": 42,\n        \"username\": \"lorem\"\n      },\n      \"updated_by\": {\n        \"id\": 42,\n        \"username\": \"lorem\"\n      }\n    }\n  ]\n}\nLists SQL snippets for the logged in user\nQuery parametersproject_refOptionalstring\nQuery parameters\nResponse codes200500\nResponse codes\nResponse (200)\n[Beta] Remove a read replicapost/v1/projects/{ref}/read-replicas/removePath parametersrefRequiredstringProject refDetailsBodydatabase_identifierRequiredstringResponse codes201403500Response (201)schema{}\n[Beta] Remove a read replica\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nBodydatabase_identifierRequiredstring\nBody\nResponse codes201403500\nResponse codes\nResponse (201)\nRestores a PITR backup for a databasepost/v1/projects/{ref}/database/backups/restore-pitrPath parametersrefRequiredstringProject refDetailsBodyrecovery_time_target_unixRequiredintegerResponse codes201Response (201)schema{}\nRestores a PITR backup for a database\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nBodyrecovery_time_target_unixRequiredinteger\nBody\nResponse codes201\nResponse codes\nResponse (201)\n[Beta] Run sql querypost/v1/projects/{ref}/database/queryPath parametersrefRequiredstringProject refDetailsBodyqueryRequiredstringResponse codes201403500Response (201)exampleschema{}\n[Beta] Run sql query\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nBodyqueryRequiredstring\nBody\nResponse codes201403500\nResponse codes\nResponse (201)\n[Beta] Set up a read replicapost/v1/projects/{ref}/read-replicas/setupPath parametersrefRequiredstringProject refDetailsBodyread_replica_regionRequiredenumAccepted valuesResponse codes201403500Response (201)schema{}\n[Beta] Set up a read replica\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nBodyread_replica_regionRequiredenumAccepted values\nBody\nResponse codes201403500\nResponse codes\nResponse (201)\nUpdates project's Postgres configput/v1/projects/{ref}/config/database/postgresPath parametersrefRequiredstringProject refDetailsBodyeffective_cache_sizeOptionalstringlogical_decoding_work_memOptionalstringmaintenance_work_memOptionalstringmax_connectionsOptionalintegermax_locks_per_transactionOptionalintegermax_parallel_maintenance_workersOptionalintegermax_parallel_workersOptionalintegermax_parallel_workers_per_gatherOptionalintegermax_replication_slotsOptionalintegermax_slot_wal_keep_sizeOptionalstringmax_standby_archive_delayOptionalstringmax_standby_streaming_delayOptionalstringmax_wal_sizeOptionalstringmax_wal_sendersOptionalintegermax_worker_processesOptionalintegershared_buffersOptionalstringstatement_timeoutOptionalstringtrack_commit_timestampOptionalbooleanwal_keep_sizeOptionalstringwal_sender_timeoutOptionalstringwork_memOptionalstringrestart_databaseOptionalbooleansession_replication_roleOptionalenumAccepted valuesResponse codes200403500Response (200)exampleschema{\n  \"effective_cache_size\": \"lorem\",\n  \"logical_decoding_work_mem\": \"lorem\",\n  \"maintenance_work_mem\": \"lorem\",\n  \"max_connections\": 1,\n  \"max_locks_per_transaction\": 10,\n  \"max_parallel_maintenance_workers\": 0,\n  \"max_parallel_workers\": 0,\n  \"max_parallel_workers_per_gather\": 0,\n  \"max_replication_slots\": 42,\n  \"max_slot_wal_keep_size\": \"lorem\",\n  \"max_standby_archive_delay\": \"lorem\",\n  \"max_standby_streaming_delay\": \"lorem\",\n  \"max_wal_size\": \"lorem\",\n  \"max_wal_senders\": 42,\n  \"max_worker_processes\": 0,\n  \"shared_buffers\": \"lorem\",\n  \"statement_timeout\": \"lorem\",\n  \"track_commit_timestamp\": true,\n  \"wal_keep_size\": \"lorem\",\n  \"wal_sender_timeout\": \"lorem\",\n  \"work_mem\": \"lorem\",\n  \"session_replication_role\": \"origin\"\n}\nUpdates project's Postgres config\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nBodyeffective_cache_sizeOptionalstringlogical_decoding_work_memOptionalstringmaintenance_work_memOptionalstringmax_connectionsOptionalintegermax_locks_per_transactionOptionalintegermax_parallel_maintenance_workersOptionalintegermax_parallel_workersOptionalintegermax_parallel_workers_per_gatherOptionalintegermax_replication_slotsOptionalintegermax_slot_wal_keep_sizeOptionalstringmax_standby_archive_delayOptionalstringmax_standby_streaming_delayOptionalstringmax_wal_sizeOptionalstringmax_wal_sendersOptionalintegermax_worker_processesOptionalintegershared_buffersOptionalstringstatement_timeoutOptionalstringtrack_commit_timestampOptionalbooleanwal_keep_sizeOptionalstringwal_sender_timeoutOptionalstringwork_memOptionalstringrestart_databaseOptionalbooleansession_replication_roleOptionalenumAccepted values\nBody\nResponse codes200403500\nResponse codes\nResponse (200)\n[Beta] Update project's SSL enforcement configuration.put/v1/projects/{ref}/ssl-enforcementPath parametersrefRequiredstringProject refDetailsBodyrequestedConfigRequiredobjectObject schemaResponse codes200403500Response (200)exampleschema{\n  \"currentConfig\": {\n    \"database\": true\n  },\n  \"appliedSuccessfully\": true\n}\n[Beta] Update project's SSL enforcement configuration.\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nBodyrequestedConfigRequiredobjectObject schema\nBody\nResponse codes200403500\nResponse codes\nResponse (200)\nUpdates project's supavisor configpatch/v1/projects/{ref}/config/database/poolerPath parametersrefRequiredstringProject refDetailsBodydefault_pool_sizeOptionalintegerpool_modeOptionalDeprecatedenumAccepted valuesResponse codes200403500Response (200)exampleschema{\n  \"default_pool_size\": 42,\n  \"pool_mode\": \"transaction\"\n}\nUpdates project's supavisor config\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nBodydefault_pool_sizeOptionalintegerpool_modeOptionalDeprecatedenumAccepted values\nBody\nResponse codes200403500\nResponse codes\nResponse (200)\n[Beta] Activates a custom hostname for a project.post/v1/projects/{ref}/custom-hostname/activatePath parametersrefRequiredstringProject refDetailsResponse codes201403500Response (201)exampleschema{\n  \"status\": \"1_not_started\",\n  \"custom_hostname\": \"lorem\",\n  \"data\": {\n    \"success\": true,\n    \"errors\": [\n      {}\n    ],\n    \"messages\": [\n      {}\n    ],\n    \"result\": {\n      \"id\": \"lorem\",\n      \"hostname\": \"lorem\",\n      \"ssl\": {\n        \"status\": \"lorem\",\n        \"validation_records\": [\n          {\n            \"txt_name\": \"lorem\",\n            \"txt_value\": \"lorem\"\n          }\n        ],\n        \"validation_errors\": [\n          {\n            \"message\": \"lorem\"\n          }\n        ]\n      },\n      \"ownership_verification\": {\n        \"type\": \"lorem\",\n        \"name\": \"lorem\",\n        \"value\": \"lorem\"\n      },\n      \"custom_origin_server\": \"lorem\",\n      \"verification_errors\": [\n        \"lorem\"\n      ],\n      \"status\": \"lorem\"\n    }\n  }\n}\n[Beta] Activates a custom hostname for a project.\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes201403500\nResponse codes\nResponse (201)\n[Beta] Activates a vanity subdomain for a project.post/v1/projects/{ref}/vanity-subdomain/activatePath parametersrefRequiredstringProject refDetailsBodyvanity_subdomainRequiredstringResponse codes201403500Response (201)exampleschema{\n  \"custom_domain\": \"lorem\"\n}\n[Beta] Activates a vanity subdomain for a project.\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nBodyvanity_subdomainRequiredstring\nBody\nResponse codes201403500\nResponse codes\nResponse (201)\n[Beta] Checks vanity subdomain availabilitypost/v1/projects/{ref}/vanity-subdomain/check-availabilityPath parametersrefRequiredstringProject refDetailsBodyvanity_subdomainRequiredstringResponse codes201403500Response (201)exampleschema{\n  \"available\": true\n}\n[Beta] Checks vanity subdomain availability\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nBodyvanity_subdomainRequiredstring\nBody\nResponse codes201403500\nResponse codes\nResponse (201)\n[Beta] Deletes a project's vanity subdomain configurationdelete/v1/projects/{ref}/vanity-subdomainPath parametersrefRequiredstringProject refDetailsResponse codes200403500Response (200)schema{}\n[Beta] Deletes a project's vanity subdomain configuration\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes200403500\nResponse codes\nResponse (200)\n[Beta] Gets project's custom hostname configget/v1/projects/{ref}/custom-hostnamePath parametersrefRequiredstringProject refDetailsResponse codes200403500Response (200)exampleschema{\n  \"status\": \"1_not_started\",\n  \"custom_hostname\": \"lorem\",\n  \"data\": {\n    \"success\": true,\n    \"errors\": [\n      {}\n    ],\n    \"messages\": [\n      {}\n    ],\n    \"result\": {\n      \"id\": \"lorem\",\n      \"hostname\": \"lorem\",\n      \"ssl\": {\n        \"status\": \"lorem\",\n        \"validation_records\": [\n          {\n            \"txt_name\": \"lorem\",\n            \"txt_value\": \"lorem\"\n          }\n        ],\n        \"validation_errors\": [\n          {\n            \"message\": \"lorem\"\n          }\n        ]\n      },\n      \"ownership_verification\": {\n        \"type\": \"lorem\",\n        \"name\": \"lorem\",\n        \"value\": \"lorem\"\n      },\n      \"custom_origin_server\": \"lorem\",\n      \"verification_errors\": [\n        \"lorem\"\n      ],\n      \"status\": \"lorem\"\n    }\n  }\n}\n[Beta] Gets project's custom hostname config\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes200403500\nResponse codes\nResponse (200)\n[Beta] Gets current vanity subdomain configget/v1/projects/{ref}/vanity-subdomainPath parametersrefRequiredstringProject refDetailsResponse codes200403500Response (200)exampleschema{\n  \"status\": \"not-used\",\n  \"custom_domain\": \"lorem\"\n}\n[Beta] Gets current vanity subdomain config\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes200403500\nResponse codes\nResponse (200)\n[Beta] Updates project's custom hostname configurationpost/v1/projects/{ref}/custom-hostname/initializePath parametersrefRequiredstringProject refDetailsBodycustom_hostnameRequiredstringResponse codes201403500Response (201)exampleschema{\n  \"status\": \"1_not_started\",\n  \"custom_hostname\": \"lorem\",\n  \"data\": {\n    \"success\": true,\n    \"errors\": [\n      {}\n    ],\n    \"messages\": [\n      {}\n    ],\n    \"result\": {\n      \"id\": \"lorem\",\n      \"hostname\": \"lorem\",\n      \"ssl\": {\n        \"status\": \"lorem\",\n        \"validation_records\": [\n          {\n            \"txt_name\": \"lorem\",\n            \"txt_value\": \"lorem\"\n          }\n        ],\n        \"validation_errors\": [\n          {\n            \"message\": \"lorem\"\n          }\n        ]\n      },\n      \"ownership_verification\": {\n        \"type\": \"lorem\",\n        \"name\": \"lorem\",\n        \"value\": \"lorem\"\n      },\n      \"custom_origin_server\": \"lorem\",\n      \"verification_errors\": [\n        \"lorem\"\n      ],\n      \"status\": \"lorem\"\n    }\n  }\n}\n[Beta] Updates project's custom hostname configuration\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nBodycustom_hostnameRequiredstring\nBody\nResponse codes201403500\nResponse codes\nResponse (201)\n[Beta] Attempts to verify the DNS configuration for project's custom hostname configurationpost/v1/projects/{ref}/custom-hostname/reverifyPath parametersrefRequiredstringProject refDetailsResponse codes201403500Response (201)exampleschema{\n  \"status\": \"1_not_started\",\n  \"custom_hostname\": \"lorem\",\n  \"data\": {\n    \"success\": true,\n    \"errors\": [\n      {}\n    ],\n    \"messages\": [\n      {}\n    ],\n    \"result\": {\n      \"id\": \"lorem\",\n      \"hostname\": \"lorem\",\n      \"ssl\": {\n        \"status\": \"lorem\",\n        \"validation_records\": [\n          {\n            \"txt_name\": \"lorem\",\n            \"txt_value\": \"lorem\"\n          }\n        ],\n        \"validation_errors\": [\n          {\n            \"message\": \"lorem\"\n          }\n        ]\n      },\n      \"ownership_verification\": {\n        \"type\": \"lorem\",\n        \"name\": \"lorem\",\n        \"value\": \"lorem\"\n      },\n      \"custom_origin_server\": \"lorem\",\n      \"verification_errors\": [\n        \"lorem\"\n      ],\n      \"status\": \"lorem\"\n    }\n  }\n}\n[Beta] Attempts to verify the DNS configuration for project's custom hostname configuration\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes201403500\nResponse codes\nResponse (201)\nCreate a functionpost/v1/projects/{ref}/functionsCreates a function and adds it to the specified project.Path parametersrefRequiredstringProject refDetailsQuery parametersslugOptionalstringDetailsnameOptionalstringverify_jwtOptionalbooleanimport_mapOptionalbooleanentrypoint_pathOptionalstringimport_map_pathOptionalstringBodyslugRequiredstringDetailsnameRequiredstringbodyRequiredstringverify_jwtOptionalbooleanslugRequiredstringDetailsnameRequiredstringbodyRequiredstringverify_jwtOptionalbooleanResponse codes201403500Response (201)exampleschema{\n  \"version\": 42,\n  \"created_at\": 42,\n  \"updated_at\": 42,\n  \"id\": \"lorem\",\n  \"slug\": \"lorem\",\n  \"name\": \"lorem\",\n  \"status\": \"ACTIVE\",\n  \"verify_jwt\": true,\n  \"import_map\": true,\n  \"entrypoint_path\": \"lorem\",\n  \"import_map_path\": \"lorem\"\n}\nCreate a function\nCreates a function and adds it to the specified project.\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nQuery parametersslugOptionalstringDetailsnameOptionalstringverify_jwtOptionalbooleanimport_mapOptionalbooleanentrypoint_pathOptionalstringimport_map_pathOptionalstring\nQuery parameters\nBodyslugRequiredstringDetailsnameRequiredstringbodyRequiredstringverify_jwtOptionalbooleanslugRequiredstringDetailsnameRequiredstringbodyRequiredstringverify_jwtOptionalboolean\nBody\nResponse codes201403500\nResponse codes\nResponse (201)\nDelete a functiondelete/v1/projects/{ref}/functions/{function_slug}Deletes a function with the specified slug from the specified project.Path parametersrefRequiredstringProject refDetailsfunction_slugRequiredstringFunction slugDetailsResponse codes200403500Response (200)schema{}\nDelete a function\nDeletes a function with the specified slug from the specified project.\nPath parametersrefRequiredstringProject refDetailsfunction_slugRequiredstringFunction slugDetails\nPath parameters\nProject ref\nFunction slug\nResponse codes200403500\nResponse codes\nResponse (200)\nRetrieve a functionget/v1/projects/{ref}/functions/{function_slug}Retrieves a function with the specified slug and project.Path parametersrefRequiredstringProject refDetailsfunction_slugRequiredstringFunction slugDetailsResponse codes200403500Response (200)exampleschema{\n  \"version\": 42,\n  \"created_at\": 42,\n  \"updated_at\": 42,\n  \"id\": \"lorem\",\n  \"slug\": \"lorem\",\n  \"name\": \"lorem\",\n  \"status\": \"ACTIVE\",\n  \"verify_jwt\": true,\n  \"import_map\": true,\n  \"entrypoint_path\": \"lorem\",\n  \"import_map_path\": \"lorem\"\n}\nRetrieve a function\nRetrieves a function with the specified slug and project.\nPath parametersrefRequiredstringProject refDetailsfunction_slugRequiredstringFunction slugDetails\nPath parameters\nProject ref\nFunction slug\nResponse codes200403500\nResponse codes\nResponse (200)\nRetrieve a function bodyget/v1/projects/{ref}/functions/{function_slug}/bodyRetrieves a function body for the specified slug and project.Path parametersrefRequiredstringProject refDetailsfunction_slugRequiredstringFunction slugDetailsResponse codes200403500Response (200)schema{}\nRetrieve a function body\nRetrieves a function body for the specified slug and project.\nPath parametersrefRequiredstringProject refDetailsfunction_slugRequiredstringFunction slugDetails\nPath parameters\nProject ref\nFunction slug\nResponse codes200403500\nResponse codes\nResponse (200)\nList all functionsget/v1/projects/{ref}/functionsReturns all functions you've previously added to the specified project.Path parametersrefRequiredstringProject refDetailsResponse codes200403500Response (200)exampleschema[\n  {\n    \"version\": 42,\n    \"created_at\": 42,\n    \"updated_at\": 42,\n    \"id\": \"lorem\",\n    \"slug\": \"lorem\",\n    \"name\": \"lorem\",\n    \"status\": \"ACTIVE\",\n    \"verify_jwt\": true,\n    \"import_map\": true,\n    \"entrypoint_path\": \"lorem\",\n    \"import_map_path\": \"lorem\"\n  }\n]\nList all functions\nReturns all functions you've previously added to the specified project.\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes200403500\nResponse codes\nResponse (200)\nUpdate a functionpatch/v1/projects/{ref}/functions/{function_slug}Updates a function with the specified slug and project.Path parametersrefRequiredstringProject refDetailsfunction_slugRequiredstringFunction slugDetailsQuery parametersslugOptionalstringDetailsnameOptionalstringverify_jwtOptionalbooleanimport_mapOptionalbooleanentrypoint_pathOptionalstringimport_map_pathOptionalstringBodynameOptionalstringbodyOptionalstringverify_jwtOptionalbooleannameOptionalstringbodyOptionalstringverify_jwtOptionalbooleanResponse codes200403500Response (200)exampleschema{\n  \"version\": 42,\n  \"created_at\": 42,\n  \"updated_at\": 42,\n  \"id\": \"lorem\",\n  \"slug\": \"lorem\",\n  \"name\": \"lorem\",\n  \"status\": \"ACTIVE\",\n  \"verify_jwt\": true,\n  \"import_map\": true,\n  \"entrypoint_path\": \"lorem\",\n  \"import_map_path\": \"lorem\"\n}\nUpdate a function\nUpdates a function with the specified slug and project.\nPath parametersrefRequiredstringProject refDetailsfunction_slugRequiredstringFunction slugDetails\nPath parameters\nProject ref\nFunction slug\nQuery parametersslugOptionalstringDetailsnameOptionalstringverify_jwtOptionalbooleanimport_mapOptionalbooleanentrypoint_pathOptionalstringimport_map_pathOptionalstring\nQuery parameters\nBodynameOptionalstringbodyOptionalstringverify_jwtOptionalbooleannameOptionalstringbodyOptionalstringverify_jwtOptionalboolean\nBody\nResponse codes200403500\nResponse codes\nResponse (200)\nCreate a database branchpost/v1/projects/{ref}/branchesCreates a database branch from the specified project.Path parametersrefRequiredstringProject refDetailsBodydesired_instance_sizeOptionalenumAccepted valuesrelease_channelOptionalenumAccepted valuespostgres_engineOptionalenumAccepted valuesbranch_nameRequiredstringgit_branchOptionalstringpersistentOptionalbooleanregionOptionalstringResponse codes201500Response (201)exampleschema{\n  \"pr_number\": 42,\n  \"latest_check_run_id\": 42,\n  \"id\": \"lorem\",\n  \"name\": \"lorem\",\n  \"project_ref\": \"lorem\",\n  \"parent_project_ref\": \"lorem\",\n  \"is_default\": true,\n  \"git_branch\": \"lorem\",\n  \"reset_on_push\": true,\n  \"persistent\": true,\n  \"status\": \"CREATING_PROJECT\",\n  \"created_at\": \"lorem\",\n  \"updated_at\": \"lorem\"\n}\nCreate a database branch\nCreates a database branch from the specified project.\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nBodydesired_instance_sizeOptionalenumAccepted valuesrelease_channelOptionalenumAccepted valuespostgres_engineOptionalenumAccepted valuesbranch_nameRequiredstringgit_branchOptionalstringpersistentOptionalbooleanregionOptionalstring\nBody\nResponse codes201500\nResponse codes\nResponse (201)\nDelete a database branchdelete/v1/branches/{branch_id}Deletes the specified database branchPath parametersbranch_idRequiredstringBranch IDResponse codes200500Response (200)exampleschema{\n  \"message\": \"lorem\"\n}\nDelete a database branch\nDeletes the specified database branch\nPath parametersbranch_idRequiredstringBranch ID\nPath parameters\nBranch ID\nResponse codes200500\nResponse codes\nResponse (200)\nDisables preview branchingdelete/v1/projects/{ref}/branchesDisables preview branching for the specified projectPath parametersrefRequiredstringProject refDetailsResponse codes200500Response (200)schema{}\nDisables preview branching\nDisables preview branching for the specified project\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes200500\nResponse codes\nResponse (200)\nGet database branch configget/v1/branches/{branch_id}Fetches configurations of the specified database branchPath parametersbranch_idRequiredstringBranch IDResponse codes200500Response (200)exampleschema{\n  \"db_port\": 42,\n  \"ref\": \"lorem\",\n  \"postgres_version\": \"lorem\",\n  \"postgres_engine\": \"lorem\",\n  \"release_channel\": \"lorem\",\n  \"status\": \"ACTIVE_HEALTHY\",\n  \"db_host\": \"lorem\",\n  \"db_user\": \"lorem\",\n  \"db_pass\": \"lorem\",\n  \"jwt_secret\": \"lorem\"\n}\nGet database branch config\nFetches configurations of the specified database branch\nPath parametersbranch_idRequiredstringBranch ID\nPath parameters\nBranch ID\nResponse codes200500\nResponse codes\nResponse (200)\nList all database branchesget/v1/projects/{ref}/branchesReturns all database branches of the specified project.Path parametersrefRequiredstringProject refDetailsResponse codes200500Response (200)exampleschema[\n  {\n    \"pr_number\": 42,\n    \"latest_check_run_id\": 42,\n    \"id\": \"lorem\",\n    \"name\": \"lorem\",\n    \"project_ref\": \"lorem\",\n    \"parent_project_ref\": \"lorem\",\n    \"is_default\": true,\n    \"git_branch\": \"lorem\",\n    \"reset_on_push\": true,\n    \"persistent\": true,\n    \"status\": \"CREATING_PROJECT\",\n    \"created_at\": \"lorem\",\n    \"updated_at\": \"lorem\"\n  }\n]\nList all database branches\nReturns all database branches of the specified project.\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes200500\nResponse codes\nResponse (200)\nResets a database branchpost/v1/branches/{branch_id}/resetResets the specified database branchPath parametersbranch_idRequiredstringBranch IDResponse codes201500Response (201)exampleschema{\n  \"workflow_run_id\": \"lorem\",\n  \"message\": \"lorem\"\n}\nResets a database branch\nResets the specified database branch\nPath parametersbranch_idRequiredstringBranch ID\nPath parameters\nBranch ID\nResponse codes201500\nResponse codes\nResponse (201)\nUpdate database branch configpatch/v1/branches/{branch_id}Updates the configuration of the specified database branchPath parametersbranch_idRequiredstringBranch IDBodybranch_nameOptionalstringgit_branchOptionalstringreset_on_pushOptionalbooleanpersistentOptionalbooleanstatusOptionalenumAccepted valuesResponse codes200500Response (200)exampleschema{\n  \"pr_number\": 42,\n  \"latest_check_run_id\": 42,\n  \"id\": \"lorem\",\n  \"name\": \"lorem\",\n  \"project_ref\": \"lorem\",\n  \"parent_project_ref\": \"lorem\",\n  \"is_default\": true,\n  \"git_branch\": \"lorem\",\n  \"reset_on_push\": true,\n  \"persistent\": true,\n  \"status\": \"CREATING_PROJECT\",\n  \"created_at\": \"lorem\",\n  \"updated_at\": \"lorem\"\n}\nUpdate database branch config\nUpdates the configuration of the specified database branch\nPath parametersbranch_idRequiredstringBranch ID\nPath parameters\nBranch ID\nBodybranch_nameOptionalstringgit_branchOptionalstringreset_on_pushOptionalbooleanpersistentOptionalbooleanstatusOptionalenumAccepted values\nBody\nResponse codes200500\nResponse codes\nResponse (200)\n[Beta] Authorize user through oauthget/v1/oauth/authorizeQuery parametersclient_idRequiredstringresponse_typeRequiredenumAccepted valuesredirect_uriRequiredstringscopeOptionalstringstateOptionalstringresponse_modeOptionalstringcode_challengeOptionalstringcode_challenge_methodOptionalenumAccepted valuesResponse codes303\n[Beta] Authorize user through oauth\nQuery parametersclient_idRequiredstringresponse_typeRequiredenumAccepted valuesredirect_uriRequiredstringscopeOptionalstringstateOptionalstringresponse_modeOptionalstringcode_challengeOptionalstringcode_challenge_methodOptionalenumAccepted values\nQuery parameters\nResponse codes303\nResponse codes\n[Beta] Exchange auth code for user's access and refresh tokenpost/v1/oauth/tokenBodygrant_typeRequiredenumAccepted valuesclient_idRequiredstringclient_secretRequiredstringcodeOptionalstringcode_verifierOptionalstringredirect_uriOptionalstringrefresh_tokenOptionalstringResponse codes201Response (201)exampleschema{\n  \"expires_in\": 42,\n  \"token_type\": \"Bearer\",\n  \"access_token\": \"lorem\",\n  \"refresh_token\": \"lorem\"\n}\n[Beta] Exchange auth code for user's access and refresh token\nBodygrant_typeRequiredenumAccepted valuesclient_idRequiredstringclient_secretRequiredstringcodeOptionalstringcode_verifierOptionalstringredirect_uriOptionalstringrefresh_tokenOptionalstring\nBody\nResponse codes201\nResponse codes\nResponse (201)\nCreate an organizationpost/v1/organizationsBodynameRequiredstringResponse codes201500Response (201)exampleschema{\n  \"id\": \"lorem\",\n  \"name\": \"lorem\"\n}\nCreate an organization\nBodynameRequiredstring\nBody\nResponse codes201500\nResponse codes\nResponse (201)\nGets information about the organizationget/v1/organizations/{slug}Path parametersslugRequiredstringResponse codes200Response (200)exampleschema{\n  \"plan\": \"free\",\n  \"opt_in_tags\": [\n    \"AI_SQL_GENERATOR_OPT_IN\"\n  ],\n  \"allowed_release_channels\": [\n    \"internal\"\n  ],\n  \"id\": \"lorem\",\n  \"name\": \"lorem\"\n}\nGets information about the organization\nPath parametersslugRequiredstring\nPath parameters\nResponse codes200\nResponse codes\nResponse (200)\nList all organizationsget/v1/organizationsReturns a list of organizations that you currently belong to.Response codes200500Response (200)exampleschema[\n  {\n    \"id\": \"lorem\",\n    \"name\": \"lorem\"\n  }\n]\nList all organizations\nReturns a list of organizations that you currently belong to.\nResponse codes200500\nResponse codes\nResponse (200)\nList members of an organizationget/v1/organizations/{slug}/membersPath parametersslugRequiredstringResponse codes200Response (200)exampleschema[\n  {\n    \"user_id\": \"lorem\",\n    \"user_name\": \"lorem\",\n    \"email\": \"lorem\",\n    \"role_name\": \"lorem\",\n    \"mfa_enabled\": true\n  }\n]\nList members of an organization\nPath parametersslugRequiredstring\nPath parameters\nResponse codes200\nResponse codes\nResponse (200)\nCreate a projectpost/v1/projectsBodydb_passRequiredstringnameRequiredstringorganization_idRequiredstringplanOptionalDeprecatedenumAccepted valuesregionRequiredenumAccepted valueskps_enabledOptionalDeprecatedbooleandesired_instance_sizeOptionalenumAccepted valuestemplate_urlOptionalstringrelease_channelOptionalenumAccepted valuespostgres_engineOptionalenumAccepted valuesResponse codes201Response (201)exampleschema{\n  \"id\": \"lorem\",\n  \"organization_id\": \"lorem\",\n  \"name\": \"lorem\",\n  \"region\": \"us-east-1\",\n  \"created_at\": \"2023-03-29T16:32:59Z\",\n  \"database\": {\n    \"host\": \"lorem\",\n    \"version\": \"lorem\",\n    \"postgres_engine\": \"lorem\",\n    \"release_channel\": \"lorem\"\n  },\n  \"status\": \"ACTIVE_HEALTHY\"\n}\nCreate a project\nBodydb_passRequiredstringnameRequiredstringorganization_idRequiredstringplanOptionalDeprecatedenumAccepted valuesregionRequiredenumAccepted valueskps_enabledOptionalDeprecatedbooleandesired_instance_sizeOptionalenumAccepted valuestemplate_urlOptionalstringrelease_channelOptionalenumAccepted valuespostgres_engineOptionalenumAccepted values\nBody\nResponse codes201\nResponse codes\nResponse (201)\nDeletes the given projectdelete/v1/projects/{ref}Path parametersrefRequiredstringProject refDetailsResponse codes200403Response (200)exampleschema{\n  \"id\": 42,\n  \"ref\": \"lorem\",\n  \"name\": \"lorem\"\n}\nDeletes the given project\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes200403\nResponse codes\nResponse (200)\n[Beta] Remove network bans.delete/v1/projects/{ref}/network-bansPath parametersrefRequiredstringProject refDetailsBodyipv4_addressesRequiredArray<string>Response codes200403500Response (200)schema{}\n[Beta] Remove network bans.\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nBodyipv4_addressesRequiredArray<string>\nBody\nResponse codes200403500\nResponse codes\nResponse (200)\n[Beta] Gets project's network restrictionsget/v1/projects/{ref}/network-restrictionsPath parametersrefRequiredstringProject refDetailsResponse codes200403500Response (200)exampleschema{\n  \"entitlement\": \"disallowed\",\n  \"config\": {\n    \"dbAllowedCidrs\": [\n      \"lorem\"\n    ],\n    \"dbAllowedCidrsV6\": [\n      \"lorem\"\n    ]\n  },\n  \"old_config\": {\n    \"dbAllowedCidrs\": [\n      \"lorem\"\n    ],\n    \"dbAllowedCidrsV6\": [\n      \"lorem\"\n    ]\n  },\n  \"status\": \"stored\"\n}\n[Beta] Gets project's network restrictions\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes200403500\nResponse codes\nResponse (200)\n[Beta] Returns the project's eligibility for upgradesget/v1/projects/{ref}/upgrade/eligibilityPath parametersrefRequiredstringProject refDetailsResponse codes200403500Response (200)exampleschema{\n  \"current_app_version_release_channel\": \"internal\",\n  \"duration_estimate_hours\": 42,\n  \"eligible\": true,\n  \"current_app_version\": \"lorem\",\n  \"latest_app_version\": \"lorem\",\n  \"target_upgrade_versions\": [\n    {\n      \"postgres_version\": \"15\",\n      \"release_channel\": \"internal\",\n      \"app_version\": \"lorem\"\n    }\n  ],\n  \"potential_breaking_changes\": [\n    \"lorem\"\n  ],\n  \"legacy_auth_custom_roles\": [\n    \"lorem\"\n  ],\n  \"extension_dependent_objects\": [\n    \"lorem\"\n  ]\n}\n[Beta] Returns the project's eligibility for upgrades\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes200403500\nResponse codes\nResponse (200)\n[Beta] Gets the latest status of the project's upgradeget/v1/projects/{ref}/upgrade/statusPath parametersrefRequiredstringProject refDetailsQuery parameterstracking_idOptionalstringResponse codes200403500Response (200)exampleschema{\n  \"databaseUpgradeStatus\": {\n    \"target_version\": 42,\n    \"status\": 0,\n    \"initiated_at\": \"lorem\",\n    \"latest_status_at\": \"lorem\",\n    \"error\": \"1_upgraded_instance_launch_failed\",\n    \"progress\": \"0_requested\"\n  }\n}\n[Beta] Gets the latest status of the project's upgrade\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nQuery parameterstracking_idOptionalstring\nQuery parameters\nResponse codes200403500\nResponse codes\nResponse (200)\nGets a specific project that belongs to the authenticated userget/v1/projects/{ref}Path parametersrefRequiredstringProject refDetailsResponse codes200500Response (200)exampleschema{\n  \"id\": \"lorem\",\n  \"organization_id\": \"lorem\",\n  \"name\": \"lorem\",\n  \"region\": \"us-east-1\",\n  \"created_at\": \"2023-03-29T16:32:59Z\",\n  \"database\": {\n    \"host\": \"lorem\",\n    \"version\": \"lorem\",\n    \"postgres_engine\": \"lorem\",\n    \"release_channel\": \"lorem\"\n  },\n  \"status\": \"ACTIVE_HEALTHY\"\n}\nGets a specific project that belongs to the authenticated user\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes200500\nResponse codes\nResponse (200)\nGets project's service health statusget/v1/projects/{ref}/healthPath parametersrefRequiredstringProject refDetailsQuery parameterstimeout_msOptionalintegerservicesRequiredArray<enum>Response codes200403500Response (200)exampleschema[\n  {\n    \"info\": {\n      \"name\": \"GoTrue\"\n    },\n    \"name\": \"auth\",\n    \"healthy\": true,\n    \"status\": \"COMING_UP\",\n    \"error\": \"lorem\"\n  }\n]\nGets project's service health status\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nQuery parameterstimeout_msOptionalintegerservicesRequiredArray<enum>\nQuery parameters\nResponse codes200403500\nResponse codes\nResponse (200)\n[Beta] Gets project's network banspost/v1/projects/{ref}/network-bans/retrievePath parametersrefRequiredstringProject refDetailsResponse codes201403500Response (201)exampleschema{\n  \"banned_ipv4_addresses\": [\n    \"lorem\"\n  ]\n}\n[Beta] Gets project's network bans\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes201403500\nResponse codes\nResponse (201)\nList all projectsget/v1/projectsReturns a list of all projects you've previously created.Response codes200Response (200)exampleschema[\n  {\n    \"id\": \"lorem\",\n    \"organization_id\": \"lorem\",\n    \"name\": \"lorem\",\n    \"region\": \"us-east-1\",\n    \"created_at\": \"2023-03-29T16:32:59Z\",\n    \"database\": {\n      \"host\": \"lorem\",\n      \"version\": \"lorem\",\n      \"postgres_engine\": \"lorem\",\n      \"release_channel\": \"lorem\"\n    },\n    \"status\": \"ACTIVE_HEALTHY\"\n  }\n]\nList all projects\nReturns a list of all projects you've previously created.\nResponse codes200\nResponse codes\nResponse (200)\n[Beta] Updates project's network restrictionspost/v1/projects/{ref}/network-restrictions/applyPath parametersrefRequiredstringProject refDetailsBodydbAllowedCidrsOptionalArray<string>dbAllowedCidrsV6OptionalArray<string>Response codes201403500Response (201)exampleschema{\n  \"entitlement\": \"disallowed\",\n  \"config\": {\n    \"dbAllowedCidrs\": [\n      \"lorem\"\n    ],\n    \"dbAllowedCidrsV6\": [\n      \"lorem\"\n    ]\n  },\n  \"old_config\": {\n    \"dbAllowedCidrs\": [\n      \"lorem\"\n    ],\n    \"dbAllowedCidrsV6\": [\n      \"lorem\"\n    ]\n  },\n  \"status\": \"stored\"\n}\n[Beta] Updates project's network restrictions\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nBodydbAllowedCidrsOptionalArray<string>dbAllowedCidrsV6OptionalArray<string>\nBody\nResponse codes201403500\nResponse codes\nResponse (201)\n[Beta] Upgrades the project's Postgres versionpost/v1/projects/{ref}/upgradePath parametersrefRequiredstringProject refDetailsBodyrelease_channelRequiredenumAccepted valuestarget_versionRequiredstringResponse codes201403500Response (201)exampleschema{\n  \"tracking_id\": \"lorem\"\n}\n[Beta] Upgrades the project's Postgres version\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nBodyrelease_channelRequiredenumAccepted valuestarget_versionRequiredstring\nBody\nResponse codes201403500\nResponse codes\nResponse (201)\nGets project's postgrest configget/v1/projects/{ref}/postgrestPath parametersrefRequiredstringProject refDetailsResponse codes200403500Response (200)exampleschema{\n  \"max_rows\": 42,\n  \"db_pool\": 42,\n  \"db_schema\": \"lorem\",\n  \"db_extra_search_path\": \"lorem\",\n  \"jwt_secret\": \"lorem\"\n}\nGets project's postgrest config\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes200403500\nResponse codes\nResponse (200)\nUpdates project's postgrest configpatch/v1/projects/{ref}/postgrestPath parametersrefRequiredstringProject refDetailsBodymax_rowsOptionalintegerdb_poolOptionalintegerdb_extra_search_pathOptionalstringdb_schemaOptionalstringResponse codes200403500Response (200)exampleschema{\n  \"max_rows\": 42,\n  \"db_pool\": 42,\n  \"db_schema\": \"lorem\",\n  \"db_extra_search_path\": \"lorem\"\n}\nUpdates project's postgrest config\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nBodymax_rowsOptionalintegerdb_poolOptionalintegerdb_extra_search_pathOptionalstringdb_schemaOptionalstring\nBody\nResponse codes200403500\nResponse codes\nResponse (200)\nBulk create secretspost/v1/projects/{ref}/secretsCreates multiple secrets and adds them to the specified project.Path parametersrefRequiredstringProject refDetailsBodyArray of objectObject schemaResponse codes201403500Response (201)schema{}\nBulk create secrets\nCreates multiple secrets and adds them to the specified project.\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nBodyArray of objectObject schema\nBody\nResponse codes201403500\nResponse codes\nResponse (201)\nBulk delete secretsdelete/v1/projects/{ref}/secretsDeletes all secrets with the given names from the specified projectPath parametersrefRequiredstringProject refDetailsBodyArray of stringResponse codes200403500Response (200)exampleschema{}\nBulk delete secrets\nDeletes all secrets with the given names from the specified project\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nBodyArray of string\nBody\nResponse codes200403500\nResponse codes\nResponse (200)\n[Beta] Gets project's pgsodium configget/v1/projects/{ref}/pgsodiumPath parametersrefRequiredstringProject refDetailsResponse codes200403500Response (200)exampleschema{\n  \"root_key\": \"lorem\"\n}\n[Beta] Gets project's pgsodium config\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes200403500\nResponse codes\nResponse (200)\nGet project api keysget/v1/projects/{ref}/api-keysPath parametersrefRequiredstringProject refDetailsResponse codes200Response (200)exampleschema[\n  {\n    \"name\": \"lorem\",\n    \"api_key\": \"lorem\",\n    \"id\": \"lorem\",\n    \"type\": {},\n    \"prefix\": \"lorem\",\n    \"description\": \"lorem\",\n    \"hash\": \"lorem\",\n    \"secret_jwt_template\": {\n      \"role\": \"lorem\"\n    },\n    \"inserted_at\": \"lorem\",\n    \"updated_at\": \"lorem\"\n  }\n]\nGet project api keys\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes200\nResponse codes\nResponse (200)\nList all secretsget/v1/projects/{ref}/secretsReturns all secrets you've previously added to the specified project.Path parametersrefRequiredstringProject refDetailsResponse codes200403500Response (200)exampleschema[\n  {\n    \"name\": \"lorem\",\n    \"value\": \"lorem\"\n  }\n]\nList all secrets\nReturns all secrets you've previously added to the specified project.\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes200403500\nResponse codes\nResponse (200)\n[Beta] Updates project's pgsodium config. Updating the root_key can cause all data encrypted with the older key to become inaccessible.put/v1/projects/{ref}/pgsodiumPath parametersrefRequiredstringProject refDetailsBodyroot_keyRequiredstringResponse codes200403500Response (200)exampleschema{\n  \"root_key\": \"lorem\"\n}\n[Beta] Updates project's pgsodium config. Updating the root_key can cause all data encrypted with the older key to become inaccessible.\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nBodyroot_keyRequiredstring\nBody\nResponse codes200403500\nResponse codes\nResponse (200)\nGets project's storage configget/v1/projects/{ref}/config/storagePath parametersrefRequiredstringProject refDetailsResponse codes200403500Response (200)exampleschema{\n  \"fileSizeLimit\": 42,\n  \"features\": {\n    \"imageTransformation\": {\n      \"enabled\": true\n    }\n  }\n}\nGets project's storage config\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes200403500\nResponse codes\nResponse (200)\nLists all bucketsget/v1/projects/{ref}/storage/bucketsPath parametersrefRequiredstringProject refDetailsResponse codes200403500Response (200)exampleschema[\n  {\n    \"id\": \"lorem\",\n    \"name\": \"lorem\",\n    \"owner\": \"lorem\",\n    \"created_at\": \"lorem\",\n    \"updated_at\": \"lorem\",\n    \"public\": true\n  }\n]\nLists all buckets\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nResponse codes200403500\nResponse codes\nResponse (200)\nUpdates project's storage configpatch/v1/projects/{ref}/config/storagePath parametersrefRequiredstringProject refDetailsBodyfileSizeLimitOptionalintegerfeaturesOptionalobjectObject schemaResponse codes200403500Response (200)schema{}\nUpdates project's storage config\nPath parametersrefRequiredstringProject refDetails\nPath parameters\nProject ref\nBodyfileSizeLimitOptionalintegerfeaturesOptionalobjectObject schema\nBody\nResponse codes200403500\nResponse codes\nResponse (200)\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "39",
    "url": "https://supabase.com/docs/reference/cli/introduction",
    "title": "504: GATEWAY_TIMEOUT",
    "content": "This Serverless Function has timed out.\nYour connection is working correctly.\nVercel is working correctly.\n504: GATEWAY_TIMEOUT\nCode: FUNCTION_INVOCATION_TIMEOUT\nID: bom1:bom1::5pbsm-1732204498590-240d3eb277ad\n\n"
  },
  {
    "id": "40",
    "url": "https://supabase.com/docs/guides/platform",
    "title": "Supabase Platform | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nSupabase PlatformSupabase is a hosted platform which makes it very simple to get started without needing to manage any infrastructure.\nVisit supabase.com/dashboard and sign in to start creating projects.\nProjects#\nEach project on Supabase comes with:\n\nA dedicated Postgres database\nAuto-generated APIs\nAuth and user management\nEdge Functions\nRealtime API\nStorage\n\nOrganizations#\nOrganizations are a way to group your projects. Each organization can be configured with different team members and billing settings.\nRefer to access control for more information on how to manage team members within an organization.\nPlatform status#\nIf Supabase experiences outages, we keep you as informed as possible, as early as possible. We provide the following feedback channels:\n\nStatus page: status.supabase.com\nRSS Feed: status.supabase.com/history.rss\nAtom Feed: status.supabase.com/history.atom\nSlack Alerts: You can receive updates via the RSS feed, using Slack's built-in RSS functionality /feed subscribe https://status.supabase.com/history.atom\n\nMake sure to review our SLA for details on our commitment to Platform Stability.Edit this page on GitHub\nSupabase Platform\nSupabase is a hosted platform which makes it very simple to get started without needing to manage any infrastructure.\nVisit supabase.com/dashboard and sign in to start creating projects.\nProjects#\nEach project on Supabase comes with:\nOrganizations#\nOrganizations are a way to group your projects. Each organization can be configured with different team members and billing settings.\nRefer to access control for more information on how to manage team members within an organization.\nPlatform status#\nIf Supabase experiences outages, we keep you as informed as possible, as early as possible. We provide the following feedback channels:\nMake sure to review our SLA for details on our commitment to Platform Stability.\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "41",
    "url": "https://supabase.com/docs/guides/integrations",
    "title": "Integrations | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nIntegrationsSupabase integrates with many of your favorite third-party services.\nVercel Marketplace#\nCreate and manage your Supabase projects directly through Vercel. Get started with Vercel.\nSupabase Marketplace#\nBrowse tools for extending your Supabase project. Browse the Supabase Marketplace.Edit this page on GitHub\nIntegrations\nSupabase integrates with many of your favorite third-party services.\nVercel Marketplace#\nCreate and manage your Supabase projects directly through Vercel. Get started with Vercel.\nSupabase Marketplace#\nBrowse tools for extending your Supabase project. Browse the Supabase Marketplace.\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "42",
    "url": "https://supabase.com/docs/guides/self-hosting",
    "title": "Self-Hosting | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nSelf-HostingHost Supabase on your own infrastructure.There are several ways to host Supabase on your own computer, server, or cloud.\nOfficially supported#\nMost commonDockerDeploy Supabase within your own infrastructure using Docker Compose.BYO CloudContact our Enterprise sales team if you need Supabase managed in your own cloud.\nSupabase is also a hosted platform. If you want to get started for free, visit supabase.com/dashboard.\nCommunity supported#\nThere are several community-driven projects to help you deploy Supabase. We encourage you to try them out and contribute back to the community.\nKubernetesHelm charts to deploy a Supabase on Kubernetes.TerraformA community-driven Terraform Provider for Supabase.TraefikA self-hosted Supabase setup with Traefik as a reverse proxy.AWSA CloudFormation template for Supabase.\n\nThird-party guides#\nThe following third-party providers have shown consistent support for the self-hosted version of Supabase:.\nDigital OceanDeploys using Terraform.StackGresDeploys using Kubernetes.Edit this page on GitHub\nSelf-Hosting\nHost Supabase on your own infrastructure.\nThere are several ways to host Supabase on your own computer, server, or cloud.\nOfficially supported#\nMost common\nDocker\nDeploy Supabase within your own infrastructure using Docker Compose.\nBYO Cloud\nSupabase is also a hosted platform. If you want to get started for free, visit supabase.com/dashboard.\nCommunity supported#\nThere are several community-driven projects to help you deploy Supabase. We encourage you to try them out and contribute back to the community.\nKubernetes\nTerraform\nTraefik\nAWS\nThird-party guides#\nThe following third-party providers have shown consistent support for the self-hosted version of Supabase:.\nDigital Ocean\nStackGres\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "43",
    "url": "https://supabase.com/docs/reference/self-hosting-auth/introduction",
    "title": "Self-Hosting | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nSelf-Hosting Auth\nThe Supabase Auth Server (GoTrue) is a JSON Web Token (JWT)-based API for managing users and issuing access tokens.GoTrue is an open-source API written in Golang, that acts as a self-standing API service for handling user registration and authentication for JAM projects. It's based on OAuth2 and JWT and handles user signup, authentication, and custom user data.Client libraries#\nJavaScript\nDart\nAdditional links#\nSource code\nKnown bugs and issues\nAuth guides\nGenerates an email action link.post/admin/generate_linkBodydataOptionalobjectObject schemaemailOptionalstringnew_emailOptionalstringpasswordOptionalstringredirect_toOptionalstringtypeOptionalstringResponse codes200401Response (200)exampleschema{\n  \"action_link\": \"lorem\",\n  \"app_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  },\n  \"aud\": \"lorem\",\n  \"banned_until\": \"2021-12-31T23:34:00Z\",\n  \"confirmation_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"created_at\": \"2021-12-31T23:34:00Z\",\n  \"email\": \"lorem\",\n  \"email_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"email_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"email_otp\": \"lorem\",\n  \"hashed_token\": \"lorem\",\n  \"id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\",\n  \"identities\": [\n    {\n      \"created_at\": \"2021-12-31T23:34:00Z\",\n      \"id\": \"lorem\",\n      \"identity_data\": {\n        \"property1\": null,\n        \"property2\": null\n      },\n      \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n      \"provider\": \"lorem\",\n      \"updated_at\": \"2021-12-31T23:34:00Z\",\n      \"user_id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\"\n    }\n  ],\n  \"invited_at\": \"2021-12-31T23:34:00Z\",\n  \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n  \"new_email\": \"lorem\",\n  \"new_phone\": \"lorem\",\n  \"phone\": \"lorem\",\n  \"phone_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"phone_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"reauthentication_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"recovery_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"redirect_to\": \"lorem\",\n  \"role\": \"lorem\",\n  \"updated_at\": \"2021-12-31T23:34:00Z\",\n  \"user_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  },\n  \"verification_type\": \"lorem\"\n}  Get a user.get/admin/user/{user_id}Path parametersuser_idRequiredThe user's idResponse codes200401Response (200)exampleschema{\n  \"app_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  },\n  \"aud\": \"lorem\",\n  \"banned_until\": \"2021-12-31T23:34:00Z\",\n  \"confirmation_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"created_at\": \"2021-12-31T23:34:00Z\",\n  \"email\": \"lorem\",\n  \"email_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"email_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\",\n  \"identities\": [\n    {\n      \"created_at\": \"2021-12-31T23:34:00Z\",\n      \"id\": \"lorem\",\n      \"identity_data\": {\n        \"property1\": null,\n        \"property2\": null\n      },\n      \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n      \"provider\": \"lorem\",\n      \"updated_at\": \"2021-12-31T23:34:00Z\",\n      \"user_id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\"\n    }\n  ],\n  \"invited_at\": \"2021-12-31T23:34:00Z\",\n  \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n  \"new_email\": \"lorem\",\n  \"new_phone\": \"lorem\",\n  \"phone\": \"lorem\",\n  \"phone_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"phone_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"reauthentication_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"recovery_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"role\": \"lorem\",\n  \"updated_at\": \"2021-12-31T23:34:00Z\",\n  \"user_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  }\n}  Update a user.put/admin/user/{user_id}Path parametersuser_idRequiredThe user's idResponse codes200401Response (200)exampleschema{\n  \"app_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  },\n  \"aud\": \"lorem\",\n  \"banned_until\": \"2021-12-31T23:34:00Z\",\n  \"confirmation_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"created_at\": \"2021-12-31T23:34:00Z\",\n  \"email\": \"lorem\",\n  \"email_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"email_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\",\n  \"identities\": [\n    {\n      \"created_at\": \"2021-12-31T23:34:00Z\",\n      \"id\": \"lorem\",\n      \"identity_data\": {\n        \"property1\": null,\n        \"property2\": null\n      },\n      \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n      \"provider\": \"lorem\",\n      \"updated_at\": \"2021-12-31T23:34:00Z\",\n      \"user_id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\"\n    }\n  ],\n  \"invited_at\": \"2021-12-31T23:34:00Z\",\n  \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n  \"new_email\": \"lorem\",\n  \"new_phone\": \"lorem\",\n  \"phone\": \"lorem\",\n  \"phone_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"phone_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"reauthentication_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"recovery_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"role\": \"lorem\",\n  \"updated_at\": \"2021-12-31T23:34:00Z\",\n  \"user_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  }\n}  Deletes a user.delete/admin/user/{user_id}Path parametersuser_idRequiredThe user's idResponse codes200401Response (200)schema{}  List all users.get/admin/usersResponse codes200401Response (200)exampleschema{\n  \"aud\": \"lorem\",\n  \"users\": [\n    {\n      \"app_metadata\": {\n        \"property1\": null,\n        \"property2\": null\n      },\n      \"aud\": \"lorem\",\n      \"banned_until\": \"2021-12-31T23:34:00Z\",\n      \"confirmation_sent_at\": \"2021-12-31T23:34:00Z\",\n      \"confirmed_at\": \"2021-12-31T23:34:00Z\",\n      \"created_at\": \"2021-12-31T23:34:00Z\",\n      \"email\": \"lorem\",\n      \"email_change_sent_at\": \"2021-12-31T23:34:00Z\",\n      \"email_confirmed_at\": \"2021-12-31T23:34:00Z\",\n      \"id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\",\n      \"identities\": [\n        {\n          \"created_at\": \"2021-12-31T23:34:00Z\",\n          \"id\": \"lorem\",\n          \"identity_data\": {\n            \"property1\": null,\n            \"property2\": null\n          },\n          \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n          \"provider\": \"lorem\",\n          \"updated_at\": \"2021-12-31T23:34:00Z\",\n          \"user_id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\"\n        }\n      ],\n      \"invited_at\": \"2021-12-31T23:34:00Z\",\n      \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n      \"new_email\": \"lorem\",\n      \"new_phone\": \"lorem\",\n      \"phone\": \"lorem\",\n      \"phone_change_sent_at\": \"2021-12-31T23:34:00Z\",\n      \"phone_confirmed_at\": \"2021-12-31T23:34:00Z\",\n      \"reauthentication_sent_at\": \"2021-12-31T23:34:00Z\",\n      \"recovery_sent_at\": \"2021-12-31T23:34:00Z\",\n      \"role\": \"lorem\",\n      \"updated_at\": \"2021-12-31T23:34:00Z\",\n      \"user_metadata\": {\n        \"property1\": null,\n        \"property2\": null\n      }\n    }\n  ]\n}  Returns the created user.post/admin/usersBodyapp_metadataOptionalobjectObject schemaaudOptionalstringban_durationOptionalstringemailOptionalstringemail_confirmOptionalbooleanpasswordOptionalstringphoneOptionalstringphone_confirmOptionalbooleanroleOptionalstringuser_metadataOptionalobjectObject schemaResponse codes200401Response (200)exampleschema{\n  \"app_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  },\n  \"aud\": \"lorem\",\n  \"banned_until\": \"2021-12-31T23:34:00Z\",\n  \"confirmation_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"created_at\": \"2021-12-31T23:34:00Z\",\n  \"email\": \"lorem\",\n  \"email_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"email_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\",\n  \"identities\": [\n    {\n      \"created_at\": \"2021-12-31T23:34:00Z\",\n      \"id\": \"lorem\",\n      \"identity_data\": {\n        \"property1\": null,\n        \"property2\": null\n      },\n      \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n      \"provider\": \"lorem\",\n      \"updated_at\": \"2021-12-31T23:34:00Z\",\n      \"user_id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\"\n    }\n  ],\n  \"invited_at\": \"2021-12-31T23:34:00Z\",\n  \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n  \"new_email\": \"lorem\",\n  \"new_phone\": \"lorem\",\n  \"phone\": \"lorem\",\n  \"phone_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"phone_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"reauthentication_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"recovery_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"role\": \"lorem\",\n  \"updated_at\": \"2021-12-31T23:34:00Z\",\n  \"user_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  }\n}  Receives the redirect from an external provider during the OAuth authentication process. Starts the process of creating an access and refresh token.get/callbackResponse codes302The healthcheck endpoint for gotrue. Returns the current gotrue version.get/healthResponse codes200Response (200)exampleschema{\n  \"description\": \"lorem\",\n  \"name\": \"lorem\",\n  \"version\": \"lorem\"\n}  Sends an invite link to the user.post/inviteBodydataOptionalobjectObject schemaemailOptionalstringResponse codes200Response (200)schema{}  Logs out the user.post/logoutResponse codes204Response (204)schema{}  Passwordless sign-in method for email or phone.post/otpBodycreate_userOptionalbooleandataOptionalobjectObject schemaemailOptionalstringphoneOptionalstringResponse codes200Response (200)schema{}  Sends a password recovery email link to the user's email.post/recoverBodyemailOptionalstringResponse codes200Response (200)schema{}  Returns the configuration settings for the gotrue server.get/settingsResponse codes200Response (200)exampleschema{\n  \"disable_signup\": true,\n  \"external\": {\n    \"apple\": true,\n    \"azure\": true,\n    \"bitbucket\": true,\n    \"discord\": true,\n    \"email\": true,\n    \"facebook\": true,\n    \"github\": true,\n    \"gitlab\": true,\n    \"google\": true,\n    \"keycloak\": true,\n    \"linkedin\": true,\n    \"notion\": true,\n    \"phone\": true,\n    \"saml\": true,\n    \"slack\": true,\n    \"spotify\": true,\n    \"twitch\": true,\n    \"twitter\": true,\n    \"workos\": true,\n    \"zoom\": true\n  },\n  \"mailer_autoconfirm\": true,\n  \"phone_autoconfirm\": true,\n  \"sms_provider\": \"lorem\"\n}  Password-based signup with either email or phone.post/signupBodydataOptionalobjectObject schemaemailOptionalstringpasswordOptionalstringphoneOptionalstringResponse codes200Response (200)exampleschema{\n  \"app_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  },\n  \"aud\": \"lorem\",\n  \"banned_until\": \"2021-12-31T23:34:00Z\",\n  \"confirmation_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"created_at\": \"2021-12-31T23:34:00Z\",\n  \"email\": \"lorem\",\n  \"email_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"email_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\",\n  \"identities\": [\n    {\n      \"created_at\": \"2021-12-31T23:34:00Z\",\n      \"id\": \"lorem\",\n      \"identity_data\": {\n        \"property1\": null,\n        \"property2\": null\n      },\n      \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n      \"provider\": \"lorem\",\n      \"updated_at\": \"2021-12-31T23:34:00Z\",\n      \"user_id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\"\n    }\n  ],\n  \"invited_at\": \"2021-12-31T23:34:00Z\",\n  \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n  \"new_email\": \"lorem\",\n  \"new_phone\": \"lorem\",\n  \"phone\": \"lorem\",\n  \"phone_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"phone_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"reauthentication_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"recovery_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"role\": \"lorem\",\n  \"updated_at\": \"2021-12-31T23:34:00Z\",\n  \"user_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  }\n}  Signs in a user with a password.post/token?grant_type=passwordBodyemailOptionalstringpasswordOptionalstringphoneOptionalstringResponse codes200Response (200)exampleschema{\n  \"access_token\": \"lorem\",\n  \"expires_in\": 42,\n  \"refresh_token\": \"lorem\",\n  \"token_type\": \"lorem\",\n  \"user\": {\n    \"app_metadata\": {\n      \"property1\": null,\n      \"property2\": null\n    },\n    \"aud\": \"lorem\",\n    \"banned_until\": \"2021-12-31T23:34:00Z\",\n    \"confirmation_sent_at\": \"2021-12-31T23:34:00Z\",\n    \"confirmed_at\": \"2021-12-31T23:34:00Z\",\n    \"created_at\": \"2021-12-31T23:34:00Z\",\n    \"email\": \"lorem\",\n    \"email_change_sent_at\": \"2021-12-31T23:34:00Z\",\n    \"email_confirmed_at\": \"2021-12-31T23:34:00Z\",\n    \"id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\",\n    \"identities\": [\n      {\n        \"created_at\": \"2021-12-31T23:34:00Z\",\n        \"id\": \"lorem\",\n        \"identity_data\": {\n          \"property1\": null,\n          \"property2\": null\n        },\n        \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n        \"provider\": \"lorem\",\n        \"updated_at\": \"2021-12-31T23:34:00Z\",\n        \"user_id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\"\n      }\n    ],\n    \"invited_at\": \"2021-12-31T23:34:00Z\",\n    \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n    \"new_email\": \"lorem\",\n    \"new_phone\": \"lorem\",\n    \"phone\": \"lorem\",\n    \"phone_change_sent_at\": \"2021-12-31T23:34:00Z\",\n    \"phone_confirmed_at\": \"2021-12-31T23:34:00Z\",\n    \"reauthentication_sent_at\": \"2021-12-31T23:34:00Z\",\n    \"recovery_sent_at\": \"2021-12-31T23:34:00Z\",\n    \"role\": \"lorem\",\n    \"updated_at\": \"2021-12-31T23:34:00Z\",\n    \"user_metadata\": {\n      \"property1\": null,\n      \"property2\": null\n    }\n  }\n}  Refreshes a user's refresh token.post/token?grant_type=refresh_tokenBodyrefresh_tokenOptionalstringResponse codes200Response (200)exampleschema{\n  \"access_token\": \"lorem\",\n  \"expires_in\": 42,\n  \"refresh_token\": \"lorem\",\n  \"token_type\": \"lorem\",\n  \"user\": {\n    \"app_metadata\": {\n      \"property1\": null,\n      \"property2\": null\n    },\n    \"aud\": \"lorem\",\n    \"banned_until\": \"2021-12-31T23:34:00Z\",\n    \"confirmation_sent_at\": \"2021-12-31T23:34:00Z\",\n    \"confirmed_at\": \"2021-12-31T23:34:00Z\",\n    \"created_at\": \"2021-12-31T23:34:00Z\",\n    \"email\": \"lorem\",\n    \"email_change_sent_at\": \"2021-12-31T23:34:00Z\",\n    \"email_confirmed_at\": \"2021-12-31T23:34:00Z\",\n    \"id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\",\n    \"identities\": [\n      {\n        \"created_at\": \"2021-12-31T23:34:00Z\",\n        \"id\": \"lorem\",\n        \"identity_data\": {\n          \"property1\": null,\n          \"property2\": null\n        },\n        \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n        \"provider\": \"lorem\",\n        \"updated_at\": \"2021-12-31T23:34:00Z\",\n        \"user_id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\"\n      }\n    ],\n    \"invited_at\": \"2021-12-31T23:34:00Z\",\n    \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n    \"new_email\": \"lorem\",\n    \"new_phone\": \"lorem\",\n    \"phone\": \"lorem\",\n    \"phone_change_sent_at\": \"2021-12-31T23:34:00Z\",\n    \"phone_confirmed_at\": \"2021-12-31T23:34:00Z\",\n    \"reauthentication_sent_at\": \"2021-12-31T23:34:00Z\",\n    \"recovery_sent_at\": \"2021-12-31T23:34:00Z\",\n    \"role\": \"lorem\",\n    \"updated_at\": \"2021-12-31T23:34:00Z\",\n    \"user_metadata\": {\n      \"property1\": null,\n      \"property2\": null\n    }\n  }\n}  Get information for the logged-in user.get/userResponse codes200401Response (200)exampleschema{\n  \"app_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  },\n  \"aud\": \"lorem\",\n  \"banned_until\": \"2021-12-31T23:34:00Z\",\n  \"confirmation_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"created_at\": \"2021-12-31T23:34:00Z\",\n  \"email\": \"lorem\",\n  \"email_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"email_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\",\n  \"identities\": [\n    {\n      \"created_at\": \"2021-12-31T23:34:00Z\",\n      \"id\": \"lorem\",\n      \"identity_data\": {\n        \"property1\": null,\n        \"property2\": null\n      },\n      \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n      \"provider\": \"lorem\",\n      \"updated_at\": \"2021-12-31T23:34:00Z\",\n      \"user_id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\"\n    }\n  ],\n  \"invited_at\": \"2021-12-31T23:34:00Z\",\n  \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n  \"new_email\": \"lorem\",\n  \"new_phone\": \"lorem\",\n  \"phone\": \"lorem\",\n  \"phone_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"phone_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"reauthentication_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"recovery_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"role\": \"lorem\",\n  \"updated_at\": \"2021-12-31T23:34:00Z\",\n  \"user_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  }\n}  Returns the updated user.put/userBodyapp_metadataOptionalobjectObject schemadataOptionalobjectObject schemaemailOptionalstringnonceOptionalstringpasswordOptionalstringphoneOptionalstringResponse codes200401Response (200)exampleschema{\n  \"app_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  },\n  \"aud\": \"lorem\",\n  \"banned_until\": \"2021-12-31T23:34:00Z\",\n  \"confirmation_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"created_at\": \"2021-12-31T23:34:00Z\",\n  \"email\": \"lorem\",\n  \"email_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"email_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\",\n  \"identities\": [\n    {\n      \"created_at\": \"2021-12-31T23:34:00Z\",\n      \"id\": \"lorem\",\n      \"identity_data\": {\n        \"property1\": null,\n        \"property2\": null\n      },\n      \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n      \"provider\": \"lorem\",\n      \"updated_at\": \"2021-12-31T23:34:00Z\",\n      \"user_id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\"\n    }\n  ],\n  \"invited_at\": \"2021-12-31T23:34:00Z\",\n  \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n  \"new_email\": \"lorem\",\n  \"new_phone\": \"lorem\",\n  \"phone\": \"lorem\",\n  \"phone_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"phone_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"reauthentication_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"recovery_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"role\": \"lorem\",\n  \"updated_at\": \"2021-12-31T23:34:00Z\",\n  \"user_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  }\n}  Verifies a sign up.post/verifyBodyemailOptionalstringphoneOptionalstringredirect_toOptionalstringtokenOptionalstringtypeOptionalstring\nSelf-Hosting Auth\nThe Supabase Auth Server (GoTrue) is a JSON Web Token (JWT)-based API for managing users and issuing access tokens.GoTrue is an open-source API written in Golang, that acts as a self-standing API service for handling user registration and authentication for JAM projects. It's based on OAuth2 and JWT and handles user signup, authentication, and custom user data.Client libraries#\nJavaScript\nDart\nAdditional links#\nSource code\nKnown bugs and issues\nAuth guides\nSelf-Hosting Auth\nThe Supabase Auth Server (GoTrue) is a JSON Web Token (JWT)-based API for managing users and issuing access tokens.\nGoTrue is an open-source API written in Golang, that acts as a self-standing API service for handling user registration and authentication for JAM projects. It's based on OAuth2 and JWT and handles user signup, authentication, and custom user data.\nClient libraries#\nAdditional links#\nGenerates an email action link.post/admin/generate_linkBodydataOptionalobjectObject schemaemailOptionalstringnew_emailOptionalstringpasswordOptionalstringredirect_toOptionalstringtypeOptionalstringResponse codes200401Response (200)exampleschema{\n  \"action_link\": \"lorem\",\n  \"app_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  },\n  \"aud\": \"lorem\",\n  \"banned_until\": \"2021-12-31T23:34:00Z\",\n  \"confirmation_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"created_at\": \"2021-12-31T23:34:00Z\",\n  \"email\": \"lorem\",\n  \"email_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"email_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"email_otp\": \"lorem\",\n  \"hashed_token\": \"lorem\",\n  \"id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\",\n  \"identities\": [\n    {\n      \"created_at\": \"2021-12-31T23:34:00Z\",\n      \"id\": \"lorem\",\n      \"identity_data\": {\n        \"property1\": null,\n        \"property2\": null\n      },\n      \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n      \"provider\": \"lorem\",\n      \"updated_at\": \"2021-12-31T23:34:00Z\",\n      \"user_id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\"\n    }\n  ],\n  \"invited_at\": \"2021-12-31T23:34:00Z\",\n  \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n  \"new_email\": \"lorem\",\n  \"new_phone\": \"lorem\",\n  \"phone\": \"lorem\",\n  \"phone_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"phone_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"reauthentication_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"recovery_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"redirect_to\": \"lorem\",\n  \"role\": \"lorem\",\n  \"updated_at\": \"2021-12-31T23:34:00Z\",\n  \"user_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  },\n  \"verification_type\": \"lorem\"\n}\nGenerates an email action link.\nBodydataOptionalobjectObject schemaemailOptionalstringnew_emailOptionalstringpasswordOptionalstringredirect_toOptionalstringtypeOptionalstring\nBody\nResponse codes200401\nResponse codes\nResponse (200)\nGet a user.get/admin/user/{user_id}Path parametersuser_idRequiredThe user's idResponse codes200401Response (200)exampleschema{\n  \"app_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  },\n  \"aud\": \"lorem\",\n  \"banned_until\": \"2021-12-31T23:34:00Z\",\n  \"confirmation_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"created_at\": \"2021-12-31T23:34:00Z\",\n  \"email\": \"lorem\",\n  \"email_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"email_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\",\n  \"identities\": [\n    {\n      \"created_at\": \"2021-12-31T23:34:00Z\",\n      \"id\": \"lorem\",\n      \"identity_data\": {\n        \"property1\": null,\n        \"property2\": null\n      },\n      \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n      \"provider\": \"lorem\",\n      \"updated_at\": \"2021-12-31T23:34:00Z\",\n      \"user_id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\"\n    }\n  ],\n  \"invited_at\": \"2021-12-31T23:34:00Z\",\n  \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n  \"new_email\": \"lorem\",\n  \"new_phone\": \"lorem\",\n  \"phone\": \"lorem\",\n  \"phone_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"phone_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"reauthentication_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"recovery_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"role\": \"lorem\",\n  \"updated_at\": \"2021-12-31T23:34:00Z\",\n  \"user_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  }\n}\nGet a user.\nPath parametersuser_idRequiredThe user's id\nPath parameters\nThe user's id\nResponse codes200401\nResponse codes\nResponse (200)\nUpdate a user.put/admin/user/{user_id}Path parametersuser_idRequiredThe user's idResponse codes200401Response (200)exampleschema{\n  \"app_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  },\n  \"aud\": \"lorem\",\n  \"banned_until\": \"2021-12-31T23:34:00Z\",\n  \"confirmation_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"created_at\": \"2021-12-31T23:34:00Z\",\n  \"email\": \"lorem\",\n  \"email_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"email_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\",\n  \"identities\": [\n    {\n      \"created_at\": \"2021-12-31T23:34:00Z\",\n      \"id\": \"lorem\",\n      \"identity_data\": {\n        \"property1\": null,\n        \"property2\": null\n      },\n      \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n      \"provider\": \"lorem\",\n      \"updated_at\": \"2021-12-31T23:34:00Z\",\n      \"user_id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\"\n    }\n  ],\n  \"invited_at\": \"2021-12-31T23:34:00Z\",\n  \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n  \"new_email\": \"lorem\",\n  \"new_phone\": \"lorem\",\n  \"phone\": \"lorem\",\n  \"phone_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"phone_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"reauthentication_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"recovery_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"role\": \"lorem\",\n  \"updated_at\": \"2021-12-31T23:34:00Z\",\n  \"user_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  }\n}\nUpdate a user.\nPath parametersuser_idRequiredThe user's id\nPath parameters\nThe user's id\nResponse codes200401\nResponse codes\nResponse (200)\nDeletes a user.delete/admin/user/{user_id}Path parametersuser_idRequiredThe user's idResponse codes200401Response (200)schema{}\nDeletes a user.\nPath parametersuser_idRequiredThe user's id\nPath parameters\nThe user's id\nResponse codes200401\nResponse codes\nResponse (200)\nList all users.get/admin/usersResponse codes200401Response (200)exampleschema{\n  \"aud\": \"lorem\",\n  \"users\": [\n    {\n      \"app_metadata\": {\n        \"property1\": null,\n        \"property2\": null\n      },\n      \"aud\": \"lorem\",\n      \"banned_until\": \"2021-12-31T23:34:00Z\",\n      \"confirmation_sent_at\": \"2021-12-31T23:34:00Z\",\n      \"confirmed_at\": \"2021-12-31T23:34:00Z\",\n      \"created_at\": \"2021-12-31T23:34:00Z\",\n      \"email\": \"lorem\",\n      \"email_change_sent_at\": \"2021-12-31T23:34:00Z\",\n      \"email_confirmed_at\": \"2021-12-31T23:34:00Z\",\n      \"id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\",\n      \"identities\": [\n        {\n          \"created_at\": \"2021-12-31T23:34:00Z\",\n          \"id\": \"lorem\",\n          \"identity_data\": {\n            \"property1\": null,\n            \"property2\": null\n          },\n          \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n          \"provider\": \"lorem\",\n          \"updated_at\": \"2021-12-31T23:34:00Z\",\n          \"user_id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\"\n        }\n      ],\n      \"invited_at\": \"2021-12-31T23:34:00Z\",\n      \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n      \"new_email\": \"lorem\",\n      \"new_phone\": \"lorem\",\n      \"phone\": \"lorem\",\n      \"phone_change_sent_at\": \"2021-12-31T23:34:00Z\",\n      \"phone_confirmed_at\": \"2021-12-31T23:34:00Z\",\n      \"reauthentication_sent_at\": \"2021-12-31T23:34:00Z\",\n      \"recovery_sent_at\": \"2021-12-31T23:34:00Z\",\n      \"role\": \"lorem\",\n      \"updated_at\": \"2021-12-31T23:34:00Z\",\n      \"user_metadata\": {\n        \"property1\": null,\n        \"property2\": null\n      }\n    }\n  ]\n}\nList all users.\nResponse codes200401\nResponse codes\nResponse (200)\nReturns the created user.post/admin/usersBodyapp_metadataOptionalobjectObject schemaaudOptionalstringban_durationOptionalstringemailOptionalstringemail_confirmOptionalbooleanpasswordOptionalstringphoneOptionalstringphone_confirmOptionalbooleanroleOptionalstringuser_metadataOptionalobjectObject schemaResponse codes200401Response (200)exampleschema{\n  \"app_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  },\n  \"aud\": \"lorem\",\n  \"banned_until\": \"2021-12-31T23:34:00Z\",\n  \"confirmation_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"created_at\": \"2021-12-31T23:34:00Z\",\n  \"email\": \"lorem\",\n  \"email_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"email_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\",\n  \"identities\": [\n    {\n      \"created_at\": \"2021-12-31T23:34:00Z\",\n      \"id\": \"lorem\",\n      \"identity_data\": {\n        \"property1\": null,\n        \"property2\": null\n      },\n      \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n      \"provider\": \"lorem\",\n      \"updated_at\": \"2021-12-31T23:34:00Z\",\n      \"user_id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\"\n    }\n  ],\n  \"invited_at\": \"2021-12-31T23:34:00Z\",\n  \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n  \"new_email\": \"lorem\",\n  \"new_phone\": \"lorem\",\n  \"phone\": \"lorem\",\n  \"phone_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"phone_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"reauthentication_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"recovery_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"role\": \"lorem\",\n  \"updated_at\": \"2021-12-31T23:34:00Z\",\n  \"user_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  }\n}\nReturns the created user.\nBodyapp_metadataOptionalobjectObject schemaaudOptionalstringban_durationOptionalstringemailOptionalstringemail_confirmOptionalbooleanpasswordOptionalstringphoneOptionalstringphone_confirmOptionalbooleanroleOptionalstringuser_metadataOptionalobjectObject schema\nBody\nResponse codes200401\nResponse codes\nResponse (200)\nReceives the redirect from an external provider during the OAuth authentication process. Starts the process of creating an access and refresh token.get/callbackResponse codes302\nReceives the redirect from an external provider during the OAuth authentication process. Starts the process of creating an access and refresh token.\nResponse codes302\nResponse codes\nThe healthcheck endpoint for gotrue. Returns the current gotrue version.get/healthResponse codes200Response (200)exampleschema{\n  \"description\": \"lorem\",\n  \"name\": \"lorem\",\n  \"version\": \"lorem\"\n}\nThe healthcheck endpoint for gotrue. Returns the current gotrue version.\nResponse codes200\nResponse codes\nResponse (200)\nSends an invite link to the user.post/inviteBodydataOptionalobjectObject schemaemailOptionalstringResponse codes200Response (200)schema{}\nSends an invite link to the user.\nBodydataOptionalobjectObject schemaemailOptionalstring\nBody\nResponse codes200\nResponse codes\nResponse (200)\nLogs out the user.post/logoutResponse codes204Response (204)schema{}\nLogs out the user.\nResponse codes204\nResponse codes\nResponse (204)\nPasswordless sign-in method for email or phone.post/otpBodycreate_userOptionalbooleandataOptionalobjectObject schemaemailOptionalstringphoneOptionalstringResponse codes200Response (200)schema{}\nPasswordless sign-in method for email or phone.\nBodycreate_userOptionalbooleandataOptionalobjectObject schemaemailOptionalstringphoneOptionalstring\nBody\nResponse codes200\nResponse codes\nResponse (200)\nSends a password recovery email link to the user's email.post/recoverBodyemailOptionalstringResponse codes200Response (200)schema{}\nSends a password recovery email link to the user's email.\nBodyemailOptionalstring\nBody\nResponse codes200\nResponse codes\nResponse (200)\nReturns the configuration settings for the gotrue server.get/settingsResponse codes200Response (200)exampleschema{\n  \"disable_signup\": true,\n  \"external\": {\n    \"apple\": true,\n    \"azure\": true,\n    \"bitbucket\": true,\n    \"discord\": true,\n    \"email\": true,\n    \"facebook\": true,\n    \"github\": true,\n    \"gitlab\": true,\n    \"google\": true,\n    \"keycloak\": true,\n    \"linkedin\": true,\n    \"notion\": true,\n    \"phone\": true,\n    \"saml\": true,\n    \"slack\": true,\n    \"spotify\": true,\n    \"twitch\": true,\n    \"twitter\": true,\n    \"workos\": true,\n    \"zoom\": true\n  },\n  \"mailer_autoconfirm\": true,\n  \"phone_autoconfirm\": true,\n  \"sms_provider\": \"lorem\"\n}\nReturns the configuration settings for the gotrue server.\nResponse codes200\nResponse codes\nResponse (200)\nPassword-based signup with either email or phone.post/signupBodydataOptionalobjectObject schemaemailOptionalstringpasswordOptionalstringphoneOptionalstringResponse codes200Response (200)exampleschema{\n  \"app_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  },\n  \"aud\": \"lorem\",\n  \"banned_until\": \"2021-12-31T23:34:00Z\",\n  \"confirmation_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"created_at\": \"2021-12-31T23:34:00Z\",\n  \"email\": \"lorem\",\n  \"email_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"email_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\",\n  \"identities\": [\n    {\n      \"created_at\": \"2021-12-31T23:34:00Z\",\n      \"id\": \"lorem\",\n      \"identity_data\": {\n        \"property1\": null,\n        \"property2\": null\n      },\n      \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n      \"provider\": \"lorem\",\n      \"updated_at\": \"2021-12-31T23:34:00Z\",\n      \"user_id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\"\n    }\n  ],\n  \"invited_at\": \"2021-12-31T23:34:00Z\",\n  \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n  \"new_email\": \"lorem\",\n  \"new_phone\": \"lorem\",\n  \"phone\": \"lorem\",\n  \"phone_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"phone_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"reauthentication_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"recovery_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"role\": \"lorem\",\n  \"updated_at\": \"2021-12-31T23:34:00Z\",\n  \"user_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  }\n}\nPassword-based signup with either email or phone.\nBodydataOptionalobjectObject schemaemailOptionalstringpasswordOptionalstringphoneOptionalstring\nBody\nResponse codes200\nResponse codes\nResponse (200)\nSigns in a user with a password.post/token?grant_type=passwordBodyemailOptionalstringpasswordOptionalstringphoneOptionalstringResponse codes200Response (200)exampleschema{\n  \"access_token\": \"lorem\",\n  \"expires_in\": 42,\n  \"refresh_token\": \"lorem\",\n  \"token_type\": \"lorem\",\n  \"user\": {\n    \"app_metadata\": {\n      \"property1\": null,\n      \"property2\": null\n    },\n    \"aud\": \"lorem\",\n    \"banned_until\": \"2021-12-31T23:34:00Z\",\n    \"confirmation_sent_at\": \"2021-12-31T23:34:00Z\",\n    \"confirmed_at\": \"2021-12-31T23:34:00Z\",\n    \"created_at\": \"2021-12-31T23:34:00Z\",\n    \"email\": \"lorem\",\n    \"email_change_sent_at\": \"2021-12-31T23:34:00Z\",\n    \"email_confirmed_at\": \"2021-12-31T23:34:00Z\",\n    \"id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\",\n    \"identities\": [\n      {\n        \"created_at\": \"2021-12-31T23:34:00Z\",\n        \"id\": \"lorem\",\n        \"identity_data\": {\n          \"property1\": null,\n          \"property2\": null\n        },\n        \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n        \"provider\": \"lorem\",\n        \"updated_at\": \"2021-12-31T23:34:00Z\",\n        \"user_id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\"\n      }\n    ],\n    \"invited_at\": \"2021-12-31T23:34:00Z\",\n    \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n    \"new_email\": \"lorem\",\n    \"new_phone\": \"lorem\",\n    \"phone\": \"lorem\",\n    \"phone_change_sent_at\": \"2021-12-31T23:34:00Z\",\n    \"phone_confirmed_at\": \"2021-12-31T23:34:00Z\",\n    \"reauthentication_sent_at\": \"2021-12-31T23:34:00Z\",\n    \"recovery_sent_at\": \"2021-12-31T23:34:00Z\",\n    \"role\": \"lorem\",\n    \"updated_at\": \"2021-12-31T23:34:00Z\",\n    \"user_metadata\": {\n      \"property1\": null,\n      \"property2\": null\n    }\n  }\n}\nSigns in a user with a password.\nBodyemailOptionalstringpasswordOptionalstringphoneOptionalstring\nBody\nResponse codes200\nResponse codes\nResponse (200)\nRefreshes a user's refresh token.post/token?grant_type=refresh_tokenBodyrefresh_tokenOptionalstringResponse codes200Response (200)exampleschema{\n  \"access_token\": \"lorem\",\n  \"expires_in\": 42,\n  \"refresh_token\": \"lorem\",\n  \"token_type\": \"lorem\",\n  \"user\": {\n    \"app_metadata\": {\n      \"property1\": null,\n      \"property2\": null\n    },\n    \"aud\": \"lorem\",\n    \"banned_until\": \"2021-12-31T23:34:00Z\",\n    \"confirmation_sent_at\": \"2021-12-31T23:34:00Z\",\n    \"confirmed_at\": \"2021-12-31T23:34:00Z\",\n    \"created_at\": \"2021-12-31T23:34:00Z\",\n    \"email\": \"lorem\",\n    \"email_change_sent_at\": \"2021-12-31T23:34:00Z\",\n    \"email_confirmed_at\": \"2021-12-31T23:34:00Z\",\n    \"id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\",\n    \"identities\": [\n      {\n        \"created_at\": \"2021-12-31T23:34:00Z\",\n        \"id\": \"lorem\",\n        \"identity_data\": {\n          \"property1\": null,\n          \"property2\": null\n        },\n        \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n        \"provider\": \"lorem\",\n        \"updated_at\": \"2021-12-31T23:34:00Z\",\n        \"user_id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\"\n      }\n    ],\n    \"invited_at\": \"2021-12-31T23:34:00Z\",\n    \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n    \"new_email\": \"lorem\",\n    \"new_phone\": \"lorem\",\n    \"phone\": \"lorem\",\n    \"phone_change_sent_at\": \"2021-12-31T23:34:00Z\",\n    \"phone_confirmed_at\": \"2021-12-31T23:34:00Z\",\n    \"reauthentication_sent_at\": \"2021-12-31T23:34:00Z\",\n    \"recovery_sent_at\": \"2021-12-31T23:34:00Z\",\n    \"role\": \"lorem\",\n    \"updated_at\": \"2021-12-31T23:34:00Z\",\n    \"user_metadata\": {\n      \"property1\": null,\n      \"property2\": null\n    }\n  }\n}\nRefreshes a user's refresh token.\nBodyrefresh_tokenOptionalstring\nBody\nResponse codes200\nResponse codes\nResponse (200)\nGet information for the logged-in user.get/userResponse codes200401Response (200)exampleschema{\n  \"app_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  },\n  \"aud\": \"lorem\",\n  \"banned_until\": \"2021-12-31T23:34:00Z\",\n  \"confirmation_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"created_at\": \"2021-12-31T23:34:00Z\",\n  \"email\": \"lorem\",\n  \"email_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"email_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\",\n  \"identities\": [\n    {\n      \"created_at\": \"2021-12-31T23:34:00Z\",\n      \"id\": \"lorem\",\n      \"identity_data\": {\n        \"property1\": null,\n        \"property2\": null\n      },\n      \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n      \"provider\": \"lorem\",\n      \"updated_at\": \"2021-12-31T23:34:00Z\",\n      \"user_id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\"\n    }\n  ],\n  \"invited_at\": \"2021-12-31T23:34:00Z\",\n  \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n  \"new_email\": \"lorem\",\n  \"new_phone\": \"lorem\",\n  \"phone\": \"lorem\",\n  \"phone_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"phone_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"reauthentication_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"recovery_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"role\": \"lorem\",\n  \"updated_at\": \"2021-12-31T23:34:00Z\",\n  \"user_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  }\n}\nGet information for the logged-in user.\nResponse codes200401\nResponse codes\nResponse (200)\nReturns the updated user.put/userBodyapp_metadataOptionalobjectObject schemadataOptionalobjectObject schemaemailOptionalstringnonceOptionalstringpasswordOptionalstringphoneOptionalstringResponse codes200401Response (200)exampleschema{\n  \"app_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  },\n  \"aud\": \"lorem\",\n  \"banned_until\": \"2021-12-31T23:34:00Z\",\n  \"confirmation_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"created_at\": \"2021-12-31T23:34:00Z\",\n  \"email\": \"lorem\",\n  \"email_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"email_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\",\n  \"identities\": [\n    {\n      \"created_at\": \"2021-12-31T23:34:00Z\",\n      \"id\": \"lorem\",\n      \"identity_data\": {\n        \"property1\": null,\n        \"property2\": null\n      },\n      \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n      \"provider\": \"lorem\",\n      \"updated_at\": \"2021-12-31T23:34:00Z\",\n      \"user_id\": \"fbdf5a53-161e-4460-98ad-0e39408d8689\"\n    }\n  ],\n  \"invited_at\": \"2021-12-31T23:34:00Z\",\n  \"last_sign_in_at\": \"2021-12-31T23:34:00Z\",\n  \"new_email\": \"lorem\",\n  \"new_phone\": \"lorem\",\n  \"phone\": \"lorem\",\n  \"phone_change_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"phone_confirmed_at\": \"2021-12-31T23:34:00Z\",\n  \"reauthentication_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"recovery_sent_at\": \"2021-12-31T23:34:00Z\",\n  \"role\": \"lorem\",\n  \"updated_at\": \"2021-12-31T23:34:00Z\",\n  \"user_metadata\": {\n    \"property1\": null,\n    \"property2\": null\n  }\n}\nReturns the updated user.\nBodyapp_metadataOptionalobjectObject schemadataOptionalobjectObject schemaemailOptionalstringnonceOptionalstringpasswordOptionalstringphoneOptionalstring\nBody\nResponse codes200401\nResponse codes\nResponse (200)\nVerifies a sign up.post/verifyBodyemailOptionalstringphoneOptionalstringredirect_toOptionalstringtokenOptionalstringtypeOptionalstring\nVerifies a sign up.\nBodyemailOptionalstringphoneOptionalstringredirect_toOptionalstringtokenOptionalstringtypeOptionalstring\nBody\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "44",
    "url": "https://supabase.com/docs/reference/self-hosting-realtime/introduction",
    "title": "Self-Hosting | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nSelf-Hosting Realtime\nSupabase Realtime is a server built with Elixir using the Phoenix Framework that allows you to listen to changes in your PostgreSQL database via logical replication and then broadcast those changes via WebSockets.There are two versions of this server: Realtime and Realtime RLS.Realtime server works by:\nListening to PostgreSQL's replication functionality (using PostgreSQL's logical decoding)\nConverting the byte stream into JSON\nBroadcasting to all connected clients over WebSockets\nRealtime RLS server works by:\nPolling PostgreSQL's replication functionality (using PostgreSQL's logical decoding and wal2json output plugin)\nPassing database changes to a Write Ahead Log Realtime Unified Security (WALRUS) PostgresSQL function and receiving a list of authorized subscribers depending on Row Level Security (RLS) policies\nConverting the changes into JSON\nBroadcasting to authorized subscribers over WebSockets\nWhy not just use PostgreSQL's NOTIFY?#A few reasons:\nYou don't have to set up triggers on every table.\nNOTIFY has a payload limit of 8000 bytes and will fail for anything larger. The usual solution is to send an ID and then fetch the record, but that's heavy on the database.\nRealtime server consumes two connections to the database, then you can connect many clients to this server. Easier on your database, and to scale up you just add additional Realtime servers.\nBenefits#\nThe beauty of listening to the replication functionality is that you can make changes to your database from anywhere - your API, directly in the DB, via a console, etc. - and you will still receive the changes via WebSockets.\nDecoupling. For example, if you want to send a new slack message every time someone makes a new purchase you might build that functionality directly into your API. This allows you to decouple your async functionality from your API.\nThis is built with Phoenix, an extremely scalable Elixir framework.\nDoes this server guarantee delivery of every data change?#Not yet! Due to the following limitations:\nPostgres database runs out of disk space due to Write-Ahead Logging (WAL) buildup, which can crash the database and prevent Realtime server from receiving and broadcasting changes. This can be mitigated in the Realtime RLS version of this server by setting the Postgres config max_slot_wal_keep_size to a reasonable size.\nRealtime server can crash due to a larger replication lag than available memory, forcing the creation of a new replication slot and resetting replication to read from the latest WAL data.\nWhen Realtime server falls too far behind for any reason, for example disconnecting from database as WAL continues to build up, then database can delete WAL segments the server still needs to read from, for example after reconnecting.\nClient libraries#\nJavaScript\nDart\nAdditional links#\nSource code\nKnown bugs and issues\nRealtime guides\nSelf-Hosting Realtime\nSupabase Realtime is a server built with Elixir using the Phoenix Framework that allows you to listen to changes in your PostgreSQL database via logical replication and then broadcast those changes via WebSockets.There are two versions of this server: Realtime and Realtime RLS.Realtime server works by:\nListening to PostgreSQL's replication functionality (using PostgreSQL's logical decoding)\nConverting the byte stream into JSON\nBroadcasting to all connected clients over WebSockets\nRealtime RLS server works by:\nPolling PostgreSQL's replication functionality (using PostgreSQL's logical decoding and wal2json output plugin)\nPassing database changes to a Write Ahead Log Realtime Unified Security (WALRUS) PostgresSQL function and receiving a list of authorized subscribers depending on Row Level Security (RLS) policies\nConverting the changes into JSON\nBroadcasting to authorized subscribers over WebSockets\nWhy not just use PostgreSQL's NOTIFY?#A few reasons:\nYou don't have to set up triggers on every table.\nNOTIFY has a payload limit of 8000 bytes and will fail for anything larger. The usual solution is to send an ID and then fetch the record, but that's heavy on the database.\nRealtime server consumes two connections to the database, then you can connect many clients to this server. Easier on your database, and to scale up you just add additional Realtime servers.\nBenefits#\nThe beauty of listening to the replication functionality is that you can make changes to your database from anywhere - your API, directly in the DB, via a console, etc. - and you will still receive the changes via WebSockets.\nDecoupling. For example, if you want to send a new slack message every time someone makes a new purchase you might build that functionality directly into your API. This allows you to decouple your async functionality from your API.\nThis is built with Phoenix, an extremely scalable Elixir framework.\nDoes this server guarantee delivery of every data change?#Not yet! Due to the following limitations:\nPostgres database runs out of disk space due to Write-Ahead Logging (WAL) buildup, which can crash the database and prevent Realtime server from receiving and broadcasting changes. This can be mitigated in the Realtime RLS version of this server by setting the Postgres config max_slot_wal_keep_size to a reasonable size.\nRealtime server can crash due to a larger replication lag than available memory, forcing the creation of a new replication slot and resetting replication to read from the latest WAL data.\nWhen Realtime server falls too far behind for any reason, for example disconnecting from database as WAL continues to build up, then database can delete WAL segments the server still needs to read from, for example after reconnecting.\nClient libraries#\nJavaScript\nDart\nAdditional links#\nSource code\nKnown bugs and issues\nRealtime guides\nSelf-Hosting Realtime\nSupabase Realtime is a server built with Elixir using the Phoenix Framework that allows you to listen to changes in your PostgreSQL database via logical replication and then broadcast those changes via WebSockets.\nThere are two versions of this server: Realtime and Realtime RLS.\nRealtime server works by:\nRealtime RLS server works by:\nWhy not just use PostgreSQL's NOTIFY?#\nA few reasons:\nBenefits#\nDoes this server guarantee delivery of every data change?#\nNot yet! Due to the following limitations:\nClient libraries#\nAdditional links#\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "45",
    "url": "https://supabase.com/docs/reference/self-hosting-storage/introduction",
    "title": "Self-Hosting | Supabase Docs",
    "content": "Search docs...\nSearch docs...\nSelf-Hosting Storage\nAn S3 compatible object storage service that integrates with Postgres.\nUses Postgres as it's datastore for storing metadata\nAuthorization rules are written as Postgres Row Level Security policies\nIntegrates with S3 as the storage backend (with more in the pipeline!)\nExtremely lightweight and performant\nClient libraries#\nJavaScript\nDart\nAdditional links#\nSource code\nKnown bugs and issues\nStorage guides\nOpenAPI docs\nWhy we built a new object storage service\nCreate a bucketpost/bucket/BodynameRequiredstringidOptionalstringpublicOptionalbooleanfile_size_limitOptionalany of the following optionsOptionsallowed_mime_typesOptionalArray<string>Response codes2004XXResponse (200)exampleschema{\n  \"name\": \"avatars\"\n}  Gets all bucketsget/bucket/Response codes2004XXResponse (200)exampleschema[\n  {\n    \"id\": \"bucket2\",\n    \"name\": \"bucket2\",\n    \"public\": false,\n    \"file_size_limit\": 1000000,\n    \"allowed_mime_types\": [\n      \"image/png\",\n      \"image/jpeg\"\n    ],\n    \"owner\": \"4d56e902-f0a0-4662-8448-a4d9e643c142\",\n    \"created_at\": \"2021-02-17T04:43:32.770206+00:00\",\n    \"updated_at\": \"2021-02-17T04:43:32.770206+00:00\"\n  }\n]  Empty a bucketpost/bucket/{bucketId}/emptyPath parametersbucketIdRequiredstringResponse codes2004XXResponse (200)exampleschema{\n  \"message\": \"Successfully emptied\"\n}  Get details of a bucketget/bucket/{bucketId}Path parametersbucketIdRequiredstringResponse codes2004XXResponse (200)exampleschema{\n  \"id\": \"lorem\",\n  \"name\": \"lorem\",\n  \"owner\": \"lorem\",\n  \"public\": true,\n  \"created_at\": \"lorem\",\n  \"updated_at\": \"lorem\"\n}  Update properties of a bucketput/bucket/{bucketId}BodypublicOptionalbooleanfile_size_limitOptionalany of the following optionsOptionsallowed_mime_typesOptionalArray<string>Response codes2004XXResponse (200)exampleschema{\n  \"message\": \"Successfully updated\"\n}  Delete a bucketdelete/bucket/{bucketId}Path parametersbucketIdRequiredstringResponse codes2004XXResponse (200)exampleschema{\n  \"message\": \"Successfully deleted\"\n}  Delete an objectdelete/object/{bucketName}/{wildcard}Path parametersbucketNameRequiredstring*RequiredstringResponse codes2004XXResponse (200)exampleschema{\n  \"message\": \"Successfully deleted\"\n}  Get objectget/object/{bucketName}/{wildcard}use GET /object/authenticated/{bucketName} insteadPath parametersbucketNameRequiredstring*RequiredstringResponse codes4XXUpdate the object at an existing keyput/object/{bucketName}/{wildcard}Path parametersbucketNameRequiredstring*RequiredstringResponse codes2004XXResponse (200)exampleschema{\n  \"Id\": \"lorem\",\n  \"Key\": \"avatars/folder/cat.png\"\n}  Upload a new objectpost/object/{bucketName}/{wildcard}Path parametersbucketNameRequiredstring*RequiredstringResponse codes2004XXResponse (200)exampleschema{\n  \"Id\": \"lorem\",\n  \"Key\": \"avatars/folder/cat.png\"\n}  Delete multiple objectsdelete/object/{bucketName}Path parametersbucketNameRequiredstringBodyprefixesRequiredArray<string>Response codes2004XXResponse (200)exampleschema[\n  {\n    \"name\": \"folder/cat.png\",\n    \"bucket_id\": \"avatars\",\n    \"owner\": \"317eadce-631a-4429-a0bb-f19a7a517b4a\",\n    \"id\": \"eaa8bdb5-2e00-4767-b5a9-d2502efe2196\",\n    \"updated_at\": \"2021-04-06T16:30:35.394674+00:00\",\n    \"created_at\": \"2021-04-06T16:30:35.394674+00:00\",\n    \"last_accessed_at\": \"2021-04-06T16:30:35.394674+00:00\",\n    \"metadata\": {\n      \"size\": 1234\n    }\n  }\n]  Retrieve an objectget/object/authenticated/{bucketName}/{wildcard}Path parametersbucketNameRequiredstring*RequiredstringResponse codes4XXGenerate a presigned url to retrieve an objectpost/object/sign/{bucketName}/{wildcard}Path parametersbucketNameRequiredstring*RequiredstringBodyexpiresInRequiredintegertransformOptionalobjectObject schemaResponse codes2004XXResponse (200)exampleschema{\n  \"signedURL\": \"/object/sign/avatars/folder/cat.png?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJhdmF0YXJzL2ZvbGRlci9jYXQucG5nIiwiaWF0IjoxNjE3NzI2MjczLCJleHAiOjE2MTc3MjcyNzN9.s7Gt8ME80iREVxPhH01ZNv8oUn4XtaWsmiQ5csiUHn4\"\n}  Retrieve an object via a presigned URLget/object/sign/{bucketName}/{wildcard}Path parametersbucketNameRequiredstring*RequiredstringQuery parametersdownloadOptionalstringtokenRequiredstringResponse codes4XXGenerate presigned urls to retrieve objectspost/object/sign/{bucketName}Path parametersbucketNameRequiredstringBodyexpiresInRequiredintegerpathsRequiredArray<string>Response codes2004XXResponse (200)exampleschema[\n  {\n    \"error\": \"Either the object does not exist or you do not have access to it\",\n    \"path\": \"folder/cat.png\",\n    \"signedURL\": \"/object/sign/avatars/folder/cat.png?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJhdmF0YXJzL2ZvbGRlci9jYXQucG5nIiwiaWF0IjoxNjE3NzI2MjczLCJleHAiOjE2MTc3MjcyNzN9.s7Gt8ME80iREVxPhH01ZNv8oUn4XtaWsmiQ5csiUHn4\"\n  }\n]  Moves an objectpost/object/moveBodybucketIdRequiredstringsourceKeyRequiredstringdestinationKeyRequiredstringResponse codes2004XXResponse (200)exampleschema{\n  \"message\": \"Successfully moved\"\n}  Search for objects under a prefixpost/object/list/{bucketName}Path parametersbucketNameRequiredstringBodyprefixRequiredstringlimitOptionalintegeroffsetOptionalintegersortByOptionalobjectObject schemasearchOptionalstringResponse codes2004XXResponse (200)exampleschema[\n  {\n    \"name\": \"folder/cat.png\",\n    \"bucket_id\": \"avatars\",\n    \"owner\": \"317eadce-631a-4429-a0bb-f19a7a517b4a\",\n    \"id\": \"eaa8bdb5-2e00-4767-b5a9-d2502efe2196\",\n    \"updated_at\": \"2021-04-06T16:30:35.394674+00:00\",\n    \"created_at\": \"2021-04-06T16:30:35.394674+00:00\",\n    \"last_accessed_at\": \"2021-04-06T16:30:35.394674+00:00\",\n    \"metadata\": {\n      \"size\": 1234\n    }\n  }\n]  Retrieve object infoget/object/info/{bucketName}/{wildcard}use HEAD /object/authenticated/{bucketName} insteadPath parametersbucketNameRequiredstring*RequiredstringResponse codes4XXCopies an objectpost/object/copyBodysourceKeyRequiredstringbucketIdRequiredstringdestinationKeyRequiredstringResponse codes2004XXResponse (200)exampleschema{\n  \"Key\": \"folder/destination.png\"\n}  Retrieve an object from a public bucketget/object/public/{bucketName}/{wildcard}Path parametersbucketNameRequiredstring*RequiredstringResponse codes4XXGet object infoget/object/info/public/{bucketName}/{wildcard}returns object infoPath parametersbucketNameRequiredstring*RequiredstringResponse codes4XX\nSelf-Hosting Storage\nAn S3 compatible object storage service that integrates with Postgres.\nUses Postgres as it's datastore for storing metadata\nAuthorization rules are written as Postgres Row Level Security policies\nIntegrates with S3 as the storage backend (with more in the pipeline!)\nExtremely lightweight and performant\nClient libraries#\nJavaScript\nDart\nAdditional links#\nSource code\nKnown bugs and issues\nStorage guides\nOpenAPI docs\nWhy we built a new object storage service\nSelf-Hosting Storage\nAn S3 compatible object storage service that integrates with Postgres.\nClient libraries#\nAdditional links#\nCreate a bucketpost/bucket/BodynameRequiredstringidOptionalstringpublicOptionalbooleanfile_size_limitOptionalany of the following optionsOptionsallowed_mime_typesOptionalArray<string>Response codes2004XXResponse (200)exampleschema{\n  \"name\": \"avatars\"\n}\nCreate a bucket\nBodynameRequiredstringidOptionalstringpublicOptionalbooleanfile_size_limitOptionalany of the following optionsOptionsallowed_mime_typesOptionalArray<string>\nBody\nResponse codes2004XX\nResponse codes\nResponse (200)\nGets all bucketsget/bucket/Response codes2004XXResponse (200)exampleschema[\n  {\n    \"id\": \"bucket2\",\n    \"name\": \"bucket2\",\n    \"public\": false,\n    \"file_size_limit\": 1000000,\n    \"allowed_mime_types\": [\n      \"image/png\",\n      \"image/jpeg\"\n    ],\n    \"owner\": \"4d56e902-f0a0-4662-8448-a4d9e643c142\",\n    \"created_at\": \"2021-02-17T04:43:32.770206+00:00\",\n    \"updated_at\": \"2021-02-17T04:43:32.770206+00:00\"\n  }\n]\nGets all buckets\nResponse codes2004XX\nResponse codes\nResponse (200)\nEmpty a bucketpost/bucket/{bucketId}/emptyPath parametersbucketIdRequiredstringResponse codes2004XXResponse (200)exampleschema{\n  \"message\": \"Successfully emptied\"\n}\nEmpty a bucket\nPath parametersbucketIdRequiredstring\nPath parameters\nResponse codes2004XX\nResponse codes\nResponse (200)\nGet details of a bucketget/bucket/{bucketId}Path parametersbucketIdRequiredstringResponse codes2004XXResponse (200)exampleschema{\n  \"id\": \"lorem\",\n  \"name\": \"lorem\",\n  \"owner\": \"lorem\",\n  \"public\": true,\n  \"created_at\": \"lorem\",\n  \"updated_at\": \"lorem\"\n}\nGet details of a bucket\nPath parametersbucketIdRequiredstring\nPath parameters\nResponse codes2004XX\nResponse codes\nResponse (200)\nUpdate properties of a bucketput/bucket/{bucketId}BodypublicOptionalbooleanfile_size_limitOptionalany of the following optionsOptionsallowed_mime_typesOptionalArray<string>Response codes2004XXResponse (200)exampleschema{\n  \"message\": \"Successfully updated\"\n}\nUpdate properties of a bucket\nBodypublicOptionalbooleanfile_size_limitOptionalany of the following optionsOptionsallowed_mime_typesOptionalArray<string>\nBody\nResponse codes2004XX\nResponse codes\nResponse (200)\nDelete a bucketdelete/bucket/{bucketId}Path parametersbucketIdRequiredstringResponse codes2004XXResponse (200)exampleschema{\n  \"message\": \"Successfully deleted\"\n}\nDelete a bucket\nPath parametersbucketIdRequiredstring\nPath parameters\nResponse codes2004XX\nResponse codes\nResponse (200)\nDelete an objectdelete/object/{bucketName}/{wildcard}Path parametersbucketNameRequiredstring*RequiredstringResponse codes2004XXResponse (200)exampleschema{\n  \"message\": \"Successfully deleted\"\n}\nDelete an object\nPath parametersbucketNameRequiredstring*Requiredstring\nPath parameters\nResponse codes2004XX\nResponse codes\nResponse (200)\nGet objectget/object/{bucketName}/{wildcard}use GET /object/authenticated/{bucketName} insteadPath parametersbucketNameRequiredstring*RequiredstringResponse codes4XX\nGet object\nuse GET /object/authenticated/{bucketName} instead\nPath parametersbucketNameRequiredstring*Requiredstring\nPath parameters\nResponse codes4XX\nResponse codes\nUpdate the object at an existing keyput/object/{bucketName}/{wildcard}Path parametersbucketNameRequiredstring*RequiredstringResponse codes2004XXResponse (200)exampleschema{\n  \"Id\": \"lorem\",\n  \"Key\": \"avatars/folder/cat.png\"\n}\nUpdate the object at an existing key\nPath parametersbucketNameRequiredstring*Requiredstring\nPath parameters\nResponse codes2004XX\nResponse codes\nResponse (200)\nUpload a new objectpost/object/{bucketName}/{wildcard}Path parametersbucketNameRequiredstring*RequiredstringResponse codes2004XXResponse (200)exampleschema{\n  \"Id\": \"lorem\",\n  \"Key\": \"avatars/folder/cat.png\"\n}\nUpload a new object\nPath parametersbucketNameRequiredstring*Requiredstring\nPath parameters\nResponse codes2004XX\nResponse codes\nResponse (200)\nDelete multiple objectsdelete/object/{bucketName}Path parametersbucketNameRequiredstringBodyprefixesRequiredArray<string>Response codes2004XXResponse (200)exampleschema[\n  {\n    \"name\": \"folder/cat.png\",\n    \"bucket_id\": \"avatars\",\n    \"owner\": \"317eadce-631a-4429-a0bb-f19a7a517b4a\",\n    \"id\": \"eaa8bdb5-2e00-4767-b5a9-d2502efe2196\",\n    \"updated_at\": \"2021-04-06T16:30:35.394674+00:00\",\n    \"created_at\": \"2021-04-06T16:30:35.394674+00:00\",\n    \"last_accessed_at\": \"2021-04-06T16:30:35.394674+00:00\",\n    \"metadata\": {\n      \"size\": 1234\n    }\n  }\n]\nDelete multiple objects\nPath parametersbucketNameRequiredstring\nPath parameters\nBodyprefixesRequiredArray<string>\nBody\nResponse codes2004XX\nResponse codes\nResponse (200)\nRetrieve an objectget/object/authenticated/{bucketName}/{wildcard}Path parametersbucketNameRequiredstring*RequiredstringResponse codes4XX\nRetrieve an object\nPath parametersbucketNameRequiredstring*Requiredstring\nPath parameters\nResponse codes4XX\nResponse codes\nGenerate a presigned url to retrieve an objectpost/object/sign/{bucketName}/{wildcard}Path parametersbucketNameRequiredstring*RequiredstringBodyexpiresInRequiredintegertransformOptionalobjectObject schemaResponse codes2004XXResponse (200)exampleschema{\n  \"signedURL\": \"/object/sign/avatars/folder/cat.png?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJhdmF0YXJzL2ZvbGRlci9jYXQucG5nIiwiaWF0IjoxNjE3NzI2MjczLCJleHAiOjE2MTc3MjcyNzN9.s7Gt8ME80iREVxPhH01ZNv8oUn4XtaWsmiQ5csiUHn4\"\n}\nGenerate a presigned url to retrieve an object\nPath parametersbucketNameRequiredstring*Requiredstring\nPath parameters\nBodyexpiresInRequiredintegertransformOptionalobjectObject schema\nBody\nResponse codes2004XX\nResponse codes\nResponse (200)\nRetrieve an object via a presigned URLget/object/sign/{bucketName}/{wildcard}Path parametersbucketNameRequiredstring*RequiredstringQuery parametersdownloadOptionalstringtokenRequiredstringResponse codes4XX\nRetrieve an object via a presigned URL\nPath parametersbucketNameRequiredstring*Requiredstring\nPath parameters\nQuery parametersdownloadOptionalstringtokenRequiredstring\nQuery parameters\nResponse codes4XX\nResponse codes\nGenerate presigned urls to retrieve objectspost/object/sign/{bucketName}Path parametersbucketNameRequiredstringBodyexpiresInRequiredintegerpathsRequiredArray<string>Response codes2004XXResponse (200)exampleschema[\n  {\n    \"error\": \"Either the object does not exist or you do not have access to it\",\n    \"path\": \"folder/cat.png\",\n    \"signedURL\": \"/object/sign/avatars/folder/cat.png?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJhdmF0YXJzL2ZvbGRlci9jYXQucG5nIiwiaWF0IjoxNjE3NzI2MjczLCJleHAiOjE2MTc3MjcyNzN9.s7Gt8ME80iREVxPhH01ZNv8oUn4XtaWsmiQ5csiUHn4\"\n  }\n]\nGenerate presigned urls to retrieve objects\nPath parametersbucketNameRequiredstring\nPath parameters\nBodyexpiresInRequiredintegerpathsRequiredArray<string>\nBody\nResponse codes2004XX\nResponse codes\nResponse (200)\nMoves an objectpost/object/moveBodybucketIdRequiredstringsourceKeyRequiredstringdestinationKeyRequiredstringResponse codes2004XXResponse (200)exampleschema{\n  \"message\": \"Successfully moved\"\n}\nMoves an object\nBodybucketIdRequiredstringsourceKeyRequiredstringdestinationKeyRequiredstring\nBody\nResponse codes2004XX\nResponse codes\nResponse (200)\nSearch for objects under a prefixpost/object/list/{bucketName}Path parametersbucketNameRequiredstringBodyprefixRequiredstringlimitOptionalintegeroffsetOptionalintegersortByOptionalobjectObject schemasearchOptionalstringResponse codes2004XXResponse (200)exampleschema[\n  {\n    \"name\": \"folder/cat.png\",\n    \"bucket_id\": \"avatars\",\n    \"owner\": \"317eadce-631a-4429-a0bb-f19a7a517b4a\",\n    \"id\": \"eaa8bdb5-2e00-4767-b5a9-d2502efe2196\",\n    \"updated_at\": \"2021-04-06T16:30:35.394674+00:00\",\n    \"created_at\": \"2021-04-06T16:30:35.394674+00:00\",\n    \"last_accessed_at\": \"2021-04-06T16:30:35.394674+00:00\",\n    \"metadata\": {\n      \"size\": 1234\n    }\n  }\n]\nSearch for objects under a prefix\nPath parametersbucketNameRequiredstring\nPath parameters\nBodyprefixRequiredstringlimitOptionalintegeroffsetOptionalintegersortByOptionalobjectObject schemasearchOptionalstring\nBody\nResponse codes2004XX\nResponse codes\nResponse (200)\nRetrieve object infoget/object/info/{bucketName}/{wildcard}use HEAD /object/authenticated/{bucketName} insteadPath parametersbucketNameRequiredstring*RequiredstringResponse codes4XX\nRetrieve object info\nuse HEAD /object/authenticated/{bucketName} instead\nPath parametersbucketNameRequiredstring*Requiredstring\nPath parameters\nResponse codes4XX\nResponse codes\nCopies an objectpost/object/copyBodysourceKeyRequiredstringbucketIdRequiredstringdestinationKeyRequiredstringResponse codes2004XXResponse (200)exampleschema{\n  \"Key\": \"folder/destination.png\"\n}\nCopies an object\nBodysourceKeyRequiredstringbucketIdRequiredstringdestinationKeyRequiredstring\nBody\nResponse codes2004XX\nResponse codes\nResponse (200)\nRetrieve an object from a public bucketget/object/public/{bucketName}/{wildcard}Path parametersbucketNameRequiredstring*RequiredstringResponse codes4XX\nRetrieve an object from a public bucket\nPath parametersbucketNameRequiredstring*Requiredstring\nPath parameters\nResponse codes4XX\nResponse codes\nGet object infoget/object/info/public/{bucketName}/{wildcard}returns object infoPath parametersbucketNameRequiredstring*RequiredstringResponse codes4XX\nGet object info\nreturns object info\nPath parametersbucketNameRequiredstring*Requiredstring\nPath parameters\nResponse codes4XX\nResponse codes\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "46",
    "url": "https://supabase.com/docs/reference/self-hosting-analytics/introduction",
    "title": "Self-Hosting | Supabase Docs",
    "content": "Search docs...\nSearch docs...\n[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nSelf-Hosting Analytics\nThe Supabase Analytics server is a Logflare self-hostable instance that manages the ingestion and query pipelines for searching and aggregating structured analytics events.When self-hosting the Analytics server, the full logging experience matching that of the Supabase Platform is available in the Studio instance, allowing for an integrated and enhanced development experience.\nHowever, it's important to note that certain differences may arise due to the platform's infrastructure.Logflare Technical DocsAll Logflare technical documentation is available at https://docs.logflare.app.Backends Supported#The Analytics server supports either Postgres or BigQuery as the backend. The supabase-cli experience uses the Postgres backend out-of-the-box. However, the Supabase Platform uses the BigQuery backend for storing all platform logs.When using the BigQuery backend, a BigQuery dataset is created in the provided Google Cloud project, and tables are created for each source. Log events are streamed into each table, and all queries generated by Studio or by the Logs Explorer are executed against the BigQuery API. This backend requires internet access to work, and cannot be run fully locally.When using the Postgres backend, tables are created for each source within the provided schema (for supabase-cli, this would be _analytics). Log events received by Logflare are inserted directly into the respective tables. All BigQuery-dialect SQL queries from Studio will be handled by a translation layer within the Analytics server. This translation layer translates the query to PostgreSQL dialect, and then executes it against the Postgres database.The Postgres backend is not yet optimized for a high volume of inserts, or for heavy query usage. Today the translation layer only handles a limited subset of the BigQuery dialect. As such, the Log Explorer may produce errors for more advanced queries when using the Postgres Backend.Getting Started#The Postgres backend is recommended when familiarizing and experimenting with self-hosting Supabase. For production, we recommend using the BigQuery backend. See production recommendations for more information.To set up logging in self-hosted Supabase, see the docker-compose example.\nTwo compose services are required: Logflare, and Vector. Logflare is the HTTP Analytics server, while Vector is the logging pipeline to route all compose services' syslog to the Logflare sever.Regardless of the backend chosen, the following environment variables must be set for the supabase/logflare docker image:\nLOGFLARE_SINGLE_TENANT=true: The feature flag for enabling single tenant mode for Logflare. Must be set to true\nLOGFLARE_SUPABASE_MODE=true: The feature flag for seeding Supabase-related data. Must be set to true\nFor all other configuration environment variables, please refer to the Logflare self-hosting documentation.Postgres Backend Setup#The example docker-compose uses the Postgres backend out of the box._10# clone the supabase/supabase repo, and run the following_10cd docker_10docker compose -f docker-compose.yml upConfiguration and Requirements#\nsupabase/logflare:1.4.0 or above\nRelevant environment variables:\n\nPOSTGRES_BACKEND_URL : Required. The connection string to the Postgres database.\nPOSTGRES_BACKEND_SCHEMA : Optional. Allows customization of the schema used to scope all backend operations within the database.\n\n\nBigQuery Backend Setup#The BigQuery backend is a more robust and scalable backend option that is battle-tested and production ready. Use this backend if you intend to have heavy logging usage and require advanced querying features such as the Logs Explorer.Configuration and Requirements#The requirements are as follows after creating the project:\nGoogle Cloud project with billing enabled\nProject ID\nProject number\nA service account key.\nYou must enable billing on your Google Cloud project, as a valid billing account is required for streaming inserts.Setting up BigQuery Service Account#The service account used must have sufficient permissions to insert into your Google Cloud BigQuery. Ensure that the service account has either:\nBigQuery Admin role; or\nThe following permissions:\n\nbigquery.datasets.create\nbigquery.datasets.get\nbigquery.datasets.getIamPolicy\nbigquery.datasets.update\nbigquery.jobs.create\nbigquery.routines.create\nbigquery.routines.update\nbigquery.tables.create\nbigquery.tables.delete\nbigquery.tables.get\nbigquery.tables.getData\nbigquery.tables.update\nbigquery.tables.updateData\n\n\nYou can create the service account via the web console or gcloud CLI, as per the Google Cloud documentation. In the web console, you can create the key by navigating to IAM > Service Accounts > Actions (dropdown) > Manage KeysWe recommend setting the BigQuery Admin role, as it simplifies permissions setup.Download the Service Account Keys#After the service account is created, you will need to create a key for the service account. This key will sign the JWTs for API requests that the Analytics server makes with BigQuery. This can be done through the IAM section in Google Cloud console.Docker Image Configuration#Using the example self-hosting stack based on docker-compose, you include the logging related services using the following command\nUpdate the .env.example file with the necessary environment variables.\n\nGOOGLE_PROJECT_ID\nGOOGLE_PROJECT_NUMBER\n\nPlace your Service Account key in your present working directory with the filename gcloud.json.\nOn docker-compose.yml, uncomment the block section below the commentary # Uncomment to use Big Query backend for analytics\nOn docker-compose.yml, comment the block section below the commentary # Comment variables to use Big Query backend for analytics\nThereafter, you can start the example stack using the following command:_10# assuming you clone the supabase/supabase repo._10cd docker_10docker compose -f docker-compose.ymlBigQuery Datset Storage Location#Currently, all BigQuery datasets stored and managed by Analytics, whether via CLI or self-hosted, will default to the US region.Vector Usage#In the Docker Compose example, Vector is used for the logging pipieline, where log events are forwarded to the Analytics API for ingestion.Please refer to the Vector configuration file when customizing your own setup.You must ensure that the payloads matches the expected event schema structure. Without the correct structure, it would cause the Studio Logs UI features to break.Differences from Platform#API logs rely on Kong instead of the Supabase Cloud API Gateway. Logs from Kong are not enriched with platform-only data.Within the self-hosted setup, all logs are routed to Logflare via Vector. As Kong routes API requests to PostgREST, self-hosted or local deployments will result in Kong request logs instead.\nThis would result in differences in the log event metadata between self-hosted API requests and Supabase Platform requests.Production Recommendations#To self-host in a production setting, we recommend performing the following for a better experience.Ensure that Logflare is behind a firewall and restrict all network access to it besides safe requests.#Self-hosted Logflare has UI authentication disabled and is intended for exposure to the internet. We recommend restricting access to the dashboard, accessible at the /dashboard path.\nIf dashboard access is required for managing sources, we recommend having an authentication layer, such as a VPN.Use a different Postgres Database to store Logflare data.#Logflare requires a Postgres database to function. However, if there is an issue with you self-hosted Postgres service, you would not be able to debug it as it would also bring Logflare down together.The self-hosted example is only used as a minimal example on running the entire stack, however it is not recommended to use the same database server for both production and observability.Use Big Query as the Logflare Backend#The current Postgres Ingestion backend isn't optimized for production usage. We recommend using Big Query for more heavy use cases.We recommend using the BigQuery backend for production environments as it offers better scaling and querying/debugging experiences.Client libraries#\nJavaScript - Pino Transport\nElixir\nElixir - Logger Backend\nErlang\nErlang - Lager Backend\nCloudflare Worker\nIntegrations#\nFly - Logs\nVercel Integration - Logs\nCloudflare App - Logs\nAdditional links#\nSource code\nOpenAPI docs\nSupabase Acquires Logflare\nLogflare self-hosting docs\nList endpointsget/api/endpointsResponse codes200Response (200)exampleschema[\n  {\n    \"cache_duration_seconds\": 42,\n    \"enable_auth\": true,\n    \"inserted_at\": \"2021-12-31T23:34:00Z\",\n    \"max_limit\": 42,\n    \"name\": \"lorem\",\n    \"proactive_requerying_seconds\": 42,\n    \"query\": \"lorem\",\n    \"sandboxable\": true,\n    \"source_mapping\": {},\n    \"token\": \"lorem\",\n    \"updated_at\": \"2021-12-31T23:34:00Z\"\n  }\n]  Create endpointpost/api/endpointsBodycache_duration_secondsOptionalintegerenable_authOptionalbooleaninserted_atOptionalstringmax_limitOptionalintegernameRequiredstringproactive_requerying_secondsOptionalintegerqueryRequiredstringsandboxableOptionalbooleansource_mappingOptionalobjectObject schematokenOptionalstringupdated_atOptionalstringResponse codes201404Response (201)exampleschema{\n  \"cache_duration_seconds\": 42,\n  \"enable_auth\": true,\n  \"inserted_at\": \"2021-12-31T23:34:00Z\",\n  \"max_limit\": 42,\n  \"name\": \"lorem\",\n  \"proactive_requerying_seconds\": 42,\n  \"query\": \"lorem\",\n  \"sandboxable\": true,\n  \"source_mapping\": {},\n  \"token\": \"lorem\",\n  \"updated_at\": \"2021-12-31T23:34:00Z\"\n}  Delete endpointdelete/api/endpoints/{token}Path parameterstokenRequiredstringEndpoint TokenResponse codes204404Response (204)schema{}  Fetch endpointget/api/endpoints/{token}Path parameterstokenRequiredstringEndpoint TokenResponse codes200404Response (200)exampleschema{\n  \"cache_duration_seconds\": 42,\n  \"enable_auth\": true,\n  \"inserted_at\": \"2021-12-31T23:34:00Z\",\n  \"max_limit\": 42,\n  \"name\": \"lorem\",\n  \"proactive_requerying_seconds\": 42,\n  \"query\": \"lorem\",\n  \"sandboxable\": true,\n  \"source_mapping\": {},\n  \"token\": \"lorem\",\n  \"updated_at\": \"2021-12-31T23:34:00Z\"\n}  Update endpointput/api/endpoints/{token}Path parameterstokenRequiredstringEndpoint TokenBodycache_duration_secondsOptionalintegerenable_authOptionalbooleaninserted_atOptionalstringmax_limitOptionalintegernameRequiredstringproactive_requerying_secondsOptionalintegerqueryRequiredstringsandboxableOptionalbooleansource_mappingOptionalobjectObject schematokenOptionalstringupdated_atOptionalstringResponse codes201404Response (201)exampleschema{\n  \"cache_duration_seconds\": 42,\n  \"enable_auth\": true,\n  \"inserted_at\": \"2021-12-31T23:34:00Z\",\n  \"max_limit\": 42,\n  \"name\": \"lorem\",\n  \"proactive_requerying_seconds\": 42,\n  \"query\": \"lorem\",\n  \"sandboxable\": true,\n  \"source_mapping\": {},\n  \"token\": \"lorem\",\n  \"updated_at\": \"2021-12-31T23:34:00Z\"\n}  List sourcesget/api/sourcesResponse codes200Response (200)schema{\n  \"items\": {\n    \"properties\": {\n      \"api_quota\": {\n        \"type\": \"integer\"\n      },\n      \"bigquery_table_ttl\": {\n        \"type\": \"integer\"\n      },\n      \"bq_table_id\": {\n        \"type\": \"string\"\n      },\n      \"bq_table_schema\": {\n        \"type\": \"object\"\n      },\n      \"custom_event_message_keys\": {\n        \"type\": \"string\"\n      },\n      \"favorite\": {\n        \"type\": \"boolean\"\n      },\n      \"has_rejected_events\": {\n        \"type\": \"boolean\"\n      },\n      \"id\": {},\n      \"inserted_at\": {\n        \"format\": \"date-time\",\n        \"type\": \"string\"\n      },\n      \"metrics\": {\n        \"type\": \"object\"\n      },\n      \"name\": {\n        \"type\": \"string\"\n      },\n      \"notifications\": {\n        \"items\": {\n          \"properties\": {\n            \"other_email_notifications\": {\n              \"type\": \"string\"\n            },\n            \"team_user_ids_for_email\": {\n              \"allOf\": {\n                \"type\": \"string\"\n              },\n              \"type\": \"array\"\n            },\n            \"team_user_ids_for_schema_updates\": {\n              \"allOf\": {\n                \"type\": \"string\"\n              },\n              \"type\": \"array\"\n            },\n            \"team_user_ids_for_sms\": {\n              \"allOf\": {\n                \"type\": \"string\"\n              },\n              \"type\": \"array\"\n            },\n            \"user_email_notifications\": {\n              \"type\": \"boolean\"\n            },\n            \"user_schema_update_notifications\": {\n              \"type\": \"boolean\"\n            },\n            \"user_text_notifications\": {\n              \"type\": \"boolean\"\n            }\n          },\n          \"title\": \"Notification\",\n          \"type\": \"object\"\n        },\n        \"type\": \"array\"\n      },\n      \"public_token\": {\n        \"type\": \"string\"\n      },\n      \"slack_hook_url\": {\n        \"type\": \"string\"\n      },\n      \"token\": {\n        \"type\": \"string\"\n      },\n      \"updated_at\": {\n        \"format\": \"date-time\",\n        \"type\": \"string\"\n      },\n      \"webhook_notification_url\": {\n        \"type\": \"string\"\n      }\n    },\n    \"required\": [\n      \"name\"\n    ],\n    \"title\": \"Source\",\n    \"type\": \"object\"\n  },\n  \"type\": \"array\"\n}  Create sourcepost/api/sourcesBodyapi_quotaOptionalintegerbigquery_table_ttlOptionalintegerbq_table_idOptionalstringbq_table_schemaOptionalobjectObject schemacustom_event_message_keysOptionalstringfavoriteOptionalbooleanhas_rejected_eventsOptionalbooleanidOptionalDetailsinserted_atOptionalstringmetricsOptionalobjectObject schemanameRequiredstringnotificationsOptionalArray<object>Itemspublic_tokenOptionalstringslack_hook_urlOptionalstringtokenOptionalstringupdated_atOptionalstringwebhook_notification_urlOptionalstringResponse codes201404Response (201)schema{\n  \"properties\": {\n    \"api_quota\": {\n      \"type\": \"integer\"\n    },\n    \"bigquery_table_ttl\": {\n      \"type\": \"integer\"\n    },\n    \"bq_table_id\": {\n      \"type\": \"string\"\n    },\n    \"bq_table_schema\": {\n      \"type\": \"object\"\n    },\n    \"custom_event_message_keys\": {\n      \"type\": \"string\"\n    },\n    \"favorite\": {\n      \"type\": \"boolean\"\n    },\n    \"has_rejected_events\": {\n      \"type\": \"boolean\"\n    },\n    \"id\": {},\n    \"inserted_at\": {\n      \"format\": \"date-time\",\n      \"type\": \"string\"\n    },\n    \"metrics\": {\n      \"type\": \"object\"\n    },\n    \"name\": {\n      \"type\": \"string\"\n    },\n    \"notifications\": {\n      \"items\": {\n        \"properties\": {\n          \"other_email_notifications\": {\n            \"type\": \"string\"\n          },\n          \"team_user_ids_for_email\": {\n            \"allOf\": {\n              \"type\": \"string\"\n            },\n            \"type\": \"array\"\n          },\n          \"team_user_ids_for_schema_updates\": {\n            \"allOf\": {\n              \"type\": \"string\"\n            },\n            \"type\": \"array\"\n          },\n          \"team_user_ids_for_sms\": {\n            \"allOf\": {\n              \"type\": \"string\"\n            },\n            \"type\": \"array\"\n          },\n          \"user_email_notifications\": {\n            \"type\": \"boolean\"\n          },\n          \"user_schema_update_notifications\": {\n            \"type\": \"boolean\"\n          },\n          \"user_text_notifications\": {\n            \"type\": \"boolean\"\n          }\n        },\n        \"title\": \"Notification\",\n        \"type\": \"object\"\n      },\n      \"type\": \"array\"\n    },\n    \"public_token\": {\n      \"type\": \"string\"\n    },\n    \"slack_hook_url\": {\n      \"type\": \"string\"\n    },\n    \"token\": {\n      \"type\": \"string\"\n    },\n    \"updated_at\": {\n      \"format\": \"date-time\",\n      \"type\": \"string\"\n    },\n    \"webhook_notification_url\": {\n      \"type\": \"string\"\n    }\n  },\n  \"required\": [\n    \"name\"\n  ],\n  \"title\": \"Source\",\n  \"type\": \"object\"\n}  Delete sourcedelete/api/sources/{token}Path parameterstokenRequiredstringSource TokenResponse codes204404Response (204)schema{}  Fetch sourceget/api/sources/{token}Path parameterstokenRequiredstringSource TokenResponse codes200404Response (200)schema{\n  \"properties\": {\n    \"api_quota\": {\n      \"type\": \"integer\"\n    },\n    \"bigquery_table_ttl\": {\n      \"type\": \"integer\"\n    },\n    \"bq_table_id\": {\n      \"type\": \"string\"\n    },\n    \"bq_table_schema\": {\n      \"type\": \"object\"\n    },\n    \"custom_event_message_keys\": {\n      \"type\": \"string\"\n    },\n    \"favorite\": {\n      \"type\": \"boolean\"\n    },\n    \"has_rejected_events\": {\n      \"type\": \"boolean\"\n    },\n    \"id\": {},\n    \"inserted_at\": {\n      \"format\": \"date-time\",\n      \"type\": \"string\"\n    },\n    \"metrics\": {\n      \"type\": \"object\"\n    },\n    \"name\": {\n      \"type\": \"string\"\n    },\n    \"notifications\": {\n      \"items\": {\n        \"properties\": {\n          \"other_email_notifications\": {\n            \"type\": \"string\"\n          },\n          \"team_user_ids_for_email\": {\n            \"allOf\": {\n              \"type\": \"string\"\n            },\n            \"type\": \"array\"\n          },\n          \"team_user_ids_for_schema_updates\": {\n            \"allOf\": {\n              \"type\": \"string\"\n            },\n            \"type\": \"array\"\n          },\n          \"team_user_ids_for_sms\": {\n            \"allOf\": {\n              \"type\": \"string\"\n            },\n            \"type\": \"array\"\n          },\n          \"user_email_notifications\": {\n            \"type\": \"boolean\"\n          },\n          \"user_schema_update_notifications\": {\n            \"type\": \"boolean\"\n          },\n          \"user_text_notifications\": {\n            \"type\": \"boolean\"\n          }\n        },\n        \"title\": \"Notification\",\n        \"type\": \"object\"\n      },\n      \"type\": \"array\"\n    },\n    \"public_token\": {\n      \"type\": \"string\"\n    },\n    \"slack_hook_url\": {\n      \"type\": \"string\"\n    },\n    \"token\": {\n      \"type\": \"string\"\n    },\n    \"updated_at\": {\n      \"format\": \"date-time\",\n      \"type\": \"string\"\n    },\n    \"webhook_notification_url\": {\n      \"type\": \"string\"\n    }\n  },\n  \"required\": [\n    \"name\"\n  ],\n  \"title\": \"Source\",\n  \"type\": \"object\"\n}  Update sourceput/api/sources/{token}Path parameterstokenRequiredstringSource TokenBodyapi_quotaOptionalintegerbigquery_table_ttlOptionalintegerbq_table_idOptionalstringbq_table_schemaOptionalobjectObject schemacustom_event_message_keysOptionalstringfavoriteOptionalbooleanhas_rejected_eventsOptionalbooleanidOptionalDetailsinserted_atOptionalstringmetricsOptionalobjectObject schemanameRequiredstringnotificationsOptionalArray<object>Itemspublic_tokenOptionalstringslack_hook_urlOptionalstringtokenOptionalstringupdated_atOptionalstringwebhook_notification_urlOptionalstringResponse codes201404Response (201)schema{\n  \"properties\": {\n    \"api_quota\": {\n      \"type\": \"integer\"\n    },\n    \"bigquery_table_ttl\": {\n      \"type\": \"integer\"\n    },\n    \"bq_table_id\": {\n      \"type\": \"string\"\n    },\n    \"bq_table_schema\": {\n      \"type\": \"object\"\n    },\n    \"custom_event_message_keys\": {\n      \"type\": \"string\"\n    },\n    \"favorite\": {\n      \"type\": \"boolean\"\n    },\n    \"has_rejected_events\": {\n      \"type\": \"boolean\"\n    },\n    \"id\": {},\n    \"inserted_at\": {\n      \"format\": \"date-time\",\n      \"type\": \"string\"\n    },\n    \"metrics\": {\n      \"type\": \"object\"\n    },\n    \"name\": {\n      \"type\": \"string\"\n    },\n    \"notifications\": {\n      \"items\": {\n        \"properties\": {\n          \"other_email_notifications\": {\n            \"type\": \"string\"\n          },\n          \"team_user_ids_for_email\": {\n            \"allOf\": {\n              \"type\": \"string\"\n            },\n            \"type\": \"array\"\n          },\n          \"team_user_ids_for_schema_updates\": {\n            \"allOf\": {\n              \"type\": \"string\"\n            },\n            \"type\": \"array\"\n          },\n          \"team_user_ids_for_sms\": {\n            \"allOf\": {\n              \"type\": \"string\"\n            },\n            \"type\": \"array\"\n          },\n          \"user_email_notifications\": {\n            \"type\": \"boolean\"\n          },\n          \"user_schema_update_notifications\": {\n            \"type\": \"boolean\"\n          },\n          \"user_text_notifications\": {\n            \"type\": \"boolean\"\n          }\n        },\n        \"title\": \"Notification\",\n        \"type\": \"object\"\n      },\n      \"type\": \"array\"\n    },\n    \"public_token\": {\n      \"type\": \"string\"\n    },\n    \"slack_hook_url\": {\n      \"type\": \"string\"\n    },\n    \"token\": {\n      \"type\": \"string\"\n    },\n    \"updated_at\": {\n      \"format\": \"date-time\",\n      \"type\": \"string\"\n    },\n    \"webhook_notification_url\": {\n      \"type\": \"string\"\n    }\n  },\n  \"required\": [\n    \"name\"\n  ],\n  \"title\": \"Source\",\n  \"type\": \"object\"\n}  List teamsget/api/teamsResponse codes200Response (200)exampleschema[\n  {\n    \"name\": \"lorem\",\n    \"team_users\": [\n      {\n        \"email\": \"lorem\",\n        \"name\": \"lorem\"\n      }\n    ],\n    \"token\": \"lorem\",\n    \"user\": {\n      \"api_key\": \"lorem\",\n      \"api_quota\": 42,\n      \"bigquery_dataset_id\": \"lorem\",\n      \"bigquery_dataset_location\": \"lorem\",\n      \"bigquery_project_id\": \"lorem\",\n      \"company\": \"lorem\",\n      \"email\": \"lorem\",\n      \"email_me_product\": true,\n      \"email_preferred\": \"lorem\",\n      \"image\": \"lorem\",\n      \"name\": \"lorem\",\n      \"phone\": \"lorem\",\n      \"provider\": \"lorem\",\n      \"token\": \"lorem\"\n    }\n  }\n]  Create Teampost/api/teamsBodynameRequiredstringteam_usersOptionalArray<object>ItemstokenOptionalstringuserOptionalobjectObject schemaResponse codes201404Response (201)exampleschema{\n  \"name\": \"lorem\",\n  \"team_users\": [\n    {\n      \"email\": \"lorem\",\n      \"name\": \"lorem\"\n    }\n  ],\n  \"token\": \"lorem\",\n  \"user\": {\n    \"api_key\": \"lorem\",\n    \"api_quota\": 42,\n    \"bigquery_dataset_id\": \"lorem\",\n    \"bigquery_dataset_location\": \"lorem\",\n    \"bigquery_project_id\": \"lorem\",\n    \"company\": \"lorem\",\n    \"email\": \"lorem\",\n    \"email_me_product\": true,\n    \"email_preferred\": \"lorem\",\n    \"image\": \"lorem\",\n    \"name\": \"lorem\",\n    \"phone\": \"lorem\",\n    \"provider\": \"lorem\",\n    \"token\": \"lorem\"\n  }\n}  Delete Teamdelete/api/teams/{token}Path parameterstokenRequiredstringTeam TokenResponse codes204404Response (204)schema{}  Fetch teamget/api/teams/{token}Path parameterstokenRequiredstringTeam TokenResponse codes200404Response (200)exampleschema{\n  \"name\": \"lorem\",\n  \"team_users\": [\n    {\n      \"email\": \"lorem\",\n      \"name\": \"lorem\"\n    }\n  ],\n  \"token\": \"lorem\",\n  \"user\": {\n    \"api_key\": \"lorem\",\n    \"api_quota\": 42,\n    \"bigquery_dataset_id\": \"lorem\",\n    \"bigquery_dataset_location\": \"lorem\",\n    \"bigquery_project_id\": \"lorem\",\n    \"company\": \"lorem\",\n    \"email\": \"lorem\",\n    \"email_me_product\": true,\n    \"email_preferred\": \"lorem\",\n    \"image\": \"lorem\",\n    \"name\": \"lorem\",\n    \"phone\": \"lorem\",\n    \"provider\": \"lorem\",\n    \"token\": \"lorem\"\n  }\n}  Update teamput/api/teams/{token}Path parameterstokenRequiredstringTeam TokenBodynameRequiredstringteam_usersOptionalArray<object>ItemstokenOptionalstringuserOptionalobjectObject schemaResponse codes201404Response (201)exampleschema{\n  \"name\": \"lorem\",\n  \"team_users\": [\n    {\n      \"email\": \"lorem\",\n      \"name\": \"lorem\"\n    }\n  ],\n  \"token\": \"lorem\",\n  \"user\": {\n    \"api_key\": \"lorem\",\n    \"api_quota\": 42,\n    \"bigquery_dataset_id\": \"lorem\",\n    \"bigquery_dataset_location\": \"lorem\",\n    \"bigquery_project_id\": \"lorem\",\n    \"company\": \"lorem\",\n    \"email\": \"lorem\",\n    \"email_me_product\": true,\n    \"email_preferred\": \"lorem\",\n    \"image\": \"lorem\",\n    \"name\": \"lorem\",\n    \"phone\": \"lorem\",\n    \"provider\": \"lorem\",\n    \"token\": \"lorem\"\n  }\n}\n[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nSelf-Hosting Analytics\nThe Supabase Analytics server is a Logflare self-hostable instance that manages the ingestion and query pipelines for searching and aggregating structured analytics events.When self-hosting the Analytics server, the full logging experience matching that of the Supabase Platform is available in the Studio instance, allowing for an integrated and enhanced development experience.\nHowever, it's important to note that certain differences may arise due to the platform's infrastructure.Logflare Technical DocsAll Logflare technical documentation is available at https://docs.logflare.app.Backends Supported#The Analytics server supports either Postgres or BigQuery as the backend. The supabase-cli experience uses the Postgres backend out-of-the-box. However, the Supabase Platform uses the BigQuery backend for storing all platform logs.When using the BigQuery backend, a BigQuery dataset is created in the provided Google Cloud project, and tables are created for each source. Log events are streamed into each table, and all queries generated by Studio or by the Logs Explorer are executed against the BigQuery API. This backend requires internet access to work, and cannot be run fully locally.When using the Postgres backend, tables are created for each source within the provided schema (for supabase-cli, this would be _analytics). Log events received by Logflare are inserted directly into the respective tables. All BigQuery-dialect SQL queries from Studio will be handled by a translation layer within the Analytics server. This translation layer translates the query to PostgreSQL dialect, and then executes it against the Postgres database.The Postgres backend is not yet optimized for a high volume of inserts, or for heavy query usage. Today the translation layer only handles a limited subset of the BigQuery dialect. As such, the Log Explorer may produce errors for more advanced queries when using the Postgres Backend.Getting Started#The Postgres backend is recommended when familiarizing and experimenting with self-hosting Supabase. For production, we recommend using the BigQuery backend. See production recommendations for more information.To set up logging in self-hosted Supabase, see the docker-compose example.\nTwo compose services are required: Logflare, and Vector. Logflare is the HTTP Analytics server, while Vector is the logging pipeline to route all compose services' syslog to the Logflare sever.Regardless of the backend chosen, the following environment variables must be set for the supabase/logflare docker image:\nLOGFLARE_SINGLE_TENANT=true: The feature flag for enabling single tenant mode for Logflare. Must be set to true\nLOGFLARE_SUPABASE_MODE=true: The feature flag for seeding Supabase-related data. Must be set to true\nFor all other configuration environment variables, please refer to the Logflare self-hosting documentation.Postgres Backend Setup#The example docker-compose uses the Postgres backend out of the box._10# clone the supabase/supabase repo, and run the following_10cd docker_10docker compose -f docker-compose.yml upConfiguration and Requirements#\nsupabase/logflare:1.4.0 or above\nRelevant environment variables:\n\nPOSTGRES_BACKEND_URL : Required. The connection string to the Postgres database.\nPOSTGRES_BACKEND_SCHEMA : Optional. Allows customization of the schema used to scope all backend operations within the database.\n\n\nBigQuery Backend Setup#The BigQuery backend is a more robust and scalable backend option that is battle-tested and production ready. Use this backend if you intend to have heavy logging usage and require advanced querying features such as the Logs Explorer.Configuration and Requirements#The requirements are as follows after creating the project:\nGoogle Cloud project with billing enabled\nProject ID\nProject number\nA service account key.\nYou must enable billing on your Google Cloud project, as a valid billing account is required for streaming inserts.Setting up BigQuery Service Account#The service account used must have sufficient permissions to insert into your Google Cloud BigQuery. Ensure that the service account has either:\nBigQuery Admin role; or\nThe following permissions:\n\nbigquery.datasets.create\nbigquery.datasets.get\nbigquery.datasets.getIamPolicy\nbigquery.datasets.update\nbigquery.jobs.create\nbigquery.routines.create\nbigquery.routines.update\nbigquery.tables.create\nbigquery.tables.delete\nbigquery.tables.get\nbigquery.tables.getData\nbigquery.tables.update\nbigquery.tables.updateData\n\n\nYou can create the service account via the web console or gcloud CLI, as per the Google Cloud documentation. In the web console, you can create the key by navigating to IAM > Service Accounts > Actions (dropdown) > Manage KeysWe recommend setting the BigQuery Admin role, as it simplifies permissions setup.Download the Service Account Keys#After the service account is created, you will need to create a key for the service account. This key will sign the JWTs for API requests that the Analytics server makes with BigQuery. This can be done through the IAM section in Google Cloud console.Docker Image Configuration#Using the example self-hosting stack based on docker-compose, you include the logging related services using the following command\nUpdate the .env.example file with the necessary environment variables.\n\nGOOGLE_PROJECT_ID\nGOOGLE_PROJECT_NUMBER\n\nPlace your Service Account key in your present working directory with the filename gcloud.json.\nOn docker-compose.yml, uncomment the block section below the commentary # Uncomment to use Big Query backend for analytics\nOn docker-compose.yml, comment the block section below the commentary # Comment variables to use Big Query backend for analytics\nThereafter, you can start the example stack using the following command:_10# assuming you clone the supabase/supabase repo._10cd docker_10docker compose -f docker-compose.ymlBigQuery Datset Storage Location#Currently, all BigQuery datasets stored and managed by Analytics, whether via CLI or self-hosted, will default to the US region.Vector Usage#In the Docker Compose example, Vector is used for the logging pipieline, where log events are forwarded to the Analytics API for ingestion.Please refer to the Vector configuration file when customizing your own setup.You must ensure that the payloads matches the expected event schema structure. Without the correct structure, it would cause the Studio Logs UI features to break.Differences from Platform#API logs rely on Kong instead of the Supabase Cloud API Gateway. Logs from Kong are not enriched with platform-only data.Within the self-hosted setup, all logs are routed to Logflare via Vector. As Kong routes API requests to PostgREST, self-hosted or local deployments will result in Kong request logs instead.\nThis would result in differences in the log event metadata between self-hosted API requests and Supabase Platform requests.Production Recommendations#To self-host in a production setting, we recommend performing the following for a better experience.Ensure that Logflare is behind a firewall and restrict all network access to it besides safe requests.#Self-hosted Logflare has UI authentication disabled and is intended for exposure to the internet. We recommend restricting access to the dashboard, accessible at the /dashboard path.\nIf dashboard access is required for managing sources, we recommend having an authentication layer, such as a VPN.Use a different Postgres Database to store Logflare data.#Logflare requires a Postgres database to function. However, if there is an issue with you self-hosted Postgres service, you would not be able to debug it as it would also bring Logflare down together.The self-hosted example is only used as a minimal example on running the entire stack, however it is not recommended to use the same database server for both production and observability.Use Big Query as the Logflare Backend#The current Postgres Ingestion backend isn't optimized for production usage. We recommend using Big Query for more heavy use cases.We recommend using the BigQuery backend for production environments as it offers better scaling and querying/debugging experiences.Client libraries#\nJavaScript - Pino Transport\nElixir\nElixir - Logger Backend\nErlang\nErlang - Lager Backend\nCloudflare Worker\nIntegrations#\nFly - Logs\nVercel Integration - Logs\nCloudflare App - Logs\nAdditional links#\nSource code\nOpenAPI docs\nSupabase Acquires Logflare\nLogflare self-hosting docs\nSelf-Hosting Analytics\nThe Supabase Analytics server is a Logflare self-hostable instance that manages the ingestion and query pipelines for searching and aggregating structured analytics events.\nWhen self-hosting the Analytics server, the full logging experience matching that of the Supabase Platform is available in the Studio instance, allowing for an integrated and enhanced development experience.\nHowever, it's important to note that certain differences may arise due to the platform's infrastructure.\nLogflare Technical Docs\nAll Logflare technical documentation is available at https://docs.logflare.app.\nBackends Supported#\nThe Analytics server supports either Postgres or BigQuery as the backend. The supabase-cli experience uses the Postgres backend out-of-the-box. However, the Supabase Platform uses the BigQuery backend for storing all platform logs.\nWhen using the BigQuery backend, a BigQuery dataset is created in the provided Google Cloud project, and tables are created for each source. Log events are streamed into each table, and all queries generated by Studio or by the Logs Explorer are executed against the BigQuery API. This backend requires internet access to work, and cannot be run fully locally.\nWhen using the Postgres backend, tables are created for each source within the provided schema (for supabase-cli, this would be _analytics). Log events received by Logflare are inserted directly into the respective tables. All BigQuery-dialect SQL queries from Studio will be handled by a translation layer within the Analytics server. This translation layer translates the query to PostgreSQL dialect, and then executes it against the Postgres database.\nThe Postgres backend is not yet optimized for a high volume of inserts, or for heavy query usage. Today the translation layer only handles a limited subset of the BigQuery dialect. As such, the Log Explorer may produce errors for more advanced queries when using the Postgres Backend.\nGetting Started#\nThe Postgres backend is recommended when familiarizing and experimenting with self-hosting Supabase. For production, we recommend using the BigQuery backend. See production recommendations for more information.\nTo set up logging in self-hosted Supabase, see the docker-compose example.\nTwo compose services are required: Logflare, and Vector. Logflare is the HTTP Analytics server, while Vector is the logging pipeline to route all compose services' syslog to the Logflare sever.\nRegardless of the backend chosen, the following environment variables must be set for the supabase/logflare docker image:\nFor all other configuration environment variables, please refer to the Logflare self-hosting documentation.\nPostgres Backend Setup#\nThe example docker-compose uses the Postgres backend out of the box.\nConfiguration and Requirements#\nBigQuery Backend Setup#\nThe BigQuery backend is a more robust and scalable backend option that is battle-tested and production ready. Use this backend if you intend to have heavy logging usage and require advanced querying features such as the Logs Explorer.\nConfiguration and Requirements#\nThe requirements are as follows after creating the project:\nYou must enable billing on your Google Cloud project, as a valid billing account is required for streaming inserts.\nSetting up BigQuery Service Account#\nThe service account used must have sufficient permissions to insert into your Google Cloud BigQuery. Ensure that the service account has either:\nYou can create the service account via the web console or gcloud CLI, as per the Google Cloud documentation. In the web console, you can create the key by navigating to IAM > Service Accounts > Actions (dropdown) > Manage Keys\nWe recommend setting the BigQuery Admin role, as it simplifies permissions setup.\nDownload the Service Account Keys#\nAfter the service account is created, you will need to create a key for the service account. This key will sign the JWTs for API requests that the Analytics server makes with BigQuery. This can be done through the IAM section in Google Cloud console.\nDocker Image Configuration#\nUsing the example self-hosting stack based on docker-compose, you include the logging related services using the following command\nThereafter, you can start the example stack using the following command:\nBigQuery Datset Storage Location#\nCurrently, all BigQuery datasets stored and managed by Analytics, whether via CLI or self-hosted, will default to the US region.\nVector Usage#\nIn the Docker Compose example, Vector is used for the logging pipieline, where log events are forwarded to the Analytics API for ingestion.\nPlease refer to the Vector configuration file when customizing your own setup.\nYou must ensure that the payloads matches the expected event schema structure. Without the correct structure, it would cause the Studio Logs UI features to break.\nDifferences from Platform#\nAPI logs rely on Kong instead of the Supabase Cloud API Gateway. Logs from Kong are not enriched with platform-only data.\nWithin the self-hosted setup, all logs are routed to Logflare via Vector. As Kong routes API requests to PostgREST, self-hosted or local deployments will result in Kong request logs instead.\nThis would result in differences in the log event metadata between self-hosted API requests and Supabase Platform requests.\nProduction Recommendations#\nTo self-host in a production setting, we recommend performing the following for a better experience.\nEnsure that Logflare is behind a firewall and restrict all network access to it besides safe requests.#\nSelf-hosted Logflare has UI authentication disabled and is intended for exposure to the internet. We recommend restricting access to the dashboard, accessible at the /dashboard path.\nIf dashboard access is required for managing sources, we recommend having an authentication layer, such as a VPN.\nUse a different Postgres Database to store Logflare data.#\nLogflare requires a Postgres database to function. However, if there is an issue with you self-hosted Postgres service, you would not be able to debug it as it would also bring Logflare down together.\nThe self-hosted example is only used as a minimal example on running the entire stack, however it is not recommended to use the same database server for both production and observability.\nUse Big Query as the Logflare Backend#\nThe current Postgres Ingestion backend isn't optimized for production usage. We recommend using Big Query for more heavy use cases.\nWe recommend using the BigQuery backend for production environments as it offers better scaling and querying/debugging experiences.\nClient libraries#\nIntegrations#\nAdditional links#\nList endpointsget/api/endpointsResponse codes200Response (200)exampleschema[\n  {\n    \"cache_duration_seconds\": 42,\n    \"enable_auth\": true,\n    \"inserted_at\": \"2021-12-31T23:34:00Z\",\n    \"max_limit\": 42,\n    \"name\": \"lorem\",\n    \"proactive_requerying_seconds\": 42,\n    \"query\": \"lorem\",\n    \"sandboxable\": true,\n    \"source_mapping\": {},\n    \"token\": \"lorem\",\n    \"updated_at\": \"2021-12-31T23:34:00Z\"\n  }\n]\nList endpoints\nResponse codes200\nResponse codes\nResponse (200)\nCreate endpointpost/api/endpointsBodycache_duration_secondsOptionalintegerenable_authOptionalbooleaninserted_atOptionalstringmax_limitOptionalintegernameRequiredstringproactive_requerying_secondsOptionalintegerqueryRequiredstringsandboxableOptionalbooleansource_mappingOptionalobjectObject schematokenOptionalstringupdated_atOptionalstringResponse codes201404Response (201)exampleschema{\n  \"cache_duration_seconds\": 42,\n  \"enable_auth\": true,\n  \"inserted_at\": \"2021-12-31T23:34:00Z\",\n  \"max_limit\": 42,\n  \"name\": \"lorem\",\n  \"proactive_requerying_seconds\": 42,\n  \"query\": \"lorem\",\n  \"sandboxable\": true,\n  \"source_mapping\": {},\n  \"token\": \"lorem\",\n  \"updated_at\": \"2021-12-31T23:34:00Z\"\n}\nCreate endpoint\nBodycache_duration_secondsOptionalintegerenable_authOptionalbooleaninserted_atOptionalstringmax_limitOptionalintegernameRequiredstringproactive_requerying_secondsOptionalintegerqueryRequiredstringsandboxableOptionalbooleansource_mappingOptionalobjectObject schematokenOptionalstringupdated_atOptionalstring\nBody\nResponse codes201404\nResponse codes\nResponse (201)\nDelete endpointdelete/api/endpoints/{token}Path parameterstokenRequiredstringEndpoint TokenResponse codes204404Response (204)schema{}\nDelete endpoint\nPath parameterstokenRequiredstringEndpoint Token\nPath parameters\nEndpoint Token\nResponse codes204404\nResponse codes\nResponse (204)\nFetch endpointget/api/endpoints/{token}Path parameterstokenRequiredstringEndpoint TokenResponse codes200404Response (200)exampleschema{\n  \"cache_duration_seconds\": 42,\n  \"enable_auth\": true,\n  \"inserted_at\": \"2021-12-31T23:34:00Z\",\n  \"max_limit\": 42,\n  \"name\": \"lorem\",\n  \"proactive_requerying_seconds\": 42,\n  \"query\": \"lorem\",\n  \"sandboxable\": true,\n  \"source_mapping\": {},\n  \"token\": \"lorem\",\n  \"updated_at\": \"2021-12-31T23:34:00Z\"\n}\nFetch endpoint\nPath parameterstokenRequiredstringEndpoint Token\nPath parameters\nEndpoint Token\nResponse codes200404\nResponse codes\nResponse (200)\nUpdate endpointput/api/endpoints/{token}Path parameterstokenRequiredstringEndpoint TokenBodycache_duration_secondsOptionalintegerenable_authOptionalbooleaninserted_atOptionalstringmax_limitOptionalintegernameRequiredstringproactive_requerying_secondsOptionalintegerqueryRequiredstringsandboxableOptionalbooleansource_mappingOptionalobjectObject schematokenOptionalstringupdated_atOptionalstringResponse codes201404Response (201)exampleschema{\n  \"cache_duration_seconds\": 42,\n  \"enable_auth\": true,\n  \"inserted_at\": \"2021-12-31T23:34:00Z\",\n  \"max_limit\": 42,\n  \"name\": \"lorem\",\n  \"proactive_requerying_seconds\": 42,\n  \"query\": \"lorem\",\n  \"sandboxable\": true,\n  \"source_mapping\": {},\n  \"token\": \"lorem\",\n  \"updated_at\": \"2021-12-31T23:34:00Z\"\n}\nUpdate endpoint\nPath parameterstokenRequiredstringEndpoint Token\nPath parameters\nEndpoint Token\nBodycache_duration_secondsOptionalintegerenable_authOptionalbooleaninserted_atOptionalstringmax_limitOptionalintegernameRequiredstringproactive_requerying_secondsOptionalintegerqueryRequiredstringsandboxableOptionalbooleansource_mappingOptionalobjectObject schematokenOptionalstringupdated_atOptionalstring\nBody\nResponse codes201404\nResponse codes\nResponse (201)\nList sourcesget/api/sourcesResponse codes200Response (200)schema{\n  \"items\": {\n    \"properties\": {\n      \"api_quota\": {\n        \"type\": \"integer\"\n      },\n      \"bigquery_table_ttl\": {\n        \"type\": \"integer\"\n      },\n      \"bq_table_id\": {\n        \"type\": \"string\"\n      },\n      \"bq_table_schema\": {\n        \"type\": \"object\"\n      },\n      \"custom_event_message_keys\": {\n        \"type\": \"string\"\n      },\n      \"favorite\": {\n        \"type\": \"boolean\"\n      },\n      \"has_rejected_events\": {\n        \"type\": \"boolean\"\n      },\n      \"id\": {},\n      \"inserted_at\": {\n        \"format\": \"date-time\",\n        \"type\": \"string\"\n      },\n      \"metrics\": {\n        \"type\": \"object\"\n      },\n      \"name\": {\n        \"type\": \"string\"\n      },\n      \"notifications\": {\n        \"items\": {\n          \"properties\": {\n            \"other_email_notifications\": {\n              \"type\": \"string\"\n            },\n            \"team_user_ids_for_email\": {\n              \"allOf\": {\n                \"type\": \"string\"\n              },\n              \"type\": \"array\"\n            },\n            \"team_user_ids_for_schema_updates\": {\n              \"allOf\": {\n                \"type\": \"string\"\n              },\n              \"type\": \"array\"\n            },\n            \"team_user_ids_for_sms\": {\n              \"allOf\": {\n                \"type\": \"string\"\n              },\n              \"type\": \"array\"\n            },\n            \"user_email_notifications\": {\n              \"type\": \"boolean\"\n            },\n            \"user_schema_update_notifications\": {\n              \"type\": \"boolean\"\n            },\n            \"user_text_notifications\": {\n              \"type\": \"boolean\"\n            }\n          },\n          \"title\": \"Notification\",\n          \"type\": \"object\"\n        },\n        \"type\": \"array\"\n      },\n      \"public_token\": {\n        \"type\": \"string\"\n      },\n      \"slack_hook_url\": {\n        \"type\": \"string\"\n      },\n      \"token\": {\n        \"type\": \"string\"\n      },\n      \"updated_at\": {\n        \"format\": \"date-time\",\n        \"type\": \"string\"\n      },\n      \"webhook_notification_url\": {\n        \"type\": \"string\"\n      }\n    },\n    \"required\": [\n      \"name\"\n    ],\n    \"title\": \"Source\",\n    \"type\": \"object\"\n  },\n  \"type\": \"array\"\n}\nList sources\nResponse codes200\nResponse codes\nResponse (200)\nCreate sourcepost/api/sourcesBodyapi_quotaOptionalintegerbigquery_table_ttlOptionalintegerbq_table_idOptionalstringbq_table_schemaOptionalobjectObject schemacustom_event_message_keysOptionalstringfavoriteOptionalbooleanhas_rejected_eventsOptionalbooleanidOptionalDetailsinserted_atOptionalstringmetricsOptionalobjectObject schemanameRequiredstringnotificationsOptionalArray<object>Itemspublic_tokenOptionalstringslack_hook_urlOptionalstringtokenOptionalstringupdated_atOptionalstringwebhook_notification_urlOptionalstringResponse codes201404Response (201)schema{\n  \"properties\": {\n    \"api_quota\": {\n      \"type\": \"integer\"\n    },\n    \"bigquery_table_ttl\": {\n      \"type\": \"integer\"\n    },\n    \"bq_table_id\": {\n      \"type\": \"string\"\n    },\n    \"bq_table_schema\": {\n      \"type\": \"object\"\n    },\n    \"custom_event_message_keys\": {\n      \"type\": \"string\"\n    },\n    \"favorite\": {\n      \"type\": \"boolean\"\n    },\n    \"has_rejected_events\": {\n      \"type\": \"boolean\"\n    },\n    \"id\": {},\n    \"inserted_at\": {\n      \"format\": \"date-time\",\n      \"type\": \"string\"\n    },\n    \"metrics\": {\n      \"type\": \"object\"\n    },\n    \"name\": {\n      \"type\": \"string\"\n    },\n    \"notifications\": {\n      \"items\": {\n        \"properties\": {\n          \"other_email_notifications\": {\n            \"type\": \"string\"\n          },\n          \"team_user_ids_for_email\": {\n            \"allOf\": {\n              \"type\": \"string\"\n            },\n            \"type\": \"array\"\n          },\n          \"team_user_ids_for_schema_updates\": {\n            \"allOf\": {\n              \"type\": \"string\"\n            },\n            \"type\": \"array\"\n          },\n          \"team_user_ids_for_sms\": {\n            \"allOf\": {\n              \"type\": \"string\"\n            },\n            \"type\": \"array\"\n          },\n          \"user_email_notifications\": {\n            \"type\": \"boolean\"\n          },\n          \"user_schema_update_notifications\": {\n            \"type\": \"boolean\"\n          },\n          \"user_text_notifications\": {\n            \"type\": \"boolean\"\n          }\n        },\n        \"title\": \"Notification\",\n        \"type\": \"object\"\n      },\n      \"type\": \"array\"\n    },\n    \"public_token\": {\n      \"type\": \"string\"\n    },\n    \"slack_hook_url\": {\n      \"type\": \"string\"\n    },\n    \"token\": {\n      \"type\": \"string\"\n    },\n    \"updated_at\": {\n      \"format\": \"date-time\",\n      \"type\": \"string\"\n    },\n    \"webhook_notification_url\": {\n      \"type\": \"string\"\n    }\n  },\n  \"required\": [\n    \"name\"\n  ],\n  \"title\": \"Source\",\n  \"type\": \"object\"\n}\nCreate source\nBodyapi_quotaOptionalintegerbigquery_table_ttlOptionalintegerbq_table_idOptionalstringbq_table_schemaOptionalobjectObject schemacustom_event_message_keysOptionalstringfavoriteOptionalbooleanhas_rejected_eventsOptionalbooleanidOptionalDetailsinserted_atOptionalstringmetricsOptionalobjectObject schemanameRequiredstringnotificationsOptionalArray<object>Itemspublic_tokenOptionalstringslack_hook_urlOptionalstringtokenOptionalstringupdated_atOptionalstringwebhook_notification_urlOptionalstring\nBody\nResponse codes201404\nResponse codes\nResponse (201)\nDelete sourcedelete/api/sources/{token}Path parameterstokenRequiredstringSource TokenResponse codes204404Response (204)schema{}\nDelete source\nPath parameterstokenRequiredstringSource Token\nPath parameters\nSource Token\nResponse codes204404\nResponse codes\nResponse (204)\nFetch sourceget/api/sources/{token}Path parameterstokenRequiredstringSource TokenResponse codes200404Response (200)schema{\n  \"properties\": {\n    \"api_quota\": {\n      \"type\": \"integer\"\n    },\n    \"bigquery_table_ttl\": {\n      \"type\": \"integer\"\n    },\n    \"bq_table_id\": {\n      \"type\": \"string\"\n    },\n    \"bq_table_schema\": {\n      \"type\": \"object\"\n    },\n    \"custom_event_message_keys\": {\n      \"type\": \"string\"\n    },\n    \"favorite\": {\n      \"type\": \"boolean\"\n    },\n    \"has_rejected_events\": {\n      \"type\": \"boolean\"\n    },\n    \"id\": {},\n    \"inserted_at\": {\n      \"format\": \"date-time\",\n      \"type\": \"string\"\n    },\n    \"metrics\": {\n      \"type\": \"object\"\n    },\n    \"name\": {\n      \"type\": \"string\"\n    },\n    \"notifications\": {\n      \"items\": {\n        \"properties\": {\n          \"other_email_notifications\": {\n            \"type\": \"string\"\n          },\n          \"team_user_ids_for_email\": {\n            \"allOf\": {\n              \"type\": \"string\"\n            },\n            \"type\": \"array\"\n          },\n          \"team_user_ids_for_schema_updates\": {\n            \"allOf\": {\n              \"type\": \"string\"\n            },\n            \"type\": \"array\"\n          },\n          \"team_user_ids_for_sms\": {\n            \"allOf\": {\n              \"type\": \"string\"\n            },\n            \"type\": \"array\"\n          },\n          \"user_email_notifications\": {\n            \"type\": \"boolean\"\n          },\n          \"user_schema_update_notifications\": {\n            \"type\": \"boolean\"\n          },\n          \"user_text_notifications\": {\n            \"type\": \"boolean\"\n          }\n        },\n        \"title\": \"Notification\",\n        \"type\": \"object\"\n      },\n      \"type\": \"array\"\n    },\n    \"public_token\": {\n      \"type\": \"string\"\n    },\n    \"slack_hook_url\": {\n      \"type\": \"string\"\n    },\n    \"token\": {\n      \"type\": \"string\"\n    },\n    \"updated_at\": {\n      \"format\": \"date-time\",\n      \"type\": \"string\"\n    },\n    \"webhook_notification_url\": {\n      \"type\": \"string\"\n    }\n  },\n  \"required\": [\n    \"name\"\n  ],\n  \"title\": \"Source\",\n  \"type\": \"object\"\n}\nFetch source\nPath parameterstokenRequiredstringSource Token\nPath parameters\nSource Token\nResponse codes200404\nResponse codes\nResponse (200)\nUpdate sourceput/api/sources/{token}Path parameterstokenRequiredstringSource TokenBodyapi_quotaOptionalintegerbigquery_table_ttlOptionalintegerbq_table_idOptionalstringbq_table_schemaOptionalobjectObject schemacustom_event_message_keysOptionalstringfavoriteOptionalbooleanhas_rejected_eventsOptionalbooleanidOptionalDetailsinserted_atOptionalstringmetricsOptionalobjectObject schemanameRequiredstringnotificationsOptionalArray<object>Itemspublic_tokenOptionalstringslack_hook_urlOptionalstringtokenOptionalstringupdated_atOptionalstringwebhook_notification_urlOptionalstringResponse codes201404Response (201)schema{\n  \"properties\": {\n    \"api_quota\": {\n      \"type\": \"integer\"\n    },\n    \"bigquery_table_ttl\": {\n      \"type\": \"integer\"\n    },\n    \"bq_table_id\": {\n      \"type\": \"string\"\n    },\n    \"bq_table_schema\": {\n      \"type\": \"object\"\n    },\n    \"custom_event_message_keys\": {\n      \"type\": \"string\"\n    },\n    \"favorite\": {\n      \"type\": \"boolean\"\n    },\n    \"has_rejected_events\": {\n      \"type\": \"boolean\"\n    },\n    \"id\": {},\n    \"inserted_at\": {\n      \"format\": \"date-time\",\n      \"type\": \"string\"\n    },\n    \"metrics\": {\n      \"type\": \"object\"\n    },\n    \"name\": {\n      \"type\": \"string\"\n    },\n    \"notifications\": {\n      \"items\": {\n        \"properties\": {\n          \"other_email_notifications\": {\n            \"type\": \"string\"\n          },\n          \"team_user_ids_for_email\": {\n            \"allOf\": {\n              \"type\": \"string\"\n            },\n            \"type\": \"array\"\n          },\n          \"team_user_ids_for_schema_updates\": {\n            \"allOf\": {\n              \"type\": \"string\"\n            },\n            \"type\": \"array\"\n          },\n          \"team_user_ids_for_sms\": {\n            \"allOf\": {\n              \"type\": \"string\"\n            },\n            \"type\": \"array\"\n          },\n          \"user_email_notifications\": {\n            \"type\": \"boolean\"\n          },\n          \"user_schema_update_notifications\": {\n            \"type\": \"boolean\"\n          },\n          \"user_text_notifications\": {\n            \"type\": \"boolean\"\n          }\n        },\n        \"title\": \"Notification\",\n        \"type\": \"object\"\n      },\n      \"type\": \"array\"\n    },\n    \"public_token\": {\n      \"type\": \"string\"\n    },\n    \"slack_hook_url\": {\n      \"type\": \"string\"\n    },\n    \"token\": {\n      \"type\": \"string\"\n    },\n    \"updated_at\": {\n      \"format\": \"date-time\",\n      \"type\": \"string\"\n    },\n    \"webhook_notification_url\": {\n      \"type\": \"string\"\n    }\n  },\n  \"required\": [\n    \"name\"\n  ],\n  \"title\": \"Source\",\n  \"type\": \"object\"\n}\nUpdate source\nPath parameterstokenRequiredstringSource Token\nPath parameters\nSource Token\nBodyapi_quotaOptionalintegerbigquery_table_ttlOptionalintegerbq_table_idOptionalstringbq_table_schemaOptionalobjectObject schemacustom_event_message_keysOptionalstringfavoriteOptionalbooleanhas_rejected_eventsOptionalbooleanidOptionalDetailsinserted_atOptionalstringmetricsOptionalobjectObject schemanameRequiredstringnotificationsOptionalArray<object>Itemspublic_tokenOptionalstringslack_hook_urlOptionalstringtokenOptionalstringupdated_atOptionalstringwebhook_notification_urlOptionalstring\nBody\nResponse codes201404\nResponse codes\nResponse (201)\nList teamsget/api/teamsResponse codes200Response (200)exampleschema[\n  {\n    \"name\": \"lorem\",\n    \"team_users\": [\n      {\n        \"email\": \"lorem\",\n        \"name\": \"lorem\"\n      }\n    ],\n    \"token\": \"lorem\",\n    \"user\": {\n      \"api_key\": \"lorem\",\n      \"api_quota\": 42,\n      \"bigquery_dataset_id\": \"lorem\",\n      \"bigquery_dataset_location\": \"lorem\",\n      \"bigquery_project_id\": \"lorem\",\n      \"company\": \"lorem\",\n      \"email\": \"lorem\",\n      \"email_me_product\": true,\n      \"email_preferred\": \"lorem\",\n      \"image\": \"lorem\",\n      \"name\": \"lorem\",\n      \"phone\": \"lorem\",\n      \"provider\": \"lorem\",\n      \"token\": \"lorem\"\n    }\n  }\n]\nList teams\nResponse codes200\nResponse codes\nResponse (200)\nCreate Teampost/api/teamsBodynameRequiredstringteam_usersOptionalArray<object>ItemstokenOptionalstringuserOptionalobjectObject schemaResponse codes201404Response (201)exampleschema{\n  \"name\": \"lorem\",\n  \"team_users\": [\n    {\n      \"email\": \"lorem\",\n      \"name\": \"lorem\"\n    }\n  ],\n  \"token\": \"lorem\",\n  \"user\": {\n    \"api_key\": \"lorem\",\n    \"api_quota\": 42,\n    \"bigquery_dataset_id\": \"lorem\",\n    \"bigquery_dataset_location\": \"lorem\",\n    \"bigquery_project_id\": \"lorem\",\n    \"company\": \"lorem\",\n    \"email\": \"lorem\",\n    \"email_me_product\": true,\n    \"email_preferred\": \"lorem\",\n    \"image\": \"lorem\",\n    \"name\": \"lorem\",\n    \"phone\": \"lorem\",\n    \"provider\": \"lorem\",\n    \"token\": \"lorem\"\n  }\n}\nCreate Team\nBodynameRequiredstringteam_usersOptionalArray<object>ItemstokenOptionalstringuserOptionalobjectObject schema\nBody\nResponse codes201404\nResponse codes\nResponse (201)\nDelete Teamdelete/api/teams/{token}Path parameterstokenRequiredstringTeam TokenResponse codes204404Response (204)schema{}\nDelete Team\nPath parameterstokenRequiredstringTeam Token\nPath parameters\nTeam Token\nResponse codes204404\nResponse codes\nResponse (204)\nFetch teamget/api/teams/{token}Path parameterstokenRequiredstringTeam TokenResponse codes200404Response (200)exampleschema{\n  \"name\": \"lorem\",\n  \"team_users\": [\n    {\n      \"email\": \"lorem\",\n      \"name\": \"lorem\"\n    }\n  ],\n  \"token\": \"lorem\",\n  \"user\": {\n    \"api_key\": \"lorem\",\n    \"api_quota\": 42,\n    \"bigquery_dataset_id\": \"lorem\",\n    \"bigquery_dataset_location\": \"lorem\",\n    \"bigquery_project_id\": \"lorem\",\n    \"company\": \"lorem\",\n    \"email\": \"lorem\",\n    \"email_me_product\": true,\n    \"email_preferred\": \"lorem\",\n    \"image\": \"lorem\",\n    \"name\": \"lorem\",\n    \"phone\": \"lorem\",\n    \"provider\": \"lorem\",\n    \"token\": \"lorem\"\n  }\n}\nFetch team\nPath parameterstokenRequiredstringTeam Token\nPath parameters\nTeam Token\nResponse codes200404\nResponse codes\nResponse (200)\nUpdate teamput/api/teams/{token}Path parameterstokenRequiredstringTeam TokenBodynameRequiredstringteam_usersOptionalArray<object>ItemstokenOptionalstringuserOptionalobjectObject schemaResponse codes201404Response (201)exampleschema{\n  \"name\": \"lorem\",\n  \"team_users\": [\n    {\n      \"email\": \"lorem\",\n      \"name\": \"lorem\"\n    }\n  ],\n  \"token\": \"lorem\",\n  \"user\": {\n    \"api_key\": \"lorem\",\n    \"api_quota\": 42,\n    \"bigquery_dataset_id\": \"lorem\",\n    \"bigquery_dataset_location\": \"lorem\",\n    \"bigquery_project_id\": \"lorem\",\n    \"company\": \"lorem\",\n    \"email\": \"lorem\",\n    \"email_me_product\": true,\n    \"email_preferred\": \"lorem\",\n    \"image\": \"lorem\",\n    \"name\": \"lorem\",\n    \"phone\": \"lorem\",\n    \"provider\": \"lorem\",\n    \"token\": \"lorem\"\n  }\n}\nUpdate team\nPath parameterstokenRequiredstringTeam Token\nPath parameters\nTeam Token\nBodynameRequiredstringteam_usersOptionalArray<object>ItemstokenOptionalstringuserOptionalobjectObject schema\nBody\nResponse codes201404\nResponse codes\nResponse (201)\nNeed some help?\nLatest product updates?\nSomething's not right?"
  },
  {
    "id": "47",
    "url": "https://supabase.com/support",
    "title": "Help & Support | Supabase",
    "content": "Enterprise\nPricing\nDocs\nBlog\nSupport\nHello, how can we help?\n\nIssues\nFound a bug? We'd love to hear about it in our GitHub issues.\nFeature requests\nWant to suggest a new feature? Share it with us and the community.\nAsk the Community\nJoin our GitHub discussions or our Discord server to browse for help and best practices.\nCan't find what you're looking for?\nThe Supabase Support Team is ready to help.\nResponse time for support tickets will vary depending on plan type and severity of the issue.\nFooter\nProduct\nResources\nDevelopers\nCompany\n"
  },
  {
    "id": "48",
    "url": "https://supabase.com/changelog",
    "title": "Changelog",
    "content": "We use first-party cookies to improve our services. Learn more Learn moreâ€¢Privacy settings Accept  Opt out Privacy settings\nWe use first-party cookies to improve our services. Learn more\nEnterprise\nPricing\nDocs\nBlog\nChangelog\nNew updates and product improvements\nDashboard Updates [04/11/24 - 18/11/24]\nNov 18, 2024\nTable Editor Performance Improvements#\nWe've set aside some time to look into improving the performance of the Table Editor over the past few weeks, in particular shortening both perceived and actual loading times as you navigate around the Table Editor. This all comes together in several PRs as we explored from 2 angles:\n\nOptimizing the queries that are firing behind the scenes by removing redundant sections + minimise waterfall requests\nIntroducing prefetching behaviours as your mouse cursor goes through the list of tables to have the tables' contents ready by the time you open it in the UI\n\nPerformance improvements have always been a consistent topic with the team, and we don't intend to stop here! Hopefully these changes will make it smoother and faster for you to build your project with the dashboard and as always let us know any feedback! ðŸ™‚ðŸ™ Just a button away in the top right corner of the dashboard to get your thoughts heard ðŸ˜„\nPRs:\n\nQuery optimizations Part 1: https://github.com/supabase/supabase/pull/30184\nQuery optimizations Part 2: https://github.com/supabase/supabase/pull/30295\nPrefetching on the table editor: https://github.com/supabase/supabase/pull/29987\nPrefetching on the home page: https://github.com/supabase/supabase/pull/30317\n\nLink: https://supabase.com/dashboard/project/_/editor\nOther bug fixes and improvements#\nTable Editor\n\nSimplified header when rows are selected (PR)\nAllow exporting of data on tables that are protected (PR)\n\nAuthentication\n\nFixed provider \"Enabled\" state when viewing user details if user's provider is LinkedIn (PR)\nSorting users on a column will shift users with NULL values on that column to the bottom (PR)\nFix \"Last signed in at\" column showing up as \"Waiting for verification\" on subsequent pages as page is scrolled down (PR)\n\nStorage\n\nAdd ability to toggle image transformations from settings (PR)\nTable Editor Performance Improvements#\nWe've set aside some time to look into improving the performance of the Table Editor over the past few weeks, in particular shortening both perceived and actual loading times as you navigate around the Table Editor. This all comes together in several PRs as we explored from 2 angles:\nPerformance improvements have always been a consistent topic with the team, and we don't intend to stop here! Hopefully these changes will make it smoother and faster for you to build your project with the dashboard and as always let us know any feedback! ðŸ™‚ðŸ™ Just a button away in the top right corner of the dashboard to get your thoughts heard ðŸ˜„\nPRs:\nLink: https://supabase.com/dashboard/project/_/editor\nOther bug fixes and improvements#\nTable Editor\nAuthentication\nStorage\n`supabase-js` release candidate `2.46.2-rc.3` incoming types inferences for PostgREST fixes and feedbacks\nNov 6, 2024\nðŸš€ Announcement: Weâ€™ve just released supabase-js version 2.46.2-rc.3, which resolves several type errors in the PostgREST client.\nNotable issues resolved:#\n\nhttps://github.com/supabase/postgrest-js/issues/523\nhttps://github.com/supabase/supabase-js/issues/943\nhttps://github.com/supabase/postgrest-js/issues/450\nhttps://github.com/supabase/postgrest-js/issues/546\n\nWeâ€™d love your feedback to ensure everything runs smoothly!\n\nImportant Notes:#\nThis update might require regenerating your database types. You can do this via the Supabase CLI (â‰¥v1.207.8) or the dashboard. For instructions, check out our guide here.\n\nPotential Issues#\nThis version introduces stricter alignment between runtime behavior and type inference. As a result, some types might appear \"broken\" but are actually being corrected.\nThe main changes to be aware of:\n\nThe result of an embedding now correctly infers a single object or an array based on the relationship.\nThe result of an object embedding now more accurately identifies whether the result can be null.\n\nBefore reporting a bug, please double-check that the inferred types are truly incorrect based on your query and database schema.\n\nBug Reporting:#\nIf your project is hosted on Supabase, please open a support ticket here and check \"Allow Supabase Support to access your project temporarily.\" This will enable us to investigate your database types directly.\nAlternatively, you can open an issue on GitHub. Please include:\n\nThe generated Database type used to instantiate the client (e.g., createClient<Database>(process.env.SUPABASE_URL, process.env.SUPABASE_ANON_KEY)).  If possible a minimal SQL declaration resulting in such Database type.\nThe query where type inference failed (e.g., .from('which-table').select('which-query')).\nYour TypeScript version (npx tsc -v).\nðŸš€ Announcement: Weâ€™ve just released supabase-js version 2.46.2-rc.3, which resolves several type errors in the PostgREST client.\nNotable issues resolved:#\nWeâ€™d love your feedback to ensure everything runs smoothly!\nImportant Notes:#\nThis update might require regenerating your database types. You can do this via the Supabase CLI (â‰¥v1.207.8) or the dashboard. For instructions, check out our guide here.\nPotential Issues#\nThis version introduces stricter alignment between runtime behavior and type inference. As a result, some types might appear \"broken\" but are actually being corrected.\nThe main changes to be aware of:\nBefore reporting a bug, please double-check that the inferred types are truly incorrect based on your query and database schema.\nBug Reporting:#\nIf your project is hosted on Supabase, please open a support ticket here and check \"Allow Supabase Support to access your project temporarily.\" This will enable us to investigate your database types directly.\nAlternatively, you can open an issue on GitHub. Please include:\nWrite Edge Functions in pure JavaScript instead of using TypeScript\nNov 6, 2024\n[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nFrom Supabase CLI version 1.215.0 or higher you can configure a custom entrypoint to your Edge Functions. This can be used to write Edge Functions in pure JavaScript instead of TypeScript.\nSave your Function as a JavaScript file (eg: index.js) and then update the supabase/config.toml as follows:\n1[functions.hello-world]2# other entries3entrypoint = './functions/hello-world/index.js' # path must be relative to config.toml\nYou can use any .ts, .js, .tsx, .jsx or .mjs file as the entrypoint for a Function.\nMore details: https://supabase.com/docs/guides/functions/quickstart#not-using-typescript\nFrom Supabase CLI version 1.215.0 or higher you can configure a custom entrypoint to your Edge Functions. This can be used to write Edge Functions in pure JavaScript instead of TypeScript.\nSave your Function as a JavaScript file (eg: index.js) and then update the supabase/config.toml as follows:\nYou can use any .ts, .js, .tsx, .jsx or .mjs file as the entrypoint for a Function.\nMore details: https://supabase.com/docs/guides/functions/quickstart#not-using-typescript\nUse `deno.json` configuration file in Edge Functions\nNov 5, 2024\n[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nEach Edge Function can now have its own deno.json or deno.jsonc file to manage dependencies. You will need to deploy your functions using Supabase CLI version v1.215.0 or above to make use of this feature.\nHow to use deno.json#\nCreate a deno.json in your function's folder:\n1// supabase/functions/function-name/deno.json2{3  \"imports\": {4    \"lodash\": \"https://cdn.skypack.dev/lodash\"5  }6}\nYou can now use aliased imports in your source code:\n1// supabase/functions/function-name/index.ts2import lodash from 'lodash'\nTo test your function locally, run supabase functions serve. When you're ready, you can deploy it to hosted platform by running supabase functions deploy function-name\nFor more details, check the guide: https://supabase.com/docs/guides/functions/import-maps#using-denojson-recommended\nEach Edge Function can now have its own deno.json or deno.jsonc file to manage dependencies. You will need to deploy your functions using Supabase CLI version v1.215.0 or above to make use of this feature.\nHow to use deno.json#\nCreate a deno.json in your function's folder:\nYou can now use aliased imports in your source code:\nTo test your function locally, run supabase functions serve. When you're ready, you can deploy it to hosted platform by running supabase functions deploy function-name\nFor more details, check the guide: https://supabase.com/docs/guides/functions/import-maps#using-denojson-recommended\nDashboard Updates [21/10/24 - 04/11/24]\nNov 4, 2024\nSpam validation check now added to Auth templates#\n\nWe've now added a spam validation checker for your email templates in the Auth section of the dashboard! This is powered by SpamAssassin and is in hopes to assist you with writing email content in a way to avoid being marked as spam by email clients.\nIf your project is using the built-in SMTP service, this validation will prevent you from saving the templates until you address all the issues found. However, if your project is on its own custom SMTP service, this validation will then purely serve as a warning while still letting you save your templates.\nPR: https://github.com/supabase/supabase/pull/30188\nLinks: https://supabase.com/dashboard/project/_/auth/templates\nOther improvements and bug fixes#\nAuthentication\n\nHovering over auth logs for a user will show relative time info (PR)\nAllow sorting on last signed in at for users (PR)\nAllow selection of functions that return void for auth hooks (PR)\nAllow updating of SMS rate limit irregardless of SMS autoconfirm being enabled (PR)\n\nStorage\n\nFix developer roles not being able to update buckets (PR)\n\nDatabase\n\nFix create index \"Select a table\" combobox not using search input (PR)\nSupport opening tables in table editor from the schema visualizer (PR)\n\nLogs & Analytics\n\nFix filters for log reports (PR)\nSpam validation check now added to Auth templates#\n\nWe've now added a spam validation checker for your email templates in the Auth section of the dashboard! This is powered by SpamAssassin and is in hopes to assist you with writing email content in a way to avoid being marked as spam by email clients.\nIf your project is using the built-in SMTP service, this validation will prevent you from saving the templates until you address all the issues found. However, if your project is on its own custom SMTP service, this validation will then purely serve as a warning while still letting you save your templates.\nPR: https://github.com/supabase/supabase/pull/30188\nLinks: https://supabase.com/dashboard/project/_/auth/templates\nOther improvements and bug fixes#\nAuthentication\nStorage\nDatabase\nLogs & Analytics\nImport NPM packages from private registries in Edge Functions\nOct 30, 2024\n[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nEdge Functions now support importing NPM packages from private registries. You will need to deploy your functions using Supabase CLI version v1.207.9 or above to make use of this feature.\nHow to use packages from private registries#\nCreate a .npmrc file within supabase/functions. This will allow you to import the private packages into multiple functions. Alternatively, you can place the .npmrc file directly inside supabase/functions/function-name directory.\nAdd your registry details in the .npmrc file. Follow this guide to learn more about the syntax of npmrc files.\n1@myorg:registry=https://npm.registryhost.com2//npm.registryhost.com/:_authToken=VALID_AUTH_TOKEN\nAfter that, you can import the package directly in your function code or add it to the import_map.json (https://supabase.com/docs/guides/functions/import-maps#using-import-maps).\n1import MyPackage from \"npm:@myorg/private-package@v1.0.1\"23// use MyPackage\nTo test your function locally, run supabase functions serve. When you're ready, you can deploy it to hosted platform by running supabase functions deploy function-name\nEdge Functions now support importing NPM packages from private registries. You will need to deploy your functions using Supabase CLI version v1.207.9 or above to make use of this feature.\nHow to use packages from private registries#\nCreate a .npmrc file within supabase/functions. This will allow you to import the private packages into multiple functions. Alternatively, you can place the .npmrc file directly inside supabase/functions/function-name directory.\nAdd your registry details in the .npmrc file. Follow this guide to learn more about the syntax of npmrc files.\nAfter that, you can import the package directly in your function code or add it to the import_map.json (https://supabase.com/docs/guides/functions/import-maps#using-import-maps).\nTo test your function locally, run supabase functions serve. When you're ready, you can deploy it to hosted platform by running supabase functions deploy function-name\nDashboard Updates [07/10/24 - 21/10/24]\nOct 21, 2024\nDisk size usage section under organization settings#\n\nWe've added a new disk size section for paid plans to give a quick overview of each project under the organization and their respective disk sizes for better visibility over the corresponding charges. This is only an initial iteration for this UI, we do plan to add historical statistics and more to improve visibility and transparency over what you're using and what you're paying for ðŸ™‚\nPR: https://github.com/supabase/supabase/pull/29862\nLink: https://supabase.com/dashboard/org/_/usage\nBug fixes and other improvements#\nTable Editor\n\nFix views filtering in table editor for local dashboard (PR)\nFix exporting a table that contains columns of enum array types to CSV (PR)\n\nSQL Editor\n\nFix snippets not loading for local dashboard (PR)\n\nAuthentication\n\nSupport searching by properties when viewing a user's raw JSON (PR)\nDisk size usage section under organization settings#\nWe've added a new disk size section for paid plans to give a quick overview of each project under the organization and their respective disk sizes for better visibility over the corresponding charges. This is only an initial iteration for this UI, we do plan to add historical statistics and more to improve visibility and transparency over what you're using and what you're paying for ðŸ™‚\nPR: https://github.com/supabase/supabase/pull/29862\nLink: https://supabase.com/dashboard/org/_/usage\nBug fixes and other improvements#\nTable Editor\nSQL Editor\nAuthentication\nImproved docs information architecture\nOct 9, 2024\nWe improved the information architecture (IA) on our docs site.\nWhy?#\nWeâ€™d outgrown the IA! As we added more features and guides, some sections grew to contain a miscellaneous collection of things that donâ€™t belong together. They just had no better place to go.\nWith the new IA, it should be easier to find what youâ€™re looking for.\nSummary of changes#\n\nTwo top-level menus, Build and Manage, to replace the old Build menu\nBuild menu:\n\nLocal development / CLI is now primarily about local dev, CI/CD information has been moved to Deployment\nInformation on both Vercel and Supabase integrations now moved to Integrations section\nNew Deployment section covers everything needed to get your changes onto hosted Supabase (including branching, Terraform, CI/CD, and production checklists)\n\n\nManage menu:\n\nPlatform management (formerly â€œPlatformâ€) trimmed down to contain information about configuring your Supabase platform (including account management, project permissions, and billing)\nNew Monitoring and troubleshooting section contains troubleshooting guides and information on logging and telemetry\nWe improved the information architecture (IA) on our docs site.\nWhy?#\nWeâ€™d outgrown the IA! As we added more features and guides, some sections grew to contain a miscellaneous collection of things that donâ€™t belong together. They just had no better place to go.\nWith the new IA, it should be easier to find what youâ€™re looking for.\nSummary of changes#\nDashboard Updates [23/09/24 - 07/10/24]\nOct 7, 2024\nImproved users management UI#\n\nOne of our oldest pages on the dashboard has finally gotten an upgrade! ðŸ˜„ We're taking the first steps towards a pattern of visualizing table data with a data grid, with the Auth users page being our first contender. Couple of stuff that we'd love to highlight that were improved and introduced:\nClick on users to grab more details about them in a side panel (PR)#\n\nAdded a ban functionality within the danger zone at the bottom of the panel#\n\nSearch now also supports filtering for providers (PR)#\n\nColumns can be sorted based on your preference (and will be persisted in local storage)#\nhttps://github.com/user-attachments/assets/3f7890ca-04cf-4cb9-8046-63b3db9b6eb9\nYou can also now toggle column visibility, as well as apply sorts on columns#\n\nView authentication logs of the user right from the panel (PR)#\n\nThese tooling should now allow you to customize the auth users view that best fits your workflow, and we definitely hope to keep making this better so as always, feel free to drop us any feedback good or bad, any bugs via the widget at the top right corner of the dashboard ðŸ™‚ We say this all the time and its a promise that we've kept - we look at every feedback that comes in ðŸ¤™\nPR: https://github.com/supabase/supabase/pull/29105\nLink: https://supabase.com/dashboard/project/_/auth/users\nTimestamp helper for Logs Collections#\nhttps://github.com/user-attachments/assets/80541e0a-4571-4193-ab9e-8d9af4b63d55\nHovering over the date/time string in the left most column of a row in any logs collection will now show a helper tooltip that will depict the time in 4 different formats: UTC, Local TZ, Relative time, and raw numerical timestamp. This will hopefully help with interpreting timestamps much easier and faster and alleviate any confusion around timezones! ðŸ™‚ðŸ•°ï¸ We're also planning to use this pattern across the whole dashboard too wherever time data is involved ðŸ’ªðŸ»\nPR: https://github.com/supabase/supabase/pull/29530\nLink: https://supabase.com/dashboard/project/_/logs/edge-logs\nOther bug fixes and improvements#\nGeneral\n\nAdded breakdown of security issues dropdown on project home page (PR)\n\nOrganization Settings\n\nFixed tooltip not showing up for users with project scoped roles, to show which projects they have roles for (PR)\n\nTable Editor\n\nAutofocus on search input when navigating to table editor (PR)\nImproved column type dropdown with searching for types (PR)\nImproved datetime editing in table editor grid + support for setting these column values to NULL (PR)\n\nEdge Functions\n\nAdded validations for adding/removing secrets on SUPABASE_ prefixed secrets (PR)\n\nReports\n\nAdded database connections charts to database reports (PR)\nImproved users management UI#\n\nOne of our oldest pages on the dashboard has finally gotten an upgrade! ðŸ˜„ We're taking the first steps towards a pattern of visualizing table data with a data grid, with the Auth users page being our first contender. Couple of stuff that we'd love to highlight that were improved and introduced:\nClick on users to grab more details about them in a side panel (PR)#\n\nAdded a ban functionality within the danger zone at the bottom of the panel#\n\nSearch now also supports filtering for providers (PR)#\n\nColumns can be sorted based on your preference (and will be persisted in local storage)#\nhttps://github.com/user-attachments/assets/3f7890ca-04cf-4cb9-8046-63b3db9b6eb9\nYou can also now toggle column visibility, as well as apply sorts on columns#\n\nView authentication logs of the user right from the panel (PR)#\n\nThese tooling should now allow you to customize the auth users view that best fits your workflow, and we definitely hope to keep making this better so as always, feel free to drop us any feedback good or bad, any bugs via the widget at the top right corner of the dashboard ðŸ™‚ We say this all the time and its a promise that we've kept - we look at every feedback that comes in ðŸ¤™\nPR: https://github.com/supabase/supabase/pull/29105\nLink: https://supabase.com/dashboard/project/_/auth/users\nTimestamp helper for Logs Collections#\nhttps://github.com/user-attachments/assets/80541e0a-4571-4193-ab9e-8d9af4b63d55\nHovering over the date/time string in the left most column of a row in any logs collection will now show a helper tooltip that will depict the time in 4 different formats: UTC, Local TZ, Relative time, and raw numerical timestamp. This will hopefully help with interpreting timestamps much easier and faster and alleviate any confusion around timezones! ðŸ™‚ðŸ•°ï¸ We're also planning to use this pattern across the whole dashboard too wherever time data is involved ðŸ’ªðŸ»\nPR: https://github.com/supabase/supabase/pull/29530\nLink: https://supabase.com/dashboard/project/_/logs/edge-logs\nOther bug fixes and improvements#\nGeneral\nOrganization Settings\nTable Editor\nEdge Functions\nReports\nXHTML responses are only allowed with a Custom Domain enabled\nOct 2, 2024\nSummary#\nReturning XHTML responses from the Data APIs and Edge Functions is now only allowed if a Custom Domain is being used.\nAdditionally, you can now serve HTML and XHTML responses from the Storage service as well, if a Custom Domain is being used.\nIf your use-case requires serving these content types, you can continue to do so by using a Custom Domain add-on.\nAffected projects have been notified in advance.\nBackground#\nHTML responses (i.e. content-types that can be directly rendered by browsers) were historically disallowed for projects not using a custom domain, in order to prevent abuse on the shared domains used for provisioning Supabase projects. This change updates this behavior to process XHTML responses in the same manner, due to the same rationale.\nSummary#\nReturning XHTML responses from the Data APIs and Edge Functions is now only allowed if a Custom Domain is being used.\nAdditionally, you can now serve HTML and XHTML responses from the Storage service as well, if a Custom Domain is being used.\nIf your use-case requires serving these content types, you can continue to do so by using a Custom Domain add-on.\nAffected projects have been notified in advance.\nBackground#\nHTML responses (i.e. content-types that can be directly rendered by browsers) were historically disallowed for projects not using a custom domain, in order to prevent abuse on the shared domains used for provisioning Supabase projects. This change updates this behavior to process XHTML responses in the same manner, due to the same rationale.\nSupabase Platform Access Control: Project Permissions Breaking Changes on October 15, 2024\nSep 25, 2024\nThese breaking changes are rolling out on October 15, 2024 and affects only organizations on the Enterprise plan that have implemented project permissions with members assigned the Developer role.\nSupabase launched new granular access control for Enterprise organizations so that its members are given access to specific projects instead of the entire organization. You can check out our Launch Week 12 announcement to learn more.\nWe recently re-evaluated the access that the Developer role has and decided to implement changes to restrict them on a couple of resources to improve your project's security.\nOn October 15, 2024, we will turn off certain access that the Developer role currently has to your project's resources. The following table is to illustrate all of the breaking changes that will be going into effect:\nResourceActionDeveloperRead-OnlyAPI ConfigurationJWT SecretGenerate newâœ…Â â†’ âŒâŒ1API SettingsUpdateâœ…Â â†’ âŒâŒ1Auth ConfigurationAuth SettingsUpdateâœ…Â â†’ âŒâŒ1Advanced SettingsUpdateâœ…Â â†’ âŒâŒ1Storage ConfigurationUpload LimitUpdateâœ…Â â†’ âŒâŒ1S3 access keysCreateâœ…Â â†’ âŒâŒ1Deleteâœ…Â â†’ âŒâŒ1Edge Functions ConfigurationSecretsCreateâœ…Â â†’ âŒâŒ1Deleteâœ…Â â†’ âŒâŒ1AuthenticationProvidersUpdateâœ…Â â†’ âŒâŒ1Rate LimitsUpdateâœ…Â â†’ âŒâŒ1Email TemplatesUpdateâœ…Â â†’ âŒâŒ1URL ConfigurationUpdateâœ…Â â†’ âŒâŒ1Logs & AnalyticsEvents CollectionsCreateâœ…Â â†’ âŒâŒ1Updateâœ…Â â†’ âŒâŒ1Deleteâœ…Â â†’ âŒâŒ1Warehouse Access TokensCreateâœ…Â â†’ âŒâŒ1Revokeâœ…Â â†’ âŒâŒ1\nYou can learn more about our Platform Access Control here: https://supabase.com/docs/guides/platform/access-control.\nIf you have any questions or concerns please contact support.\nFootnotes#\n\n\nRole's permission to the resource and action will remain the same. â†© â†©2 â†©3 â†©4 â†©5 â†©6 â†©7 â†©8 â†©9 â†©10 â†©11 â†©12 â†©13 â†©14 â†©15 â†©16 â†©17 â†©18\nThese breaking changes are rolling out on October 15, 2024 and affects only organizations on the Enterprise plan that have implemented project permissions with members assigned the Developer role.\nSupabase launched new granular access control for Enterprise organizations so that its members are given access to specific projects instead of the entire organization. You can check out our Launch Week 12 announcement to learn more.\nWe recently re-evaluated the access that the Developer role has and decided to implement changes to restrict them on a couple of resources to improve your project's security.\nOn October 15, 2024, we will turn off certain access that the Developer role currently has to your project's resources. The following table is to illustrate all of the breaking changes that will be going into effect:\nYou can learn more about our Platform Access Control here: https://supabase.com/docs/guides/platform/access-control.\nIf you have any questions or concerns please contact support.\nFootnotes#\n\n\nRole's permission to the resource and action will remain the same. â†© â†©2 â†©3 â†©4 â†©5 â†©6 â†©7 â†©8 â†©9 â†©10 â†©11 â†©12 â†©13 â†©14 â†©15 â†©16 â†©17 â†©18\nFootnotes#\nRole's permission to the resource and action will remain the same. â†© â†©2 â†©3 â†©4 â†©5 â†©6 â†©7 â†©8 â†©9 â†©10 â†©11 â†©12 â†©13 â†©14 â†©15 â†©16 â†©17 â†©18\nDashboard Weekly Updates [16/09/24 - 23/09/24]\nSep 23, 2024\nDeployment of up to 5 read replicas now supported on larger compute sizes#\nPreviously, each project could only deploy up to 2 read replicas, but we're now raising this limit to 5 for projects on larger compute sizes (XL and above).\nPR: https://github.com/supabase/supabase/pull/29250\nLink: https://supabase.com/dashboard/project/_/settings/infrastructure\nCatch queries that contains an update query without a where clause in SQL Editor#\n\nAnother effort to safeguard against running queries with unintended side effects - this time, we're checking for UPDATE queries without a WHERE clause - this check kicks in prior to running the query. We've also consolidated this warning with our existing warning against destructive operations to catch both cases if they exist in the same query.\nPR: https://github.com/supabase/supabase/pull/28458\nLink: https://supabase.com/dashboard/project/_/sql\nOther bug fixes and improvements#\nGeneral\n\nSupport querying a table via CMDK by opening the SQL editor (PR)\nUpdate Supabase Assistant with GPT 4o from 3.5 (PR)\n\nTable Editor\n\nImprove pagination input field, by only navigating to page on Enter (PR)\n\nSQL Editor\n\nFix inability to share queries that are under favorites (PR)\nFix moving snippets into folders (PR)\n\nStorage Explorer\n\nFix to prevent continuously retrying when a file of an invalid mime type is uploaded (PR)\n\nAuth\n\nSupport searching by UID (PR)\nAdd confirmation modal when closing tab with unsaved changes on templates page (PR)\nSupport adding/removing multiple redirect URLs (PR)\n\nDatabase\n\nFix index page crashing when creating an index on a table with no columns (PR)\n\nLogs Explorer\n\nLayout shift and scroll fixes (PR)\nPrevent use of WITH, ILIKE or wildcards (PR)\nDeployment of up to 5 read replicas now supported on larger compute sizes#\nPreviously, each project could only deploy up to 2 read replicas, but we're now raising this limit to 5 for projects on larger compute sizes (XL and above).\nPR: https://github.com/supabase/supabase/pull/29250\nLink: https://supabase.com/dashboard/project/_/settings/infrastructure\nCatch queries that contains an update query without a where clause in SQL Editor#\n\nAnother effort to safeguard against running queries with unintended side effects - this time, we're checking for UPDATE queries without a WHERE clause - this check kicks in prior to running the query. We've also consolidated this warning with our existing warning against destructive operations to catch both cases if they exist in the same query.\nPR: https://github.com/supabase/supabase/pull/28458\nLink: https://supabase.com/dashboard/project/_/sql\nOther bug fixes and improvements#\nGeneral\nTable Editor\nSQL Editor\nStorage Explorer\nAuth\nDatabase\nLogs Explorer\nProjects on XL and larger compute add-ons can now create up to 5 Read Replicas.\nSep 22, 2024\nThe initial launch of Read Replicas allowed for up to two Read Replicas per project.\nThe limit for projects on XL compute add-ons and larger has now been raised to 5 Read Replicas per project.\nProjects on compute add-ons smaller than XL are still allowed up to 2 Read Replicas per project.\nThe initial launch of Read Replicas allowed for up to two Read Replicas per project.\nThe limit for projects on XL compute add-ons and larger has now been raised to 5 Read Replicas per project.\nProjects on compute add-ons smaller than XL are still allowed up to 2 Read Replicas per project.\nSupabase Auth: Changes to default email provider\nSep 19, 2024\nAs our user base has grown, we are taking steps to make sure we are able to continue to provide a safe, secure, robust free plan experience. To ensure that email-based auth continues to work for all users on Supabase, we're making changes if you're using the default email provider. This allows us to continue to offer our default provider in a more sustainable and resilient manner.\nFor maximum flexibility and control over your auth emails, we suggest one of the following:\n\nUse a custom SMTP provider instead\nSend emails through your own email provider using the email send hook\n\nIf you still want to use the default email provider, these are the changes being planned:\n\n\nEmail template customization will be allowed and customized email templates will not be reverted to default.\n\n\n26th September: If you do not have a custom SMTP server set up, emails can only be sent to email addresses in your project's organization. So for example, if your organization has the following members: person-a@example.com, person-b@example.com and person-c@example.com , this means that email messages from Auth will only be sent to these addresses.\n\n\nThese measures are taken to prevent abuse to our shared SMTP service. In the future, we may consider increasing the email rate limits once we see a drop in abuse.\nFrequently asked questions#\nWhy such a short notice?#\nSupabase uses a third-party email sending provider that has mandated we reduce email abuse significantly or they will be forced to block all email sending. A tragedy of the commons.\nCan't Supabase switch to a different email sending partner?#\nYes, but we would run into the same issues. All email sending services are required to monitor abuse and force their customers to follow the same rules.\nCan't Supabase send emails on their own, without a third party?#\nNot really. You can't just send email on the web today without investing a lot of money and time (unblocking port 25, keeping IP addresses out of spam lists, etc.). This is not our core competency and do not have plans to start doing this today.\nHow long does it take to set up a custom SMTP provider?#\nFortunately this is very easy. You can use any email sending service for this, really popular ones include:\n\nResend\nAWS SES\nPostmark\nSendGrid\nZepto Mail\nBrevo\n\nAll you need to do is create an account, verify your sending domain and finally input the SMTP username and password in the Auth settings page.\nWhat if I turn off email confirmations, can I use it then?#\nCurrently this behavior is not supported and we'll be rolling out a fix for it during the first week of October.\nConfirming email addresses is where most of the email message activity for a project originates. Turning it off can be a viable option for some projects that are still in the early testing, development or experimental phase.\nBe aware that even if you turn off email confirmations the forgot password or reset password flows in your app continue to function. They also send messages, and starting 26th September those messages will be delivered only to the members of the Supabase organization that owns the project. All other end-users will get a message similar to \"Email address not authorized.\" Effectively, the forgot password / reset password flow will be broken for your project.\nWhat if I want just username + password authentication and using <username>@<fakedomain> instead?#\nPlease don't do this. Part of the reason why we were forced to lock down these changes is bounced emails, probably from use cases like this.\nOfficial username + password support is going to be made available in the coming year, and until then:\n\nUse a real domain, that you control\nSend emails to that domain, so set up a receiving server\n\nBut the best thing to do is:\n\nSet up a Send Email Auth Hook that does nothing. You don't even need to use a server or an Edge Function. Just define a Postgres function that just does nothing.\n\nI'm using the admin API to generate links, and not really sending using Supabase's default provider. Do I need to do anything?#\nAll projects using generate link via the admin API without custom SMTP have been patched to allow the behavior. We still strongly urge those customers to set up custom SMTP regardless.\nJust because you're mostly using the admin API to generate links to send in custom email messages, doesn't mean that the Auth server is not configured to use Supabase's shared SMTP service. Your Auth API can be called from your frontend at any time, especially in edge cases such as to handle forgot password or other similar flows, which you may not be handling via the admin API.\nTherefore we urge all customers that do use the admin API to set up a custom SMTP sending service regardless.\nIf you are not interested in setting this up, you can instruct the Auth server to ignore all emails (pretend it's sending them) by configuring a Send Email Auth Hook as a Postgres function that does nothing.\nHow can I disable the warning banner?#\nYou can disable the warning banner by setting up a custom SMTP provider , or, if your project doesn't use email at all, by disabling the email provider.\nUpdates#\n20th September 2024#\nEmail template customization will be allowed and customized email templates will not be reverted to default.\nTeam has decided that restricting email template customization is not viable and a big breaking change. We may need to do go back to this in the future if abuse continues and our other measures like allowing projects to only send messages to authorized email addresses do not improve the situation. We continue to urge all customers regardless of plan that use the default SMTP service for live applications to move to a custom SMTP provider as soon as able.\n\n\n20th September: Email template customization will no longer be possible without setting up a custom SMTP provider. Email templates already customized can still be customized until 24th September.\n\n\n24th September: Projects without a custom SMTP provider will have their custom email templates returned back to the default ones from Supabase. This means that any auth emails sent out from your project will use the default email template.\nAs our user base has grown, we are taking steps to make sure we are able to continue to provide a safe, secure, robust free plan experience. To ensure that email-based auth continues to work for all users on Supabase, we're making changes if you're using the default email provider. This allows us to continue to offer our default provider in a more sustainable and resilient manner.\nFor maximum flexibility and control over your auth emails, we suggest one of the following:\nIf you still want to use the default email provider, these are the changes being planned:\nEmail template customization will be allowed and customized email templates will not be reverted to default.\n26th September: If you do not have a custom SMTP server set up, emails can only be sent to email addresses in your project's organization. So for example, if your organization has the following members: person-a@example.com, person-b@example.com and person-c@example.com , this means that email messages from Auth will only be sent to these addresses.\nThese measures are taken to prevent abuse to our shared SMTP service. In the future, we may consider increasing the email rate limits once we see a drop in abuse.\nFrequently asked questions#\nWhy such a short notice?#\nSupabase uses a third-party email sending provider that has mandated we reduce email abuse significantly or they will be forced to block all email sending. A tragedy of the commons.\nCan't Supabase switch to a different email sending partner?#\nYes, but we would run into the same issues. All email sending services are required to monitor abuse and force their customers to follow the same rules.\nCan't Supabase send emails on their own, without a third party?#\nNot really. You can't just send email on the web today without investing a lot of money and time (unblocking port 25, keeping IP addresses out of spam lists, etc.). This is not our core competency and do not have plans to start doing this today.\nHow long does it take to set up a custom SMTP provider?#\nFortunately this is very easy. You can use any email sending service for this, really popular ones include:\nAll you need to do is create an account, verify your sending domain and finally input the SMTP username and password in the Auth settings page.\nWhat if I turn off email confirmations, can I use it then?#\nCurrently this behavior is not supported and we'll be rolling out a fix for it during the first week of October.\nConfirming email addresses is where most of the email message activity for a project originates. Turning it off can be a viable option for some projects that are still in the early testing, development or experimental phase.\nBe aware that even if you turn off email confirmations the forgot password or reset password flows in your app continue to function. They also send messages, and starting 26th September those messages will be delivered only to the members of the Supabase organization that owns the project. All other end-users will get a message similar to \"Email address not authorized.\" Effectively, the forgot password / reset password flow will be broken for your project.\nWhat if I want just username + password authentication and using <username>@<fakedomain> instead?#\nPlease don't do this. Part of the reason why we were forced to lock down these changes is bounced emails, probably from use cases like this.\nOfficial username + password support is going to be made available in the coming year, and until then:\nBut the best thing to do is:\nI'm using the admin API to generate links, and not really sending using Supabase's default provider. Do I need to do anything?#\nAll projects using generate link via the admin API without custom SMTP have been patched to allow the behavior. We still strongly urge those customers to set up custom SMTP regardless.\nJust because you're mostly using the admin API to generate links to send in custom email messages, doesn't mean that the Auth server is not configured to use Supabase's shared SMTP service. Your Auth API can be called from your frontend at any time, especially in edge cases such as to handle forgot password or other similar flows, which you may not be handling via the admin API.\nTherefore we urge all customers that do use the admin API to set up a custom SMTP sending service regardless.\nIf you are not interested in setting this up, you can instruct the Auth server to ignore all emails (pretend it's sending them) by configuring a Send Email Auth Hook as a Postgres function that does nothing.\nHow can I disable the warning banner?#\nYou can disable the warning banner by setting up a custom SMTP provider , or, if your project doesn't use email at all, by disabling the email provider.\nUpdates#\n20th September 2024#\nEmail template customization will be allowed and customized email templates will not be reverted to default.\nTeam has decided that restricting email template customization is not viable and a big breaking change. We may need to do go back to this in the future if abuse continues and our other measures like allowing projects to only send messages to authorized email addresses do not improve the situation. We continue to urge all customers regardless of plan that use the default SMTP service for live applications to move to a custom SMTP provider as soon as able.\n20th September: Email template customization will no longer be possible without setting up a custom SMTP provider. Email templates already customized can still be customized until 24th September.\n24th September: Projects without a custom SMTP provider will have their custom email templates returned back to the default ones from Supabase. This means that any auth emails sent out from your project will use the default email template.\nSupabase Auth: Asymmetric Keys support in Q4 2024\nSep 13, 2024\n[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\n\nUpdate (2nd October 2024): We have decided to push back the launch from 7th October 2024 to Q4 2024 to roll this out meticulously; we want to perform exhaustive security checks and spend more time dogfooding internally.\n\nAsymmetric key changelog#\nIntroduction#\nWe are introducing asymmetric key cryptography to Supabase Auth in Q4 2024 on 7th October 2024. This will be provided as an additional option to the JWT secret currently shown in the JWT settings page.\n\nWhy are we doing this?#\nSupabase Auth has always been using a symmetric secret (known as the JWT secret) for signing and verifying JWTs. While this is simple and convenient (since the same secret is used for both signing and verifying), it presents the following problems:\n\nExtra network request required to verify the userâ€™s JWT with the symmetric secret. Currently, one needs to make a request to Supabase Auth in order to verify the userâ€™s JWT or copy the JWT secret into their environment. While the latter suggestion improves performance, it can result in security implications if the secret is accidentally leaked, which requires all your keys to be rolled.\nDifficult to roll with zero downtime. Since the symmetric secret cannot be shared publicly, developers need to wrangle with rolling the secret across their environments while ensuring that the new secret is used.\n\nBenefits of using asymmetric keys#\nAsymmetric keys rely on public / private key cryptography, which means that the private key is only used for signing, while the public key is only used for verifying. This solves the above problems in the following way:\n\nUsage of asymmetric key cryptography rather than a shared symmetric secret for signing and verifying JWTs. Since asymmetric keys donâ€™t use a shared secret, there is less risk of the secret being leaked.\nFaster JWT verification times since thereâ€™s no need to make a network call to Supabase Auth via getUser() . The public key can be used for verifying the JWT. Note that adding the symmetric secret to your server-side environment to verify the JWT also has the same effect but is potentially less secure since there is an increased risk of the secret being leaked if it is used in multiple applications.\nZero-downtime key rotation. Public keys can be exposed in a JSON Web Key Set (JWKs) format, which allows any one of them to be used for verification. When the asymmetric key is rotated, we can still keep the previously used public key in the JWKs endpoint to verify existing JWTs. New JWTs will be signed by the new asymmetric key.\n\nThese will include the following changes:\n\nA public JWKs endpoint for retrieving the public JWK to verify JWTs. This will be exposed through the https://<project_ref>.supabase.co/auth/v1/.well-known/jwks.json endpoint. The symmetric secret will not be exposed through this endpoint for security reasons.\nA new method called getClaims() , which handles verifying the JWT and returning the claims in it.\nAbility to download the public keys in different formats through the dashboard (e.g. PEM, JWKs).\n\nMigration to Asymmetric JWTs#\nNew projects that are created after 1st May 2025 will be created with an RSA asymmetric key by default. Existing projects can choose to start using asymmetric keys by doing the following:\n\nEnsure that you are using the new API keys.\nUpdate all your clients to use at least supabase-js version x.x.x (the version number will be updated closer to the release date). In this version, we are introducing a new method called getClaims which handles verifying both symmetric and asymmetric JWTs:\n\n\nExample successful response payload for getClaims()\n1{2  \"data\": {3\t  \"iss\": \"https://projectref.supabase.co\",4\t  \"sub\": \"565dafb5-fd66-4274-9c37-f0ff720f5637\",5\t  \"aud\": \"authenticated\",6\t  \"exp\": 1824717902,7\t  \"iat\": 1724717902,8\t  \"email\": \"foo@example.com\",9\t  \"phone\": \"\",10\t  \"app_metadata\": {11\t    \"provider\": \"email\",12\t    \"providers\": [\"email\"]13\t  },14\t  \"user_metadata\": {15\t    ...16\t  },17\t  \"role\": \"authenticated\",18\t  \"aal\": \"aal1\",19\t  \"amr\": [20\t    {21\t      \"method\": \"oauth\",22\t      \"timestamp\": 172471790223\t    }24\t  ],25\t  \"session_id\": \"479c1cbf-bd52-42d4-894f-1519f39b3241\",26\t  \"is_anonymous\": false27  },28  \"error\": null29}\n\n\nUsing getClaims() to verify the JWT\n1import { createClient } from 'supabase/supabase-js'23const supabase = createClient(SUPABASE_URL, SUPABASE_KEY)45// previously, using getUser() requires making an 6// additional network request to Supabase Auth to verify the JWT7// 8// const { data, error } = await supabase.auth.getUser()910// getClaims() will always return the JWT payload if the JWT is verified11// If it's an asymmetric JWT, getClaims() will verify using the JWKs endpoint.12// If it's a symmetric JWT, getClaims() calls getUser() to verify the JWT. 13const { data, error } = await supabase.auth.getClaims(jwks)\n\n\n\nCreate an asymmetric key through the dashboard. At this point the symmetric JWT moves to a Previously Used state. Existing JWTs signed with the symmetric JWT continue to be valid, but new JWTs are signed via the asymmetric JWT. Note: The UI mockup below is subjected to change and is just meant to illustrate the different possible states of a signing key.\n\n\n\nAfter the JWT expiry period, you can safely revoke the â€œPreviously Usedâ€ symmetric JWT, since new JWTs will now be signed with the asymmetric key.\n\nFrequently Asked Questions#\n\nWhat do I need to do before I can start using asymmetric keys in Supabase Auth?\n\nSee migration section above for the detailed steps\n\n\nCan I create a symmetric key after I create an asymmetric key?\n\nYes. You will still be able to create a new symmetric key under the JWT settings page in the dashboard. New projects will be created with an asymmetric key by default on 1st May 2025.\n\n\nWill the private asymmetric key be exposed?\n\nNo. Only the public keys will be exposed in various formats (e.g. PEM, JWKs) since those are needed for verification.\n\n\nWill I be able to bring my own private key?\n\nYes, you can bring your own private key as long as it complies with the key types allowed.\n\n\nWhat key types can I use to create asymmetric JWTs?\n\nBy default, asymmetric keys will be created with RS256 by default. You can optionally choose to use ECC or Ed25519. ECC keys are more performant, but not as widely supported as RS256. You can also fallback to HS256 (symmetric keys).\nUpdate (2nd October 2024): We have decided to push back the launch from 7th October 2024 to Q4 2024 to roll this out meticulously; we want to perform exhaustive security checks and spend more time dogfooding internally.\nAsymmetric key changelog#\nIntroduction#\nWe are introducing asymmetric key cryptography to Supabase Auth in Q4 2024 on 7th October 2024. This will be provided as an additional option to the JWT secret currently shown in the JWT settings page.\n\nWhy are we doing this?#\nSupabase Auth has always been using a symmetric secret (known as the JWT secret) for signing and verifying JWTs. While this is simple and convenient (since the same secret is used for both signing and verifying), it presents the following problems:\nBenefits of using asymmetric keys#\nAsymmetric keys rely on public / private key cryptography, which means that the private key is only used for signing, while the public key is only used for verifying. This solves the above problems in the following way:\nThese will include the following changes:\nMigration to Asymmetric JWTs#\nNew projects that are created after 1st May 2025 will be created with an RSA asymmetric key by default. Existing projects can choose to start using asymmetric keys by doing the following:\nExample successful response payload for getClaims()\nUsing getClaims() to verify the JWT\n\nFrequently Asked Questions#\nChanges to Supabase API Keys in Q4 2024 (new & restored projects affected from 1st May 2025, no breaking changes for existing projects until 1st October 2025)\nSep 12, 2024\n[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nIntroduction#\nWeâ€™re changing the way API keys work in Supabase to improve your projectâ€™s security and developer experience and plan to roll out these changes Q4 2024. Rest assured that the current API keys in your existing projects will continue to work for another year until 1st October 2025 during the transition.\nWeâ€™ll contact you when we launch the new API keys, and when we do, no immediate action is required. However, we strongly recommend that you migrate your projectâ€™s existing API keys for the new set when they are introduced. Updating to use the new API keys is a quick and painless process and can be as simple as a change in environment variable and take just a few minutes.\nTimeline#\n\nUpdate (2nd October 2024): We have decided to push back the launch from 7th October 2024 to Q4 2024 to roll this out meticulously; we want to perform exhaustive security checks and spend more time dogfooding internally.\n\nKey DatesDescriptionUser Action NeededQ4 20247th October 2024Introduction of new API keys.New projects will automatically generate both new API keys and legacy API keys to help ease the transition.Existing projects can continue to use the legacy API keys and can opt in to use the new API keys by manually generating them.No immediate action needed. We strongly recommend that you migrate to use the new API keys.1st May 2025We will start sending you monthly reminders to migrate off legacy API keys and start using the new keys.New projects will be created with only new API keys.Projects restored from 1st May 2025 will no longer be restored with the legacy API keys.You are highly encouraged to migrate off to use the new API keys before this date since paused projects that are restored risk being broken as they wonâ€™t have the legacy keys.1st October 2025Legacy API keys will be deleted and removed from the Docs / Dashboard.You have to migrate to use the new API keys by this point or your app will break.\nWhy are we doing this?#\nCurrently there is a tight coupling between API keys and the JWT secret which presents a few challenges:\n\n\nDifficult to revoke the service_role or anon key. Imagine if someone in your Supabase organization leaves the team, and you want to roll your projectâ€™s JWT secret to revoke their access? Or you accidentally commit the service_role key into your version control system and need to roll it?\nIf either of these keys gets leaked, the developerâ€™s only option is to roll the JWT secret by generating a new one. When the JWT secret is rolled, all authenticated users would be logged out, clients using the older anon and service keys would break. Realistically, there is no way to roll the JWT secret without downtime.\n\n\nSub-optimal developer experience to create an API key with a custom role. Developer needs to sign a JWT with a long expiry time and their custom role using the secret.\n\n\nThe introduction of new API keys solves the above problems by allowing the developer to:\n\nroll individual API keys\nroll the API keys without logging out their users\ncreate custom API keys easily\n\nAPI Key changes#\nThese are the planned changes for the API keys:\n\n\nanon key will be renamed to publishable key and the service_role key will be renamed to secret key. publishable api keys are meant to be used along with Supabase Auth users and secret api keys are for use from the server side and bypasses all row level security policies. We chose to use publishable and secret to align with stripeâ€™s terminology and preferred it to terms like public and private since those could be confused with public / private key cryptography when we introduce asymmetric JWTs to Supabase Auth.\n\n\nNew API keys will look like regular strings instead of JWTs:\nLegacy API KeysEquivalent New API Keysanon key: eyJhbGciOiJIUzI1...FDsBGn0iqSmL28Zeg8f0publishable key: sb_publishable_123abcservice_role key: eyJhbGciOiJIUzI1...SEVEyZQNhffCoSj4P5Asecret key: sb_secret_123abc\n\n\nWith the new API keys, it will be possible to revoke individual API keys and without revoking the JWT secret. Once the legacy API key is revoked, it wonâ€™t be possible to restore them.\n\n\nNew projects will be created with both new and legacy API keys until 1st May 2025. New projects created after this date will only be created with new API keys.\n\n\nProjects that are restored after 1st May 2025 will not be restored with legacy API keys.\n\n\nLegacy API keys will no longer work for all projects after 1st October 2025.\n\n\nMigration to the new API keys#\n\nIf you want to use the new API keys, all you need to do is to swap out your keys for the new ones:\n\nLegacy API KeysEquivalent New API Keysanon keypublishable keyservice_role keysecret key\n\nUpdate your .env file to contain the new API key\n\n1# the legacy anon key2SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...w6PYobnC7Ep7EnDd9DG25qBFDsBGn0iqSmL28Zeg8f0 34# the new publishable key5SUPABASE_PUBLISHABLE_KEY=sb_publishable_123abc\n\nInstantiate the supabase client with the new API Keys.\n\n1import { createClient } from 'supabase/supabase-js' 23const supabase = createClient(SUPABASE_URL, SUPABASE_PUBLISHABLE_KEY)\n\nAfter all your clients have been instantiated with the new API keys, you can revoke the legacy keys from the dashboard.\n\nFrequently Asked Questions#\n\nWhat is the timeline for the migration?\n\nSee \"Timeline\" section above\n\n\nMy app is deployed through Vercel / Netlify, how do I use the new API keys?\n\nIf youâ€™re using Vercel or Netlify, changing the keys in your environment will only be reflected when you trigger a new deployment.\n\n\nI only connect to the database via the connection string â€”Â do I need to worry about this at all?\n\nNo, unless you use the supabase client libraries to make queries to the database.\n\n\nHow do we do custom claims?\n\nCurrently, users have to manually create a new key with their custom claims using the JWT secret provided.\nThere will be support for creating new API keys with custom properties in the dashboard and management API.\n\n\nWhat benefit do we get from migrating to use the new API keys?\n\nYou can revoke an individual key in the event of a compromise\nYou can revoke keys without logging out existing users\nYou donâ€™t have to deal with minting a new JWT using the JWT secret if you want to add custom claims to an API key.\n\n\nWhat is the interaction between the apikey header, the Authorization header and the underlying Postgres role used?\n\nThe new API keys are just regular strings instead of JWTs.\nBy default, secret API keys assume the service_role. When creating the new secret API keys, you can override this behavior and assign a custom role. Downstream services like postgREST and storage assume this role when they are called with this API key.\nBy default, publishable API keys default to the anon  role. When a user JWT is passed in via the Authorization header, the role claim in the JWT is used instead. You cannot map publishable keys to custom roles when creating the key, like you will be able to do with secret API keys.\nIntroduction#\nWeâ€™re changing the way API keys work in Supabase to improve your projectâ€™s security and developer experience and plan to roll out these changes Q4 2024. Rest assured that the current API keys in your existing projects will continue to work for another year until 1st October 2025 during the transition.\nWeâ€™ll contact you when we launch the new API keys, and when we do, no immediate action is required. However, we strongly recommend that you migrate your projectâ€™s existing API keys for the new set when they are introduced. Updating to use the new API keys is a quick and painless process and can be as simple as a change in environment variable and take just a few minutes.\nTimeline#\nUpdate (2nd October 2024): We have decided to push back the launch from 7th October 2024 to Q4 2024 to roll this out meticulously; we want to perform exhaustive security checks and spend more time dogfooding internally.\nWhy are we doing this?#\nCurrently there is a tight coupling between API keys and the JWT secret which presents a few challenges:\nDifficult to revoke the service_role or anon key. Imagine if someone in your Supabase organization leaves the team, and you want to roll your projectâ€™s JWT secret to revoke their access? Or you accidentally commit the service_role key into your version control system and need to roll it?\nIf either of these keys gets leaked, the developerâ€™s only option is to roll the JWT secret by generating a new one. When the JWT secret is rolled, all authenticated users would be logged out, clients using the older anon and service keys would break. Realistically, there is no way to roll the JWT secret without downtime.\nSub-optimal developer experience to create an API key with a custom role. Developer needs to sign a JWT with a long expiry time and their custom role using the secret.\nThe introduction of new API keys solves the above problems by allowing the developer to:\nAPI Key changes#\nThese are the planned changes for the API keys:\nanon key will be renamed to publishable key and the service_role key will be renamed to secret key. publishable api keys are meant to be used along with Supabase Auth users and secret api keys are for use from the server side and bypasses all row level security policies. We chose to use publishable and secret to align with stripeâ€™s terminology and preferred it to terms like public and private since those could be confused with public / private key cryptography when we introduce asymmetric JWTs to Supabase Auth.\nNew API keys will look like regular strings instead of JWTs:\nWith the new API keys, it will be possible to revoke individual API keys and without revoking the JWT secret. Once the legacy API key is revoked, it wonâ€™t be possible to restore them.\nNew projects will be created with both new and legacy API keys until 1st May 2025. New projects created after this date will only be created with new API keys.\nProjects that are restored after 1st May 2025 will not be restored with legacy API keys.\nLegacy API keys will no longer work for all projects after 1st October 2025.\nMigration to the new API keys#\nFrequently Asked Questions#\n\nDashboard Weekly Updates [02/09/24 - 09/09/24]\nSep 12, 2024\nSchema Visualizer nodes are now persisted#\n\nThis was yet another request that we've commonly heard from everyone and we're taking a first step to making this happen ðŸ˜„ Position of the nodes will now be stored within local storage so that you won't have to re-position them each time you land on this page. We've also added a button to help arrange the nodes automatically if that might be preferred!\nNote that if you add new tables to the schema however, the node positions will be defaulted to a certain position that may overlap with other nodes - we're definitely looking into how we can make that better so that new nodes can be easily identified (and then shifted around to your liking ðŸ™‚)\nPR: https://github.com/supabase/supabase/pull/29136\nLink: https://supabase.com/dashboard/project/_/schemas\nOther improvements and bug fixes#\nGeneral\n\nMinor improvements to layouts and buttons to ensure their visibility on smaller screens (PR)\nFix project status filter on home page to only show active projects if only the active checkbox is checked (PR)\n\nTable Editor\n\nFix client crash when creating an empty table with no columns (PR)\nFix handling of of large JSON / text fields in the side panel text editor (PR)\n\nSQL Editor\n\nAdd client side validation for query size (max 1MB) (PR)\nCouple of fixes around adding a new folder with the same name as an existing one (PR)\n\nDatabase\n\nUpdate Stripe Wrapper with more tables (PR)\nRemove docs button for database extensions that have no documentation yet (PR)\nSchema Visualizer nodes are now persisted#\n\nThis was yet another request that we've commonly heard from everyone and we're taking a first step to making this happen ðŸ˜„ Position of the nodes will now be stored within local storage so that you won't have to re-position them each time you land on this page. We've also added a button to help arrange the nodes automatically if that might be preferred!\nNote that if you add new tables to the schema however, the node positions will be defaulted to a certain position that may overlap with other nodes - we're definitely looking into how we can make that better so that new nodes can be easily identified (and then shifted around to your liking ðŸ™‚)\nPR: https://github.com/supabase/supabase/pull/29136\nLink: https://supabase.com/dashboard/project/_/schemas\nOther improvements and bug fixes#\nGeneral\nTable Editor\nSQL Editor\nDatabase\nEdge Functions are now Deno 1.45 compatible\nSep 10, 2024\n[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nSupabase Edge Runtime version 1.57 is compatible with Deno 1.45.\nSupabase's hosted platform was upgraded to use this release when serving Edge Functions starting last week.\nIf you're using Supabase CLI for local development latest stable release 1.192.5, it adds compatibility for Deno 1.45.\nHow do I find which version of Edge Runtime I'm running?#\nSupabase CLI (local)#\nWhen you run supabase functions serve, it should show the current version of Edge Runtime used (and its Deno compatibility)\n1> supabase functions serve23Setting up Edge Functions runtime...4Serving functions on http://127.0.0.1:54321/functions/v1/<function-name>5Using supabase-edge-runtime-1.58.2 (compatible with Deno v1.45.2)\nHosted Platform#\nYou can check the served_by field in log events to see which Edge Runtime version was used to serve your function.\n\nWe try our best to maintain backward compatibility in these upgrades. If you're experiencing any issues, please feel free to make a support request\nSupabase Edge Runtime version 1.57 is compatible with Deno 1.45.\nSupabase's hosted platform was upgraded to use this release when serving Edge Functions starting last week.\nIf you're using Supabase CLI for local development latest stable release 1.192.5, it adds compatibility for Deno 1.45.\nHow do I find which version of Edge Runtime I'm running?#\nSupabase CLI (local)#\nWhen you run supabase functions serve, it should show the current version of Edge Runtime used (and its Deno compatibility)\nHosted Platform#\nYou can check the served_by field in log events to see which Edge Runtime version was used to serve your function.\n\nWe try our best to maintain backward compatibility in these upgrades. If you're experiencing any issues, please feel free to make a support request\nDashboard Weekly Updates [26/08/24 - 02/09/24]\nSep 2, 2024\nUpgrade your organization directly from our pricing page#\nhttps://github.com/user-attachments/assets/2262d816-0c69-4c58-a6e2-1ce4868122f2\nUsers who are logged in will now be able to select and upgrade their organization from the pricing page itself when clicking on the Upgrade to Pro / Team plan buttons. This is mainly to help streamline this process so that users can upgrade their existing organizations, and prevent confusions where users end up creating new paid organizations instead.\nPR: https://github.com/supabase/supabase/pull/28942\nLink: https://supabase.com/pricing\nUI improvements around credit card billing information#\n\nThe selected payment method on the billing page is easily missed as you'll need to scroll down before finding it. In particular with outstanding invoices, it may not be obvious that the wrong card (or even expired card) might have been selected as the default. As such we now will\n\nIndicate which cards are about to expire (within the current month)\nIndicate which cards have expired\nShow the selected payment method, along with a quick link to change it on the invoices page\n\nPR: https://github.com/supabase/supabase/pull/28971\nLink: https://supabase.com/dashboard/org/_/billing\nSet payment method as default when adding a new payment method#\n\nWhen adding a new payment method, we have now added a checkbox to set the card as default which is toggled on by default. This should resolve a UX issue whereby customers needed to explicitly set the card as default in a separate manual step after adding it.\nPR: https://github.com/supabase/supabase/pull/28921\nLink: https://supabase.com/dashboard/org/_/billing\nChoose which schemas to share with OpenAI#\n\nThis mainly applies to wherever the Supabase AI assistant is present in the dashboard (SQL Editor + RLS policies). You can now choose which schemas to share with OpenAI as opposed to sending information from all schemas in hopes to improve the output quality of the assistant by only sharing relevant information for your prompts to the assistant.\nDo keep in mind that you'll need to opt in to sending anonymous data to OpenAI prior to doing this ðŸ™‚ You may also verify exactly what data is being sent here as well under \"Important information regarding opting in\"!\nPR: https://github.com/supabase/supabase/pull/28594\nLink: https://supabase.com/dashboard/project/_/sql/new\nOther improvements and bug fixes#\nGeneral\n\nShow which is the last sign in method used on login page (PR)\nAdded 3 new regions to spin up projects from: Ohio, Stockholm, Paris, and Zurich (PR)\nCommands added for cmd+k to search and open snippets in the SQL Editor (PR)\nSupport pasting image (via Cmd/Ctrl + v) in the feedback widget (PR)\nUse expanding text area for RLS AI assistant for multi line prompts (PR)\n\nTable Editor\n\nSave last selected schema, no longer defaults to public schema (PR)\nSet the correct schema in the schema selector when opening a table via URL directly (PR)\nSupport exporting table data as SQL seed file (PR)\nCouple of fixes for bugs around composite foreign keys (PR)\nImprove display of estimated row count for the table if the table has > 50k rows, to emphasize that it's an estimated count (PR)\nSpreadsheet import now checks column types from imported spreadsheet (PR)\n\nSQL Editor\n\nFix folder name editing where clicking on the input field toggles the folder (PR)\nSupport opening cell value via right click into a side panel for a more detailed view (PR)\n\nAuth\n\n\"With check\" checkbox is toggled on by default for commands that involve a with check expression (PR)\n\nStorage\n\nSupport searching and sorting buckets (PR)\n\nLogs Explorer\n\nSupport copying cell content via context menu (PR)\nUpgrade your organization directly from our pricing page#\nhttps://github.com/user-attachments/assets/2262d816-0c69-4c58-a6e2-1ce4868122f2\nUsers who are logged in will now be able to select and upgrade their organization from the pricing page itself when clicking on the Upgrade to Pro / Team plan buttons. This is mainly to help streamline this process so that users can upgrade their existing organizations, and prevent confusions where users end up creating new paid organizations instead.\nPR: https://github.com/supabase/supabase/pull/28942\nLink: https://supabase.com/pricing\nUI improvements around credit card billing information#\nThe selected payment method on the billing page is easily missed as you'll need to scroll down before finding it. In particular with outstanding invoices, it may not be obvious that the wrong card (or even expired card) might have been selected as the default. As such we now will\nPR: https://github.com/supabase/supabase/pull/28971\nLink: https://supabase.com/dashboard/org/_/billing\nSet payment method as default when adding a new payment method#\nWhen adding a new payment method, we have now added a checkbox to set the card as default which is toggled on by default. This should resolve a UX issue whereby customers needed to explicitly set the card as default in a separate manual step after adding it.\nPR: https://github.com/supabase/supabase/pull/28921\nLink: https://supabase.com/dashboard/org/_/billing\nChoose which schemas to share with OpenAI#\n\nThis mainly applies to wherever the Supabase AI assistant is present in the dashboard (SQL Editor + RLS policies). You can now choose which schemas to share with OpenAI as opposed to sending information from all schemas in hopes to improve the output quality of the assistant by only sharing relevant information for your prompts to the assistant.\nDo keep in mind that you'll need to opt in to sending anonymous data to OpenAI prior to doing this ðŸ™‚ You may also verify exactly what data is being sent here as well under \"Important information regarding opting in\"!\nPR: https://github.com/supabase/supabase/pull/28594\nLink: https://supabase.com/dashboard/project/_/sql/new\nOther improvements and bug fixes#\nGeneral\nTable Editor\nSQL Editor\nAuth\nStorage\nLogs Explorer\nDashboard Weekly Updates [26/08/24 - 30/08/24]\nAug 30, 2024\nThe SQL Editor got an upgrade this week, finally letting you organize snippets into folders!\n\nFavourites and Shared snippets are in folders now\nOrganize Private snippets in folders as you like\nShare snippets with your team as you could before\n\nLink: https://supabase.com/dashboard/project/_/sql/new\r\nPR: https://github.com/supabase/supabase/pull/27881\nOther bug fixes and improvements#\nProject compute size badge\n\nSee project compute details and upgrade right from the home screen (PR)\n\nSQL Editor\n\nUpdate the SQL Editor AI Assistant model to the latest from OpenAI (PR)\n\nThe SQL Editor got an upgrade this week, finally letting you organize snippets into folders!\nLink: https://supabase.com/dashboard/project/_/sql/new\r\nPR: https://github.com/supabase/supabase/pull/27881\nOther bug fixes and improvements#\nProject compute size badge\nSQL Editor\nMoving to hourly usage-based billing for databases, based on disk consumption\nAug 23, 2024\ntldr:\n\nNo changes for Free Plan users\nBilling for paid plan organizations will be based on provisioned disk rather than used database space:\n\nEach project starts with 8 GB disk provisioned by default.\nThe first 8 GB of provisioned disk per project is free, then $0.125 per additional GB.\nCharges are prorated down to the hour, which is advantageous for short-lived projects and branches.\nProvisioned disk from Read Replicas will also be included in billing.\nEnables upcoming features for enhanced control over disk and Postgres parameters.\n\n\n\nTimeline\nThis change will be rolled out to new customers on August 26th, 2024 and will be gradually rolled out to existing customers shortly after.\nChanges\nWe are adjusting our pricing to offer more flexibility and self-serve for developers wanting to tune their disk and Postgres configuration. For example:\n\nSome developers want disks with higher throughput\nSome developers want to store more than 1GB of WAL (for tools like Airbyte/PeerDB, or adding more read replicas)\n\nTo make this available we will start billing for provisioned disk size (rather than database space used). Previously, costs associated with WAL files were not directly billed but also users could not control change max_wal_size (default is 1GB).\nThere is no action needed on your end. You will automatically be transitioned to the new billing model throughout the next couple of weeks. In case there is any change in your monthly bill, we will reach out to you proactively with additional information and give you a grace period to decrease your usage.\nFor customers on the Free Plan, there will be no changes; the total database space remains capped at 500MB. These adjustments only apply to customers on paid plans. The database disk will continue to autoscale when nearing capacity for paid plan customers.\nBeforeAfter (August 26th, 2024)Price$0.125 / GB$0.000171 / GB-HrChangeWe take the average database space used for all projects, independent of how many days/hours you store the files and sum it up.We will you based on the provisioned disk usage every hour. First 8GB per project are free. Read replicas will also incur disk costs.Invoice ItemYour invoices display 'Total Database size'.Your invoices will display 'Disk Size GB-Hrs'.\nExample 1: Pro plan org, active for whole month#\nIn this scenario, an Organization is on the Pro Plan with 3 active projects.\nUsage\nProject# Days ActiveAverage Database Space UsedProvisioned DiskAfter: Provisioned Disk Size GB-HrsProject A3025 GB40.5 GB29,160 (720 hours * 40.5 GB)Project B3010 GB27 GB19,440 (720 hours * 27 GB)Project C305 GB8 GB5,760 (720 hours * 8 GB)Total40 GB54,360 GB-Hrs\nBilling\nBeforeAfterTotal Usage40 GB54,360 GB-HrsUsage Discount (Pro Plan)(8 GB)(17,280 GB-Hrs - first 8 GB per project included)Billable Usage32 GB37,080 GB-HrsPrice$0.125 / GB$0.000171 / GB-HrTotal Cost$4.00$6.43\nExample 2: Pro plan org, active for part of the month#\nIn this scenario, an Organization is on the Pro Plan with 3 active projects.\nUsage\nProject# Days ActiveAverage Database Space UsedProvisioned DiskAfter: Provisioned Disk Size GB-HrsProject A309 GB12 GB8,640 (720 hours * 12 GB)Project B159 GB12 GB4,320 (360 hours * 12 GB)Project C29 GB12 GB576 (48 hours * 12 GB)Total27 GB13,536 GB-Hrs\nBilling\nBeforeAfterTotal Usage27 GB13,536 GB-HrsUsage Discount (Pro Plan)(8 GB)(9,024 - first 8 GB per project included)Billable Usage19 GB4,512 GB-HrsPrice$0.125 / GB$0.000171 / GB-HrTotal Cost$2.38$0.77\nWhere do I see my disk size?#\nYou can see your projectâ€™s disk size in your database settings (Project Settings > Database).\n\nHow can I resize my disk down?#\nYour disk size is based on your database space usage. As a first step, you need to identify current database space usage and reduce it. To see your current database space usage, head over to the built-in â€œDatabaseâ€ project report. Once you have reduced your database space and want to reduce your provisioned disk, you can upgrade your Postgres version through your project settings to automatically rightsize your disk. For further information around disk management and reducing database space, please refer to our docs.\nIs this going to affect my monthly bill?#\nIf your current disk size is >8GB, this is likely going to impact you. Note that this will be gradually rolled out and you will be notified about the concrete impact on your organization and given a 3-month grace period, which gives you time to right-size your disk and minimize the impact of this change.\ntldr:\nTimeline\nThis change will be rolled out to new customers on August 26th, 2024 and will be gradually rolled out to existing customers shortly after.\nChanges\nWe are adjusting our pricing to offer more flexibility and self-serve for developers wanting to tune their disk and Postgres configuration. For example:\nTo make this available we will start billing for provisioned disk size (rather than database space used). Previously, costs associated with WAL files were not directly billed but also users could not control change max_wal_size (default is 1GB).\nThere is no action needed on your end. You will automatically be transitioned to the new billing model throughout the next couple of weeks. In case there is any change in your monthly bill, we will reach out to you proactively with additional information and give you a grace period to decrease your usage.\nFor customers on the Free Plan, there will be no changes; the total database space remains capped at 500MB. These adjustments only apply to customers on paid plans. The database disk will continue to autoscale when nearing capacity for paid plan customers.\nExample 1: Pro plan org, active for whole month#\nIn this scenario, an Organization is on the Pro Plan with 3 active projects.\nUsage\nBilling\nExample 2: Pro plan org, active for part of the month#\nIn this scenario, an Organization is on the Pro Plan with 3 active projects.\nUsage\nBilling\nWhere do I see my disk size?#\nYou can see your projectâ€™s disk size in your database settings (Project Settings > Database).\nHow can I resize my disk down?#\nYour disk size is based on your database space usage. As a first step, you need to identify current database space usage and reduce it. To see your current database space usage, head over to the built-in â€œDatabaseâ€ project report. Once you have reduced your database space and want to reduce your provisioned disk, you can upgrade your Postgres version through your project settings to automatically rightsize your disk. For further information around disk management and reducing database space, please refer to our docs.\nIs this going to affect my monthly bill?#\nIf your current disk size is >8GB, this is likely going to impact you. Note that this will be gradually rolled out and you will be notified about the concrete impact on your organization and given a 3-month grace period, which gives you time to right-size your disk and minimize the impact of this change.\nThreshold for transitioning projects to physical backups lowered to 15GB\nAug 19, 2024\nFurther to earlier discussions, the threshold for transitioning large databases to use physical backups for their daily backups is being lowered to 15GB in the next few days.\nPhysical backups are more performant, have lower impact on the db, and avoid holding locks for long periods of time. Restores continue to work as expected, but backups taken using this method can no longer be downloaded from the dashboard.\nOver the next few months, we'll be introducing functionality to restore to a separate, new database, allowing for the perusal of the backed up data without disruption to the original project.\nPlease refer to supabase.com/docs/guides/platform/backups#daily-backups-process for additional details.\nFurther to earlier discussions, the threshold for transitioning large databases to use physical backups for their daily backups is being lowered to 15GB in the next few days.\nPhysical backups are more performant, have lower impact on the db, and avoid holding locks for long periods of time. Restores continue to work as expected, but backups taken using this method can no longer be downloaded from the dashboard.\nOver the next few months, we'll be introducing functionality to restore to a separate, new database, allowing for the perusal of the backed up data without disruption to the original project.\nPlease refer to supabase.com/docs/guides/platform/backups#daily-backups-process for additional details.\nImproved invoices and more timely usage data\nAug 8, 2024\nCurrently, usage data on the invoice breakdown and organization usage page has a 24-hour delay. Starting from August 26th, the usage data will have no more of 1 hour delay for new customers. Afterwards, the changes will be rolled out to existing customer gradually. We're also working on additional improvements to provide better usage insights.\n\n\nAdditionally, we are revamping invoices to provide more detailed breakdowns of usage for enhanced transparency. Due to our new proration of project add-ons and storage down to the hour, you may notice slight variances in your monthly bill. For the majority of line items, youâ€™ll see the project reference and usage on the invoice, which should make it clearer which project allocated the usage/costs.\nA few examples:\nCompute Hours is broken down per project and the compute credits ($10) is displayed as discount for the compute line item.\n\nEgress is broken down to each project and displays included quota (250GB) and over-age pricing ($0.09/GB)\n\nRealtime Messages line item shows package-based pricing with $2.50 per million.\nCurrently, usage data on the invoice breakdown and organization usage page has a 24-hour delay. Starting from August 26th, the usage data will have no more of 1 hour delay for new customers. Afterwards, the changes will be rolled out to existing customer gradually. We're also working on additional improvements to provide better usage insights.\nAdditionally, we are revamping invoices to provide more detailed breakdowns of usage for enhanced transparency. Due to our new proration of project add-ons and storage down to the hour, you may notice slight variances in your monthly bill. For the majority of line items, youâ€™ll see the project reference and usage on the invoice, which should make it clearer which project allocated the usage/costs.\nA few examples:\nCompute Hours is broken down per project and the compute credits ($10) is displayed as discount for the compute line item.\nEgress is broken down to each project and displays included quota (250GB) and over-age pricing ($0.09/GB)\nRealtime Messages line item shows package-based pricing with $2.50 per million.\nMoving to hourly usage-based billing for IPv4, Custom Domain and Point-in-time recovery\nAug 7, 2024\nMoving to hourly usage-based billing for IPv4, Custom Domain and Point-in-time recovery#\nWeâ€™re moving to billing all project add-ons usage-based and prorated down to the hour at the end of your billing cycle. We're not altering the monthly prices.\n\nTimeline#\nThis change will be rolled out to new customers on August 26th, 2024 and will be gradually rolled out to existing customers shortly after.\n\nChanges#\nBeforeAfter (August 26th, 2024)Custom Domain$10 / month$0.0137 / hourIPv4$4 / month / database$0.0055 / hour / databasePoint-in-time Recovery - 7 Days$100 / month$0.137 / hourPoint-in-time Recovery - 14 Days$200 / month$0.274 / hourPoint-in-time Recovery - 28 Days$400 / month$0.55 / hourChangeProject add-ons are paid upfront. Every time you change an add-on, you immediately pay for remaining time or get credits for unused time. Each change triggers an additional invoice.We bill you at the end of your billing cycle for the hours youâ€™ve used the project add-ons. No in-between charges, credit prorations or additional invoices.Invoice ItemYour invoices display 'Add-on Name'.Your invoices will display 'Add-on Name Hours'.\n\nDetails#\nWe're updating how we bill project add-ons (IPv4, Point-in-time recovery, Custom Domain) without changing their monthly prices. This change will be rolled out on August 26th, 2024 for new customers and shortly after for existing customers.\nPreviously, when you added a project add-on, like IPv4 or PITR, you were immediately invoiced and charged for the remaining billing cycle period. At the start of a new cycle, you paid upfront for the entire month. If you removed an add-on mid-cycle, you received a credit for unused time.\nStarting August 26th, you will be billed retrospectively for these add-ons, similar to Compute Hours. There are no more upfront charges, prorated invoices, or credits. You simply pay for the exact hours you use the project add-ons.\nPlans (Pro/Team/Enterprise) are still charged upfront and there are no changes to how they are billed.\nMoving to hourly usage-based billing for IPv4, Custom Domain and Point-in-time recovery#\nWeâ€™re moving to billing all project add-ons usage-based and prorated down to the hour at the end of your billing cycle. We're not altering the monthly prices.\nTimeline#\nThis change will be rolled out to new customers on August 26th, 2024 and will be gradually rolled out to existing customers shortly after.\nChanges#\nDetails#\nWe're updating how we bill project add-ons (IPv4, Point-in-time recovery, Custom Domain) without changing their monthly prices. This change will be rolled out on August 26th, 2024 for new customers and shortly after for existing customers.\nPreviously, when you added a project add-on, like IPv4 or PITR, you were immediately invoiced and charged for the remaining billing cycle period. At the start of a new cycle, you paid upfront for the entire month. If you removed an add-on mid-cycle, you received a credit for unused time.\nStarting August 26th, you will be billed retrospectively for these add-ons, similar to Compute Hours. There are no more upfront charges, prorated invoices, or credits. You simply pay for the exact hours you use the project add-ons.\nPlans (Pro/Team/Enterprise) are still charged upfront and there are no changes to how they are billed.\nMoving to hourly billing for Storage Size\nAug 2, 2024\nHourly Billing for Storage#\nWeâ€™re moving to more granular billing periods. We're not altering the prices or storage quotas. Every customer will benefit from this change, especially short-lived projects and customers using Branching.\nTimeline#\nThis change will be rolled out to new customers on August 26th, 2024 and will be gradually rolled out to existing customers shortly after.\nChanges#\nThe price will move to \"GB per hour\" instead of \"Total storage GB\":\nBeforeAfter (August 26th, 2024)Price$0.021 / GB$0.00002919 / GB / hourChangeWe take the average storage size for all projects, independent of how many days/hours you store the files.We bill you only for the exact GBs used each hour.Invoice ItemYour invoices display 'Total storage size'.Your invoices will display 'Storage Size GB-Hrs'.\nLet's step through 2 scenarios to explain how this change will benefit developers:\n\n\n\nExample 1: Pro Plan Org, active for the full month#\nIn this scenario, an Organization is on the Pro Plan with 3 active projects.\nUsage#\nThe projects are running for the entire month:\nStorage# Days ActiveActive Hours (After)Project A200 GB30144,000 (720 hours * 200 GB)Project B1,500 GB301,080,000 (720 hours * 1,500 GB)Project C2,500 GB301,800,000 (720 hours * 2,500 GB)----Total4,200 GB3,024,000 hours\nBilling#\nAfter the billing changes on August 26th there would be no change in pricing:\nBeforeAfterTotal Usage4,200 GB3,024,000 hoursUsage Discount (Pro Plan)(100 GB)(74,400 hours)Billable Usage4,100 GB2,949,600 hours---Price$0.021 / GB$0.00002919 / GB / hourTotal Cost$86.10$86.10\n\n\n\nExample 2: Pro Plan Org, active for part of the month#\nIn this scenario, an Organization is on the Pro Plan with 3 active projects.\nUsage\nIn this scenario, some of the projects are only active for a few days in the month:\nStorage# Days ActiveAfter: GB HoursProject A200 GB29,600 (48 hours * 200 GB)Project B1,500 GB15540,000 (360 hours * 1,500 GB)Project C2,500 GB301,800,000 (720 hours * 2,500 GB)----Total4,200 GB2,349,600 hours\nBilling\nCurrently we charge you for the full 4,200 GB, even though Project A and B werenâ€™t active for the entire month. After August 26th, this scenario will be 22.87% cheaper:\nBeforeAfterTotal Usage4,200 GB2,349,600 hoursUsage Discount (Pro Plan)(100 GB)(74,400 hours)Billable Usage4,100 GB2,275,200 hours---Price$0.021 / GB$0.00002919 / GB / hourTotal Cost$86.10$66.41\n\n\n\nFeedback#\nThis change should be universally beneficial, but if there is anything that we have missed just let us know and we will make sure we consider it before rolling out this change.\nHourly Billing for Storage#\nWeâ€™re moving to more granular billing periods. We're not altering the prices or storage quotas. Every customer will benefit from this change, especially short-lived projects and customers using Branching.\nTimeline#\nThis change will be rolled out to new customers on August 26th, 2024 and will be gradually rolled out to existing customers shortly after.\nChanges#\nThe price will move to \"GB per hour\" instead of \"Total storage GB\":\nLet's step through 2 scenarios to explain how this change will benefit developers:\nExample 1: Pro Plan Org, active for the full month#\nIn this scenario, an Organization is on the Pro Plan with 3 active projects.\nUsage#\nThe projects are running for the entire month:\nBilling#\nAfter the billing changes on August 26th there would be no change in pricing:\nExample 2: Pro Plan Org, active for part of the month#\nIn this scenario, an Organization is on the Pro Plan with 3 active projects.\nUsage\nIn this scenario, some of the projects are only active for a few days in the month:\nBilling\nCurrently we charge you for the full 4,200 GB, even though Project A and B werenâ€™t active for the entire month. After August 26th, this scenario will be 22.87% cheaper:\nFeedback#\nThis change should be universally beneficial, but if there is anything that we have missed just let us know and we will make sure we consider it before rolling out this change.\nWrappers Wasm FDW is on Public Alpha\nJul 30, 2024\nWebAssembly Foreign Data Wrapper (Wasm FDW) is now on public alpha from Wrappers version >= 0.4.1. This release also contains two new Wasm FDWs: Snowflake and Paddle.\nWhat is Wasm FDW?#\nIn previous versions of Wrappers, all the foreign data wrappers need to be built into wrappers extension. The develop/test/release cycle is time consuming and fully on Supabase teams. To speed up this process and give more flexibility to community, we're adding Wasm to the Wrappers framework. With this new feature, users can build their own FDW using Wasm and use it instantly on Supabase platform.\nAnother benefit is because of the improved modularity, each FDW can be updated and loaded individually. New FDWs release will be quicker than before. Also, wrappers extension size won't be bloated as more FDWs added in.\nWhat are the changes?#\nThere is no changes from end-users' perspective, all existing native FDWs are still same. The Wasm FDW only brings a new way of developing and distributing FDW.\nHow to use it?#\nVisit Database -> Platform -> Wrappers on Supabase Studio, enable Wrappers and choose Snowflake or Paddle, then create foreign tables.\nVisit Snowflake Wasm FDW docs or Paddle Wasm FDW docs for more details.\nHow to develop my own Wasm FDW?#\nTo build your own Wasm FDW, visit the example project to get started.\nWebAssembly Foreign Data Wrapper (Wasm FDW) is now on public alpha from Wrappers version >= 0.4.1. This release also contains two new Wasm FDWs: Snowflake and Paddle.\nWhat is Wasm FDW?#\nIn previous versions of Wrappers, all the foreign data wrappers need to be built into wrappers extension. The develop/test/release cycle is time consuming and fully on Supabase teams. To speed up this process and give more flexibility to community, we're adding Wasm to the Wrappers framework. With this new feature, users can build their own FDW using Wasm and use it instantly on Supabase platform.\nAnother benefit is because of the improved modularity, each FDW can be updated and loaded individually. New FDWs release will be quicker than before. Also, wrappers extension size won't be bloated as more FDWs added in.\nWhat are the changes?#\nThere is no changes from end-users' perspective, all existing native FDWs are still same. The Wasm FDW only brings a new way of developing and distributing FDW.\nHow to use it?#\nVisit Database -> Platform -> Wrappers on Supabase Studio, enable Wrappers and choose Snowflake or Paddle, then create foreign tables.\nVisit Snowflake Wasm FDW docs or Paddle Wasm FDW docs for more details.\nHow to develop my own Wasm FDW?#\nTo build your own Wasm FDW, visit the example project to get started.\nDeveloper Updates - June 2024\nJul 24, 2024\nWe have several updates and new features to share with you this month. Dive in to see whatâ€™s new from Supabase.\nEdge Runtime Inspector Feature (CLI)#\n\nWeâ€™ve introduced the Edge Runtime Inspector, a powerful new feature in the CLI that helps you inspect and debug edge functions more efficiently.\r\nPull Request\nView and Abort Running Queries (Supabase Studio)#\n\nYou can now view and abort queries currently running on your database (primary or replica) in the Supabase Studio SQL Editor. This feature gives you greater control and flexibility in managing your queries.\r\nPull Request\nLogging Integration With The ELK Stack#\nThe Logflare to Elastic filebeat backend has been merged. This integration enables log drains to ELK stacks, providing more robust logging and monitoring capabilities.\r\nDocumentation\nInterpreting Supabase Grafana I/O Charts#\nWe have published a guide on how to use the Supabase I/O charts to identify when you may need to scale your database, optimize your queries, or spin up a read replica.\r\nGithub Discussion\nBreaking Change to Supabase Platform Access Control#\nOn July 26, 2024, Supabase will be making breaking changes to our platformâ€™s access control system. Developer and Read-Only roles will no longer have write access to an organizationâ€™s GitHub and Vercel integrations. These changes will not affect existing integrations that are in place.\r\nGithub Discussion\nChange to Retention of Paused Free Tier Projects#\nStarting June 24, 2024, paused Free Tier projects are restorable for 90 days. There is a grace period where all paused projects will continue to be restorable until September 22, 2024.\r\nGithub Discussion\nBilling Improvements#\n\nWeâ€™ve made significant improvements to our billing system to help you better understand compute pricing. These changes aim to prevent unexpected charges and provide clarity on â€œCompute Hours.â€\r\nGithub Discussion\nQuick product announcements#\n[Edge Functions] Weâ€™ve implemented some key updates to Edge Functions, including adding Deno 1.43 support [Github Discussion]\nNew Engineering and Troubleshooting Guides#\n\n\nHow Postgres chooses which index to use\nUsing SQLAlchemy with Supabase\nSupabase & Your Network: IPv4 and IPv6 compatibility\nUnderstanding the Usage Summary on the Dashboard\nSupavisor and Connection Terminology Explained\nPrisma Error Management\nHow to change max database connections\nInspecting edge function environment variables\n\nMade with Supabase#\n\nDribble - Flutter NBA name guess game available for iOS and Android [Website]\nEvalHub - an open-source platform for researchers to discover AI evaluation metrics [Website]\nSVGPS - Removes the burden of working with a cluster of SVG files by converting your icons into a single JSON file [Website]\nCleanCoffee - Lean coffee discussion utility where you can create boards and share with friends [Website]\nRewritebar - Improve your writing in any macOS application with AI assistance. Quickly correct grammar mistakes, change writing styles or translate text [Website]\n\nCommunity highlights#\n\nBuilding a Basic Social Network with Remix and Supabase [YouTube]\nNext Level Supabase Techniques For Your Production App! [YouTube]\nBuilding a Local-First React Native App with PowerSync and Supabase [YouTube]\nBuild a Fullstack Job Portal App with Next.js 14, Tailwind, Supabase, Stripe, Clerk [YouTube]\nGenerate Vector Tiles with PostGIS [Blog] [YouTube]\nWe have several updates and new features to share with you this month. Dive in to see whatâ€™s new from Supabase.\nEdge Runtime Inspector Feature (CLI)#\n\nWeâ€™ve introduced the Edge Runtime Inspector, a powerful new feature in the CLI that helps you inspect and debug edge functions more efficiently.\r\nPull Request\nView and Abort Running Queries (Supabase Studio)#\n\nYou can now view and abort queries currently running on your database (primary or replica) in the Supabase Studio SQL Editor. This feature gives you greater control and flexibility in managing your queries.\r\nPull Request\nLogging Integration With The ELK Stack#\nThe Logflare to Elastic filebeat backend has been merged. This integration enables log drains to ELK stacks, providing more robust logging and monitoring capabilities.\r\nDocumentation\nInterpreting Supabase Grafana I/O Charts#\nWe have published a guide on how to use the Supabase I/O charts to identify when you may need to scale your database, optimize your queries, or spin up a read replica.\r\nGithub Discussion\nBreaking Change to Supabase Platform Access Control#\nOn July 26, 2024, Supabase will be making breaking changes to our platformâ€™s access control system. Developer and Read-Only roles will no longer have write access to an organizationâ€™s GitHub and Vercel integrations. These changes will not affect existing integrations that are in place.\r\nGithub Discussion\nChange to Retention of Paused Free Tier Projects#\nStarting June 24, 2024, paused Free Tier projects are restorable for 90 days. There is a grace period where all paused projects will continue to be restorable until September 22, 2024.\r\nGithub Discussion\nBilling Improvements#\n\nWeâ€™ve made significant improvements to our billing system to help you better understand compute pricing. These changes aim to prevent unexpected charges and provide clarity on â€œCompute Hours.â€\r\nGithub Discussion\nQuick product announcements#\n[Edge Functions] Weâ€™ve implemented some key updates to Edge Functions, including adding Deno 1.43 support [Github Discussion]\nNew Engineering and Troubleshooting Guides#\n\nMade with Supabase#\nCommunity highlights#\nDigiCert no longer being used as the CA for Supabase HTTP APIs\nJul 22, 2024\nSupabase HTTP APIs are no longer using DigiCert as the root CA. This should have no impact on the vast majority of environments, as the other CAs in use are essentially universally trusted.\nIf your client environment only trusts certificates signed by DigiCert, you could be impacted. We're currently using Cloudflare to serve our HTTP APIs, and recommend ensuring that any client environment that only trusts a specific subset of CAs trusts all of the CAs Cloudflare uses.\nSupabase HTTP APIs are no longer using DigiCert as the root CA. This should have no impact on the vast majority of environments, as the other CAs in use are essentially universally trusted.\nIf your client environment only trusts certificates signed by DigiCert, you could be impacted. We're currently using Cloudflare to serve our HTTP APIs, and recommend ensuring that any client environment that only trusts a specific subset of CAs trusts all of the CAs Cloudflare uses.\nEdge Functions: Deploy More Functions at No Extra Cost\nJul 18, 2024\nIn an effort to simplify pricing, we are going to remove usage-based billing for the number of Edge Functions in your projects. Instead, we are going for a bigger quota across all plans at no extra costs. We picked the limits to ensure all customers are benefiting from this change.\nFree Plan customers can now create 25 instead of 10 functions without the need to upgrade to a paid Plan.\nFree PlanPro PlanTeam PlanÂ Enterprise PlanBefore10 included100 included, then $10 per additional 100100 included, then $10 per additional 100CustomAfter25 included500 included1000 includedUnlimited\nThis change is effective immediately and in case you were previously exceeding the number of included functions on a paid Plan, you will no longer be charged for it.\nIn an effort to simplify pricing, we are going to remove usage-based billing for the number of Edge Functions in your projects. Instead, we are going for a bigger quota across all plans at no extra costs. We picked the limits to ensure all customers are benefiting from this change.\nFree Plan customers can now create 25 instead of 10 functions without the need to upgrade to a paid Plan.\nThis change is effective immediately and in case you were previously exceeding the number of included functions on a paid Plan, you will no longer be charged for it.\nSupabase Platform Access Control: Organization Permissions Breaking Changes on July 26, 2024\nJul 15, 2024\nThese breaking changes are rolling out on July 26, 2024 and affects all organizations that have members assigned either the Developer or Read-Only roles.\nAll Supabase organizations invite users and assign them to one of the following roles as part of membership to an organization:\n\nOwner\nAdministrator\nDeveloper\nRead-Only (available only on Team and Enterprise plans).\n\nDepending on the role, members are authorized to access a specific set of the organization's resources, such as permission to create a new project or change the billing email.\nWe recently re-evaluated the access that the Developer and Read-Only roles have and decided to implement changes to restrict them on a couple of resources to improve your organizations' security.\nOn July 26, 2024, we will turn off certain access that the Developer and Read-Only roles currently have to your organization's resources. The following table is to illustrate the breaking changes that will be going into effect:\nResourceActionDeveloperRead-OnlyIntegrations1Authorize GitHub-âœ…Â â†’ âŒâœ…Â â†’ âŒAdd GitHub Repositories-âœ…Â â†’ âŒâœ…Â â†’ âŒGitHub ConnectionsDeleteâœ…Â â†’ âŒâŒ2Vercel ConnectionsUpdateâœ…Â â†’ âŒâŒ2Deleteâœ…Â â†’ âŒâŒ2\nYou can learn more about our Platform Access Control here: https://supabase.com/docs/guides/platform/access-control.\nIf you have any questions or concerns please contact support.\nFootnotes#\n\n\nExisting integrations will continue to work. â†©\n\n\nRole's permission to the resource and action will remain the same. â†© â†©2 â†©3\nThese breaking changes are rolling out on July 26, 2024 and affects all organizations that have members assigned either the Developer or Read-Only roles.\nAll Supabase organizations invite users and assign them to one of the following roles as part of membership to an organization:\nDepending on the role, members are authorized to access a specific set of the organization's resources, such as permission to create a new project or change the billing email.\nWe recently re-evaluated the access that the Developer and Read-Only roles have and decided to implement changes to restrict them on a couple of resources to improve your organizations' security.\nOn July 26, 2024, we will turn off certain access that the Developer and Read-Only roles currently have to your organization's resources. The following table is to illustrate the breaking changes that will be going into effect:\nYou can learn more about our Platform Access Control here: https://supabase.com/docs/guides/platform/access-control.\nIf you have any questions or concerns please contact support.\nFootnotes#\n\n\nExisting integrations will continue to work. â†©\n\n\nRole's permission to the resource and action will remain the same. â†© â†©2 â†©3\nFootnotes#\nExisting integrations will continue to work. â†©\nRole's permission to the resource and action will remain the same. â†© â†©2 â†©3\nDashboard Weekly Updates [08/07/24 - 15/07/24]\nJul 15, 2024\nOption to use a dedicated api schema for your project#\n\nBy default, the public schema is used to generate API routes for your database. In some cases, it's better to use a custom schema - this is important if you use tools that generate tables in the public schema to prevent accidental exposure of your data.\nThe dashboard supports this workflow through 2 options: either at the project creation step under \"Security Options\", or in the project's API settings after your project has been created. More information about this workflow in our documentation here!\nLink: https://supabase.com/dashboard/project/_/settings/api\nPR: https://github.com/supabase/supabase/pull/27918\nOther bug fixes and improvements#\nSQL Editor\n\nText area under AI assistant is now expandable for better UX with multi-line prompts (PR)\n\nDatabase\n\nAdded placeholder for function body editor section to hint the syntax if language selected is plpgsql (PR)\n\nLogs Explorer\n\nFixed logs explorer placeholder query for local set up (PR)\nOption to use a dedicated api schema for your project#\n\nBy default, the public schema is used to generate API routes for your database. In some cases, it's better to use a custom schema - this is important if you use tools that generate tables in the public schema to prevent accidental exposure of your data.\nThe dashboard supports this workflow through 2 options: either at the project creation step under \"Security Options\", or in the project's API settings after your project has been created. More information about this workflow in our documentation here!\nLink: https://supabase.com/dashboard/project/_/settings/api\nPR: https://github.com/supabase/supabase/pull/27918\nOther bug fixes and improvements#\nSQL Editor\nDatabase\nLogs Explorer\nPostgres 13 Deprecation Notice\nJul 12, 2024\nSupabase support for Postgres 13 is being deprecated as of 15th July 2024, and support for it will be fully removed on 15th November 2024.\nAll Postgres 13 projects should be upgraded to Postgres 15 before 15th November, 2024.\nAny projects still on Postgres 13 after the 15th of November 2024 will be automatically upgraded to Postgres 15. If any Postgres extensions or functions are in use that cause the upgrade process to fail, a backup will be taken instead, and the project will be paused.\nPostgres 15 comes with numerous features, bug fixes and performance improvements. Check out the announcement blog posts to find out what each version introduces.\n\nPostgres 14 Launch\nPostgres 15 Launch\n\nDeprecation Timeline#\n\n15th July: All users are notified via email about Postgres 13 Deprecation. Users can self-serve upgrade to Postgres 15 from our dashboard.\n30th September: Users are reminded of impending deprecation via email.\n30th October: Users are sent a final email reminder.\n15th November: Any remaining projects on PG13 start getting migrated to PG15 (or paused, if there are upgrade issues).\nSupabase support for Postgres 13 is being deprecated as of 15th July 2024, and support for it will be fully removed on 15th November 2024.\nAll Postgres 13 projects should be upgraded to Postgres 15 before 15th November, 2024.\nAny projects still on Postgres 13 after the 15th of November 2024 will be automatically upgraded to Postgres 15. If any Postgres extensions or functions are in use that cause the upgrade process to fail, a backup will be taken instead, and the project will be paused.\nPostgres 15 comes with numerous features, bug fixes and performance improvements. Check out the announcement blog posts to find out what each version introduces.\nDeprecation Timeline#\nDashboard Weekly Updates [01/07/24 - 08/07/24]\nJul 9, 2024\nOption to disable Data API when creating projects#\n\nYou can now opt to disable the Data API when creating a new project under a section called \"Advanced Options\", such that you will only be able to connect to your database via connection string. Note that this setting can be subsequently updated again in the project's API settings if and when you want to connect your project via the client libraries.\nPR: https://github.com/supabase/supabase/pull/26809\nLink: https://supabase.com/dashboard/new/_\nAuthorization for Realtime is now available!#\n\nYou can now control client access to Realtime Broadcast and Presence by adding Row Level Security policies to the realtime.messages table! Read more about through our documentation here!\nPR: https://github.com/supabase/supabase/pull/27362\nLink: https://supabase.com/dashboard/project/_/realtime/inspector\\\nOptimizations for table editor row count query#\n\nPreviously, the Table Editor on the dashboard would run a select count(*) from table query to retrieve the number of rows in the table and display it in the editor (this also supports the pagination logic as well). However, understandably this query can be resource intensive and expensive if the table in question is particularly large. As such, we've chucked some optimizations around this logic to only retrieve the exact row count if the table has less than 50k rows, otherwise we'll retrieve an estimate of the row count instead. You'll still be able to get the exact row count but on demand instead.\nPR: https://github.com/supabase/supabase/pull/27612\nLink: https://supabase.com/dashboard/project/_/editor\nSupport showing all entity types in the database/tables page#\n\nPR: https://github.com/supabase/supabase/pull/27749\nLink: https://supabase.com/dashboard/project/_/database/tables\nOther improvements and bug fixes#\nGeneral\n\nMore granular project statuses for pausing and restoration (PR)\nSupport filtering projects by status (either active or paused) (PR)\n\nAccount\n\nAdded instructions on how to change your email for your account (PR)\n\nStorage\n\nFix uploading a folder to the storage explorer causes all files to be uploaded in a flat list with the folder name prefixed to the file name (PR)\n\nTable Editor\n\nOptimized table editor select query when cutting off column values (PR)\n\nSQL Editor\n\nAdded labels and grid to SQL editor charts (PR)\nOption to disable Data API when creating projects#\nYou can now opt to disable the Data API when creating a new project under a section called \"Advanced Options\", such that you will only be able to connect to your database via connection string. Note that this setting can be subsequently updated again in the project's API settings if and when you want to connect your project via the client libraries.\nPR: https://github.com/supabase/supabase/pull/26809\nLink: https://supabase.com/dashboard/new/_\nAuthorization for Realtime is now available!#\n\nYou can now control client access to Realtime Broadcast and Presence by adding Row Level Security policies to the realtime.messages table! Read more about through our documentation here!\nPR: https://github.com/supabase/supabase/pull/27362\nLink: https://supabase.com/dashboard/project/_/realtime/inspector\\\nOptimizations for table editor row count query#\nPreviously, the Table Editor on the dashboard would run a select count(*) from table query to retrieve the number of rows in the table and display it in the editor (this also supports the pagination logic as well). However, understandably this query can be resource intensive and expensive if the table in question is particularly large. As such, we've chucked some optimizations around this logic to only retrieve the exact row count if the table has less than 50k rows, otherwise we'll retrieve an estimate of the row count instead. You'll still be able to get the exact row count but on demand instead.\nPR: https://github.com/supabase/supabase/pull/27612\nLink: https://supabase.com/dashboard/project/_/editor\nSupport showing all entity types in the database/tables page#\n\nPR: https://github.com/supabase/supabase/pull/27749\nLink: https://supabase.com/dashboard/project/_/database/tables\nOther improvements and bug fixes#\nGeneral\nAccount\nStorage\nTable Editor\nSQL Editor\nDashboard Weekly Updates [17/06/24 - 24/06/24]\nJun 24, 2024\nGreater clarity on costs when creating new projects#\n\nOne of our bigger papercuts in terms of billing is customers not understand compute pricing and that they cannot launch unlimited projects for $25 in total per month. Customers also get confused with \"Compute Hours\" on their bill. The changes aim to alleviate any \"surprise\" compute charges and serves as kaizen improvement.\nChanges involved are only applicable to paid plan organizations, as it's irrelevant for free plan organizations.\nPR: https://github.com/supabase/supabase/pull/27268\nLink: https://supabase.com/dashboard/new/_\nAddress Table Editor \"resorting\" of rows when rows are updated and no active sorts applied#\nIf you've tried updating a table via the Table Editor without an active sort in place, you'd have noticed that the rows seem to re-sort themselves, specifically the row that you were updating. While this is because rows are returned in an unspecified order without a sort clause from the select query, it certainly must've been a confusing UX. We've alleviated this problem by setting a default sort by clause when reading the table via the Table Editor, which will get overriden once you've set a sort via the UI.\nPR: https://github.com/supabase/supabase/pull/27097\nLink: https://supabase.com/dashboard/project/_/editor\nOther improvements and bug fixes#\nGeneral\n\nGreater granularity in project statuses, specifically for when project is restoring, when restoring failed and when pausing failed (PR)\n\nDatabase\n\nTable searching is now case in-sensitive (PR)\nAdd duplicate table CTA (Similar to the Table Editor) (PR)\n\nSQL Editor\n\nAuto limit fix for when SQL query has \"fetch first n rows only\" (PR)\nPreserve whitespace in results (PR)\n\nQuery Performance\n\nSupport index advisor for queries from Postgrest (PR)\n\nOrg Billing\n\nUsers can now only manage a single tax ID instead of multiple (PR)\nGreater clarity on costs when creating new projects#\nOne of our bigger papercuts in terms of billing is customers not understand compute pricing and that they cannot launch unlimited projects for $25 in total per month. Customers also get confused with \"Compute Hours\" on their bill. The changes aim to alleviate any \"surprise\" compute charges and serves as kaizen improvement.\nChanges involved are only applicable to paid plan organizations, as it's irrelevant for free plan organizations.\nPR: https://github.com/supabase/supabase/pull/27268\nLink: https://supabase.com/dashboard/new/_\nAddress Table Editor \"resorting\" of rows when rows are updated and no active sorts applied#\nIf you've tried updating a table via the Table Editor without an active sort in place, you'd have noticed that the rows seem to re-sort themselves, specifically the row that you were updating. While this is because rows are returned in an unspecified order without a sort clause from the select query, it certainly must've been a confusing UX. We've alleviated this problem by setting a default sort by clause when reading the table via the Table Editor, which will get overriden once you've set a sort via the UI.\nPR: https://github.com/supabase/supabase/pull/27097\nLink: https://supabase.com/dashboard/project/_/editor\nOther improvements and bug fixes#\nGeneral\nDatabase\nSQL Editor\nQuery Performance\nOrg Billing\nPaused Free Plan projects are restorable for 90 days\nJun 24, 2024\nThis only impacts projects on the Free Plan because projects in any of the paid plans cannot be paused.\nBeginning June 24, 2024, we're updating some project pause/restore behavior:\n\npaused Free projects are restorable for 90 days following their pause date\nany Free projects paused before June 24 will be able to restore at any point before September 22, 2024 so they have a full 90 days from when this announcement is made\nonce a project is no longer restorable, the \"restore\" option is replaced with an option to download the latest logical backup, taken right before the project is paused, and all Storage objects\n\nThis change is being made to enable us to maintain high development velocity on the platform. Previously, paused projects could be restored indefinitely. That creates the need for the platform to remain fully backwards compatible with outdated versions of Postgres and associated extensions. The update allows us to provide a reasonable pause/restore window while gaining the ability to evolve the platform.\nThis only impacts projects on the Free Plan because projects in any of the paid plans cannot be paused.\nBeginning June 24, 2024, we're updating some project pause/restore behavior:\nThis change is being made to enable us to maintain high development velocity on the platform. Previously, paused projects could be restored indefinitely. That creates the need for the platform to remain fully backwards compatible with outdated versions of Postgres and associated extensions. The update allows us to provide a reasonable pause/restore window while gaining the ability to evolve the platform.\nEdge Functions are now Deno 1.43 compatible\nJun 18, 2024\n[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nSupabase Edge Runtime version 1.54  is compatible with Deno 1.43.\nSupabase's hosted platform was upgraded to use this release when serving Edge Functions starting today.\nIf you're using Supabase CLI for local development latest stable release 1.176.10, it adds compatibility for Deno 1.43.\nHow do I find which version of Edge Runtime I'm running?#\nSupabase CLI (local)#\nWhen you run supabase functions serve, it should show the current version of Edge Runtime used (and its Deno compatibility)\n1> supabase functions serve23Setting up Edge Functions runtime...4Serving functions on http://127.0.0.1:54321/functions/v1/<function-name>5Using supabase-edge-runtime-1.54.2 (compatible with Deno v1.43.0)\nHosted Platform#\nYou can check the served_by field in log events to see which Edge Runtime version was used to serve your function\r\n.\r\n\nWe try our best to maintain backward compatibility in these upgrades. If you're experiencing any issues, please feel free to make a support request\nSupabase Edge Runtime version 1.54  is compatible with Deno 1.43.\nSupabase's hosted platform was upgraded to use this release when serving Edge Functions starting today.\nIf you're using Supabase CLI for local development latest stable release 1.176.10, it adds compatibility for Deno 1.43.\nHow do I find which version of Edge Runtime I'm running?#\nSupabase CLI (local)#\nWhen you run supabase functions serve, it should show the current version of Edge Runtime used (and its Deno compatibility)\nHosted Platform#\nYou can check the served_by field in log events to see which Edge Runtime version was used to serve your function\r\n.\nWe try our best to maintain backward compatibility in these upgrades. If you're experiencing any issues, please feel free to make a support request\nDeveloper Updates - May 2024\nJun 18, 2024\nSupabase underwent Consolidation Monthâ„¢ to focus on initiatives that improve the stability, scalability, and security of our products. We also have exciting product announcements that we canâ€™t wait to share. Letâ€™s dive in!\nConsolidation Monthâ„¢#\nWe kicked off Consolidation Month (no itâ€™s not actually trademarked) during the month of May. During this time, every product team within Supabase addressed outstanding performance and stability issues of existing features. Hereâ€™s a small subset of initiatives and product announcements as part of Consolidation Month:\nAuth Launches @supabase/ssr for Better SSR Framework Support#\n\nThe newly released @supabase/ssr package improves cookie management, developer experience, and handling of edge cases in various SSR and CSR contexts. Weâ€™ve added extensive testing to prevent issues that users experienced with the @supabase/auth-helpers package.\nAnnouncement\npgvector v0.7.0 Release Features Significant Performance Improvements#\n\npgvector v0.7.0 introduced float16 vectors that further improve HNSW build times by 30% while reducing shared memory and disk space by 50% when both index and underlying table use 16-bit float. The latest version also adds sparse and bit vectors as well as L1, Hamming, and Jaccard distance functions.\nAnnouncement\nEdge Functions Improves Memory Handling#\n\nThe Edge Functions team has significantly reduced the error rate for functions encountering memory issues by implementing better safeguards. This has greatly minimized errors with the 502 status code. Additionally, status codes and limits are now documented separately.\nStatus Codes | Limits\nDashboard Supports Bigger Workloads as Projects Grow#\n\nThe Supabase Dashboard is now better equipped to handle your projects, regardless of their size. We have implemented sensible defaults for the amount of data rendered and returned in the Table and SQL Editors to prevent browser performance issues while maintaining a snappy user experience.\nAnnouncement\nRealtime Standardizes Error Codes#\n\nRealtime now emits standardized error codes, providing descriptions of their meanings and suggested actions. This enhancement improves your error-handling code and helps to narrow down whether the issue lies with the database, Realtime service, or client error.\nRealtime Error Codes\nRLS AI Assistant v2#\n\nWeâ€™ve improved the prompt and output of our RLS AI Assistant by including best practices found in our RLS docs and upgrading to OpenAIâ€™s newest GPT-4o. Weâ€™ve also introduced numerous test scenarios to make sure youâ€™re getting the right security and performance recommendations by comparing parsed SQL with the help of pg_query.\nPull Request\nQuick product announcements#\n[Functions] JSR modules are supported in Edge Functions & Edge Runtime\r\n[Announcement][Functions] Debug Edge Functions with Chrome DevTools\r\n[Docs][Functions] Use HonoJS web Framework with Edge Functions\r\n[Docs][Analytics] Log Drains is in Private Alpha\r\n[Announcement][Realtime] Realtime Authorization Early Access\r\n[Announcement][Docs] SQL to PostgREST API Translator\r\n[Docs][Client libs] Supabase JavaScript SDK Sentry Integration now supports Sentry SDK v8\r\n[Commit]\nMade with Supabase#\nGroupUp - organize social gatherings to hang out with friends [Website]HabitKit - track habits, view daily progress, and stay motivated as you work towards your goals [Website]Meteron AI - LLM and generative AI metering, load-balancing and storage [Website]EQMonitor - An app that displays and notifies earthquake information in Japan [Website]GitAuto - AI software engineer that writes, reads, and creates pull requests [Website]GenPPT - Free AI powerpoint presentation generator to help you create beautiful slides in minutes [Website]\nCommunity highlights#\nMake your queries 43,240x faster [Video]Exploring Support Tooling at Supabase: A Dive into SLA Buddy [Article]FlutterFlow SuperApp Complex Template : Developing Feed with Supabase [Video]How We Use Supabase in Betashares Direct [Video]AI Assistant to Chat with Supabase Database [Video]How to use wrappers in Supabase [Video]Build Realtime Apps with Next.js and Supabase [Video]SvelteKit & Supabase Project Build [Video]Next.js 14 x Supabase â€” Build a Team component using shadcn [Article]Create a Real Time Chat App with Supabase and Angular [Article]\n\nThis discussion was created from the release Developer Updates - May 2024.\nSupabase underwent Consolidation Monthâ„¢ to focus on initiatives that improve the stability, scalability, and security of our products. We also have exciting product announcements that we canâ€™t wait to share. Letâ€™s dive in!\nConsolidation Monthâ„¢#\nWe kicked off Consolidation Month (no itâ€™s not actually trademarked) during the month of May. During this time, every product team within Supabase addressed outstanding performance and stability issues of existing features. Hereâ€™s a small subset of initiatives and product announcements as part of Consolidation Month:\nAuth Launches @supabase/ssr for Better SSR Framework Support#\n\nThe newly released @supabase/ssr package improves cookie management, developer experience, and handling of edge cases in various SSR and CSR contexts. Weâ€™ve added extensive testing to prevent issues that users experienced with the @supabase/auth-helpers package.\nAnnouncement\npgvector v0.7.0 Release Features Significant Performance Improvements#\n\npgvector v0.7.0 introduced float16 vectors that further improve HNSW build times by 30% while reducing shared memory and disk space by 50% when both index and underlying table use 16-bit float. The latest version also adds sparse and bit vectors as well as L1, Hamming, and Jaccard distance functions.\nAnnouncement\nEdge Functions Improves Memory Handling#\n\nThe Edge Functions team has significantly reduced the error rate for functions encountering memory issues by implementing better safeguards. This has greatly minimized errors with the 502 status code. Additionally, status codes and limits are now documented separately.\nStatus Codes | Limits\nDashboard Supports Bigger Workloads as Projects Grow#\n\nThe Supabase Dashboard is now better equipped to handle your projects, regardless of their size. We have implemented sensible defaults for the amount of data rendered and returned in the Table and SQL Editors to prevent browser performance issues while maintaining a snappy user experience.\nAnnouncement\nRealtime Standardizes Error Codes#\n\nRealtime now emits standardized error codes, providing descriptions of their meanings and suggested actions. This enhancement improves your error-handling code and helps to narrow down whether the issue lies with the database, Realtime service, or client error.\nRealtime Error Codes\nRLS AI Assistant v2#\n\nWeâ€™ve improved the prompt and output of our RLS AI Assistant by including best practices found in our RLS docs and upgrading to OpenAIâ€™s newest GPT-4o. Weâ€™ve also introduced numerous test scenarios to make sure youâ€™re getting the right security and performance recommendations by comparing parsed SQL with the help of pg_query.\nPull Request\nQuick product announcements#\n[Functions] JSR modules are supported in Edge Functions & Edge Runtime\r\n[Announcement]\n[Functions] Debug Edge Functions with Chrome DevTools\r\n[Docs]\n[Functions] Use HonoJS web Framework with Edge Functions\r\n[Docs]\n[Analytics] Log Drains is in Private Alpha\r\n[Announcement]\n[Realtime] Realtime Authorization Early Access\r\n[Announcement]\n[Docs] SQL to PostgREST API Translator\r\n[Docs]\n[Client libs] Supabase JavaScript SDK Sentry Integration now supports Sentry SDK v8\r\n[Commit]\nMade with Supabase#\nCommunity highlights#\nDashboard Weekly Updates [03/06/24 - 10/06/24]\nJun 11, 2024\nYou might be wondering what we've been up to the past few weeks when we'd usually have some cadence in our weekly updates with our GitHub discussion updates - the team at Supabase had decided to commit to a month of consolidation by putting our efforts into each of the following pillars: Alerting, Testing, and Scaling. Let's jump right in to see what this means for the Dashboard! ðŸ’ªðŸ»\nðŸš¨Â Alerts: Enabling proactive resolution to issues that users run into#\nWe want to find out about bugs before you do. In an effort to lower the time between deploying a bug and fixing it, weâ€™ve set up some alerts that will enable us to be more proactively catch bugs, in particular for show-stopping problems (e.g that awful â€œA client side exception has occurredâ€ screen)!\n\nAdded alerts for critical points of failures (PR)\r\nThis includes any errors that will completely prevent you from using the Supabase dashboard.\nAdded alerts for full page client crash events with a custom error boundary (PR)\r\nHaving a custom error boundary also allows us to potentially provide contextual hints/resolutions to the problem faced, such as what we did in this PR.\n\nðŸ› ï¸Â Testing: Identifying and covering critical points of failure#\nWe believe in ensuring that minimally our critical paths are covered by tests as opposed to ensuring our dashboard has 100% test coverage. Anything that might completely block our users from doing what they need to do should be caught as much as possible before reaching production.\n\nMoved to Vitest + Integrating packages to make writing tests easier (PR)\r\nWeâ€™ve revamped our current test set up to use Vitest instead of Jest and have integrated Mock Service Workers (MSW) and next-router-mock. These are all to support writing better tests easier, and also to reduce the amount of configuration we need to set up the tests.\nExpanded on Playwright for E2E tests (PR)\r\nWe previously had a couple of Playwright tests written over in our tests repository that weâ€™ve decided to shift over to our main repository. Weâ€™re also in the midst of writing more tests and making them public\n\nðŸ“ˆÂ Scaling: Supporting bigger workloads as the project grows#\nThe dashboard should be able to keep up with your projects, no matter how big they grow - and even if unable to, it should never block you, or leave you feeling confused. This effort involved several solutions: gracefully failing if unable to handle large workloads, better observability, or even just better error handling to allow our users to self-service most errors. We were able to get improvements out for several common issues. Check out each individual PR for more information ðŸ˜„\n\nRendering large column data within the Table Editor (PR)\r\nWeâ€™re now limiting rendering each text/JSON based column data in the table editor at a max of 10kB when initially viewing the table, which should alleviate browser performance issues when rendering tables with large row data. You may load the entire column data on demand instead.\nHandling large results within the SQL editor (PR)\r\nA limit parameter will now be added as a suffix to select queries that are run in the SQL editor, which should prevent the browser performance from degrading when trying to query too much data. The limit parameter can be optionally removed if your intention might be to pull data in greater quantity.\nView ongoing queries in the SQL editor and support terminating them (PR)\r\nThis came in response to a user who accidentally ran a large query through the SQL editor which ended up in the API request timing out, giving the impression that the query stopped running when in fact it was still running on the database in the background. This should help surface such problems and give the tooling required to abort erroneous queries.\nContextual errors when something goes wrong (PR)\r\nWhile the attached PR was more of a POC, this is the direction we want to move towards to by providing contextual information and suggest possible resolutions whenever users run into an error\n\nOf course consolidation is not a one time event, but an ongoing effort that our team is committing to in parallel to shipping new and exciting features. We hope that as our users, you will all be able to benefit from this with less blockers to keep you from building cool stuff ðŸ™‚\nAs always, if you have any feedback for us - we're just a message away through the feedback widget to the top right corner of the dashboard! We're always listening ðŸ‘‚ðŸ» (as in reading ðŸ‘€).\nYou might be wondering what we've been up to the past few weeks when we'd usually have some cadence in our weekly updates with our GitHub discussion updates - the team at Supabase had decided to commit to a month of consolidation by putting our efforts into each of the following pillars: Alerting, Testing, and Scaling. Let's jump right in to see what this means for the Dashboard! ðŸ’ªðŸ»\nðŸš¨Â Alerts: Enabling proactive resolution to issues that users run into#\nWe want to find out about bugs before you do. In an effort to lower the time between deploying a bug and fixing it, weâ€™ve set up some alerts that will enable us to be more proactively catch bugs, in particular for show-stopping problems (e.g that awful â€œA client side exception has occurredâ€ screen)!\nðŸ› ï¸Â Testing: Identifying and covering critical points of failure#\nWe believe in ensuring that minimally our critical paths are covered by tests as opposed to ensuring our dashboard has 100% test coverage. Anything that might completely block our users from doing what they need to do should be caught as much as possible before reaching production.\nðŸ“ˆÂ Scaling: Supporting bigger workloads as the project grows#\nThe dashboard should be able to keep up with your projects, no matter how big they grow - and even if unable to, it should never block you, or leave you feeling confused. This effort involved several solutions: gracefully failing if unable to handle large workloads, better observability, or even just better error handling to allow our users to self-service most errors. We were able to get improvements out for several common issues. Check out each individual PR for more information ðŸ˜„\nOf course consolidation is not a one time event, but an ongoing effort that our team is committing to in parallel to shipping new and exciting features. We hope that as our users, you will all be able to benefit from this with less blockers to keep you from building cool stuff ðŸ™‚\nAs always, if you have any feedback for us - we're just a message away through the feedback widget to the top right corner of the dashboard! We're always listening ðŸ‘‚ðŸ» (as in reading ðŸ‘€).\n@supabase/ssr updates and roadmap towards v1.0.0\nJun 5, 2024\n[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nGo here for latest update\nHey everyone,\nI'm Stojan a member of the Supabase Auth team, bringing some updates about what's next with @supabase/ssr. This is the recommended package that helps you use the Supabase JavaScript client with SSR frameworks such as NextJS, Remix, SvelteKit and others.\nWe've been quite busy recently gathering feedback, reviewing common complaints and bugs with the package, and using it in the popular SSR frameworks. We've identified a few areas needing improvement and we've already started implementing them.\nThe package is still on major version 0, indicating its beta status. We plan to move it to major version 1 in the coming months making it the preferred way of using the Supabase JavaScript library in your favorite SSR framework.\nFirst, we'll extract @supabase/ssr's code from the auth-helpers repository into its own. Weâ€™re doing this because:\n\n@supabase/auth-helpers-x (like for NextJS) is no longer supported by the team, as we expect people to move to @supabase/ssr.\nIt's no longer about \"auth-helpers,\" but rather about how you can most effectively and ergonomically use the Supabase Client in various SSR and CSR contexts.\nA standalone repo makes it easier for the community to contribute and for us to track issues.\n\nWe're going to release a fairly ground-up reimplementation of the package. This should come as version 0.4.0 around mid-June. We've received a lot of signal in the past months from developers and the community about possible improvements for developer ergonomics and better handling for edge cases.\nThe reason for this change is because @supabase/ssr is really just a thin layer for cookie management on top of @supabase/supabase-js. We've identified some improvements that reduce odd and difficult-to-diagnose behavior. The new implementation will boast over 90% test coverage, including testing for issues that weâ€™ve seen commonly reported so far.\nAs part of the new implementation, we are changing the API. The old API will be deprecated when we reach v1.0.0. This is to ensure the best possible experience for both developers and users. For most use cases and happy paths, the deprecated API will continue working during the phase-out, but we encourage switching as soon as possible. Once we release v1.0.0, major version 0 will no longer be maintained.\nThe change in the API is quite simple, so hereâ€™s an example of how it will look like. Instead of defining three cookie access methods get, set and remove like so:\n1createServerClient(SUPABASE_URL, SUPABASE_ANON_KEY, {2\tcookies: {3\t\tget: async (name) => {4\t\t\t// ...5\t\t},6\t\tset: async(name, value, options) => {7\t\t\t// ...8\t\t},9\t\tremove: async(name) => {10\t\t\t// ...11\t\t}12\t}13})\nYou would need to define two â€” getAll and setAll cookie access methods like so:\n1createServerClient(SUPABASE_URL, SUPABASE_ANON_KEY, {2\tcookies: {3\t\tgetAll: async() => {4\t\t\t// return all cookies you have access to5\t\t},6\t\tsetAll: async(cookiesToSet: { name: string; value: string; options: CookieOptions; }[]) => {7\t\t\t// set the cookies exactly as they appear in the cookiesToSet array8\t\t}9\t}10})\nNote that for createBrowserClient nothing needs to be done in most cases, it automatically works with the document.cookie API.\nThe change should be trivial for most SSR frameworks, and we'll be sure to update the guides to instruct you on how to change your code into this new way of accessing cookies.\nThanks for all your feedback! Feel free to ask any questions below!\nGo here for latest update\nHey everyone,\nI'm Stojan a member of the Supabase Auth team, bringing some updates about what's next with @supabase/ssr. This is the recommended package that helps you use the Supabase JavaScript client with SSR frameworks such as NextJS, Remix, SvelteKit and others.\nWe've been quite busy recently gathering feedback, reviewing common complaints and bugs with the package, and using it in the popular SSR frameworks. We've identified a few areas needing improvement and we've already started implementing them.\nThe package is still on major version 0, indicating its beta status. We plan to move it to major version 1 in the coming months making it the preferred way of using the Supabase JavaScript library in your favorite SSR framework.\nFirst, we'll extract @supabase/ssr's code from the auth-helpers repository into its own. Weâ€™re doing this because:\nWe're going to release a fairly ground-up reimplementation of the package. This should come as version 0.4.0 around mid-June. We've received a lot of signal in the past months from developers and the community about possible improvements for developer ergonomics and better handling for edge cases.\nThe reason for this change is because @supabase/ssr is really just a thin layer for cookie management on top of @supabase/supabase-js. We've identified some improvements that reduce odd and difficult-to-diagnose behavior. The new implementation will boast over 90% test coverage, including testing for issues that weâ€™ve seen commonly reported so far.\nAs part of the new implementation, we are changing the API. The old API will be deprecated when we reach v1.0.0. This is to ensure the best possible experience for both developers and users. For most use cases and happy paths, the deprecated API will continue working during the phase-out, but we encourage switching as soon as possible. Once we release v1.0.0, major version 0 will no longer be maintained.\nThe change in the API is quite simple, so hereâ€™s an example of how it will look like. Instead of defining three cookie access methods get, set and remove like so:\nYou would need to define two â€” getAll and setAll cookie access methods like so:\nNote that for createBrowserClient nothing needs to be done in most cases, it automatically works with the document.cookie API.\nThe change should be trivial for most SSR frameworks, and we'll be sure to update the guides to instruct you on how to change your code into this new way of accessing cookies.\nThanks for all your feedback! Feel free to ask any questions below!\nLog Drains Private Alpha\nMay 22, 2024\nLog drains is currently private alpha, and is available for Teams and Enterprise customers. We are still firming up the pricing and documentation, however it will likely involve a flat fee and variable egress usage. This will be announced separately through official channels.\nWe will be supporting Datadog as our initial provider.\nThe following destinations are in the works:\n\nElastic/Filebeat\nSyslog\n\nWe are currently onboarding interested customers manually, so please fill out this form to get started: https://forms.supabase.com/logdrains.\nLog drains is currently private alpha, and is available for Teams and Enterprise customers. We are still firming up the pricing and documentation, however it will likely involve a flat fee and variable egress usage. This will be announced separately through official channels.\nWe will be supporting Datadog as our initial provider.\nThe following destinations are in the works:\nWe are currently onboarding interested customers manually, so please fill out this form to get started: https://forms.supabase.com/logdrains.\nUpdated deployment instructions for supabase-grafana monitoring application\nMay 17, 2024\nWe've released a fix to the deployment instructions for the supabase-grafana monitoring application.\nIf you're ingesting the metrics endpoint into your pre-existing managed infrastructure without using the supabase-grafana app, this change does not affect you. If you're running the supabase-grafana app using the docker-compose mechanism, you are also not affected.\nFly applications launched off the repository between December 10, 2023, and May 16, 2024 are impacted, and will experience:\n\nFly application being shut down after periods of inactivity of a few minutes (default Fly.io behaviour)\nHistorical data will not be persisted after such a shutdown\n\nThe fix to the deployment instructions ensures that a persistent volume is created to store the data on, which prevents loss in case of a machine shutdown or restart. Additionally, autoshutdown behaviour is disabled, in order to prevent the app from being paused due to inactivity.\nIn order to fix an existing, already deployed Fly application, you can edit its configuration to disable auto_stop_machines, and create a persistent volume, and mount it at /data (similar to the updated deployment instructions). Please note that as the newly created persistent volume will be empty to start, any existing metrics data will not be preserved as part of this change. If doing so is necessary, you can initially mount it at a separate path, copy the data over, and finally mount it at /data.\nIf you need further help, please reach out to Support via https://supabase.help\nWe've released a fix to the deployment instructions for the supabase-grafana monitoring application.\nIf you're ingesting the metrics endpoint into your pre-existing managed infrastructure without using the supabase-grafana app, this change does not affect you. If you're running the supabase-grafana app using the docker-compose mechanism, you are also not affected.\nFly applications launched off the repository between December 10, 2023, and May 16, 2024 are impacted, and will experience:\nThe fix to the deployment instructions ensures that a persistent volume is created to store the data on, which prevents loss in case of a machine shutdown or restart. Additionally, autoshutdown behaviour is disabled, in order to prevent the app from being paused due to inactivity.\nIn order to fix an existing, already deployed Fly application, you can edit its configuration to disable auto_stop_machines, and create a persistent volume, and mount it at /data (similar to the updated deployment instructions). Please note that as the newly created persistent volume will be empty to start, any existing metrics data will not be preserved as part of this change. If doing so is necessary, you can initially mount it at a separate path, copy the data over, and finally mount it at /data.\nIf you need further help, please reach out to Support via https://supabase.help\nDashboard Weekly Updates [06/05/24 - 13/05/24]\nMay 15, 2024\nConversational AI assistant in the SQL Editor#\n\nThis was previously behind a feature flag but we're now making this available by default, which will replace the existing single prompt UI that you saw previously at the top of the SQL editor. Once again, thank you all so much for the feedback that you've left us - we really appreciate them and they definitely do help in guiding us towards the ideal dashboard experience for everyone. ðŸ™‚ðŸ™\nWe're also aware that the feature preview functionality is missing in the local set up - rest assured we're looking into it and hope to get a fix out soon for everyone!\nPR: https://github.com/supabase/supabase/pull/23142\nLink: https://supabase.com/dashboard/project/_/sql\nA step towards slightly more contextual error messages#\n\nA topic that came up in one of our discussions internally was regarding self-serviceability, and we realised that our error messages could do a much better job than just informing users what the error is about - especially when their errors from Postgres directly and the messages could be slightly cryptic for those not familiar with Postgres (yet ðŸ˜‰). The PR linked here is just a small idea and example for what we plan to do with error messages in the future, by giving users more context about the errors like possible solutions and links to relevant documentation. Hopefully this will make using the dashboard slightly more easier ðŸ™‚\nPR: https://github.com/supabase/supabase/pull/23135\nLink: https://supabase.com/dashboard/project/_/editor\nOther improvements and bug fixes#\nBranching\n\nDisable branch reset while branch is initializing (PR)\n\nDatabase\n\nAllow searching for schema and tables when creating indexes (PR)\nAllow SQL language for writing database functions (PR)\nConversational AI assistant in the SQL Editor#\nThis was previously behind a feature flag but we're now making this available by default, which will replace the existing single prompt UI that you saw previously at the top of the SQL editor. Once again, thank you all so much for the feedback that you've left us - we really appreciate them and they definitely do help in guiding us towards the ideal dashboard experience for everyone. ðŸ™‚ðŸ™\nWe're also aware that the feature preview functionality is missing in the local set up - rest assured we're looking into it and hope to get a fix out soon for everyone!\nPR: https://github.com/supabase/supabase/pull/23142\nLink: https://supabase.com/dashboard/project/_/sql\nA step towards slightly more contextual error messages#\nA topic that came up in one of our discussions internally was regarding self-serviceability, and we realised that our error messages could do a much better job than just informing users what the error is about - especially when their errors from Postgres directly and the messages could be slightly cryptic for those not familiar with Postgres (yet ðŸ˜‰). The PR linked here is just a small idea and example for what we plan to do with error messages in the future, by giving users more context about the errors like possible solutions and links to relevant documentation. Hopefully this will make using the dashboard slightly more easier ðŸ™‚\nPR: https://github.com/supabase/supabase/pull/23135\nLink: https://supabase.com/dashboard/project/_/editor\nOther improvements and bug fixes#\nBranching\nDatabase\nDeveloper Updates - April 2024\nMay 8, 2024\nHereâ€™s everything we shipped during our GA week:\nDay 1 - Supabase is officially launching into General Availability (GA)#\n\nSupabase has moved to General Availability (GA) with over 1 million databases under management and over 2,500 databases launched daily. Weâ€™ve been production ready for years and now we are fully confident that we can help every customer become successful, from weekend projects to enterprise initiatives at organizations like Mozilla, 1Password, and PwC.\nFull announcement | Video announcement | X space\nDay 2 - Supabase Functions now supports AI models#\n\nSupabase Functions has added a native API that makes it easy to run AI models within your functions while removing nasty cold starts. You can use the gte-small embedding model to generate text embeddings or bring your own Ollama server to tap into many more embedding models and Large Language Models (LLMs) like Llama3 and Mistral. Soon weâ€™ll provide hosted Ollama servers so you wonâ€™t have to manage them yourselves for a more seamless experience.\nBlog post | Video announcement | X space\nDay 3 - Supabase Auth now supports Anonymous sign-ins#\n\nSupabase Auth heard your requests and went to work building anonymous sign-ins which enable you to create temporary users that have yet to sign up for your application. This lowers the friction for visitors to use your application while making it easy to convert them to permanent users once theyâ€™re hooked.\nBlog post | Video announcement | X space\nDay 4 - Supabase Storage now supports the S3 protocol#\n\nSupabase Storage already has standard and resumable uploads and now supports the industry standard S3 protocol enabling multipart upload and compatibility with a myriad of tools such as AWS CLI, Clickhouse, and Airbyte for a wide array of use cases.\nBlog post | Video announcement | X space\nDay 5 - Supabase Security & Performance Advisor#\n\nSupabase has managed over 1 million databases over the last four years and has seen all manner of use cases with common pitfalls that weâ€™re helping our customers address with our Security, Performance, and Index Advisors. These Advisors will help to surface and fix insecure database configurations and recommend database and query optimizations to keep your database secure and performant for your mission critical workloads.\nBlog post | Video announcement | X space\nGA Week Hackathon Winners#\n\nWe are delighted that so many high quality projects were submitted but in the end there could only be one Best Overall Project. The decision wasnâ€™t easy but the Supabase panel of judges chose vdbs (vision database SQL) for the honorific. Congratulations ðŸ‘ to @xavimonp who will receive the prize of Apple AirPods.\nFull list of winners | All the submissions\nOne more thing from GA Week#\nJust kidding, thereâ€™s always more than one. Hereâ€™s more awesome things we shipped:\n\nSupabase on the AWS Marketplace\nDatabase branching is now Publicly Available\nSupabase Bootstrap: the fastest way to launch a new project\nSupabase Swift officially supported\nOriole, table storage extension for Postgres, joins Supabase\nFly Postgres, a managed offering from Supabase, is available to everyone for testing\nSupabase GA Week meetups  in 27 cities around the world\nJoin our upcoming Meetup in SF at the a16z office with friends from Ollama and Fly.io\n\nCommunity Highlights#\n\nChanging Databases 5 Times in 48 Hours Boosted Our Launch to 35,000 Views [Article]\nCrazy new Supabase feature: Understand and learn about anonymous users [Video]\nSupport unstructured data in Postgres with JSON columns [Video]\nBuild an AI-powered blogging platform (Next.js, Langchain & CopilotKit) [Article]\nHow to Secure Your Supabase Database and Storage [Blog post]\nSelf-host Protomaps PMTiles onÂ Supabase Storage [Video]\nSupabase Realtime - How to deal with multiplayers in Next.js [Blog post]\nThe Hard Parts of Building an Application, Made Easy with Supabase [Article]\n\n\nThis discussion was created from the release Developer Updates - April 2024.\nHereâ€™s everything we shipped during our GA week:\nDay 1 - Supabase is officially launching into General Availability (GA)#\n\nSupabase has moved to General Availability (GA) with over 1 million databases under management and over 2,500 databases launched daily. Weâ€™ve been production ready for years and now we are fully confident that we can help every customer become successful, from weekend projects to enterprise initiatives at organizations like Mozilla, 1Password, and PwC.\nFull announcement | Video announcement | X space\nDay 2 - Supabase Functions now supports AI models#\n\nSupabase Functions has added a native API that makes it easy to run AI models within your functions while removing nasty cold starts. You can use the gte-small embedding model to generate text embeddings or bring your own Ollama server to tap into many more embedding models and Large Language Models (LLMs) like Llama3 and Mistral. Soon weâ€™ll provide hosted Ollama servers so you wonâ€™t have to manage them yourselves for a more seamless experience.\nBlog post | Video announcement | X space\nDay 3 - Supabase Auth now supports Anonymous sign-ins#\n\nSupabase Auth heard your requests and went to work building anonymous sign-ins which enable you to create temporary users that have yet to sign up for your application. This lowers the friction for visitors to use your application while making it easy to convert them to permanent users once theyâ€™re hooked.\nBlog post | Video announcement | X space\nDay 4 - Supabase Storage now supports the S3 protocol#\n\nSupabase Storage already has standard and resumable uploads and now supports the industry standard S3 protocol enabling multipart upload and compatibility with a myriad of tools such as AWS CLI, Clickhouse, and Airbyte for a wide array of use cases.\nBlog post | Video announcement | X space\nDay 5 - Supabase Security & Performance Advisor#\n\nSupabase has managed over 1 million databases over the last four years and has seen all manner of use cases with common pitfalls that weâ€™re helping our customers address with our Security, Performance, and Index Advisors. These Advisors will help to surface and fix insecure database configurations and recommend database and query optimizations to keep your database secure and performant for your mission critical workloads.\nBlog post | Video announcement | X space\nGA Week Hackathon Winners#\n\nWe are delighted that so many high quality projects were submitted but in the end there could only be one Best Overall Project. The decision wasnâ€™t easy but the Supabase panel of judges chose vdbs (vision database SQL) for the honorific. Congratulations ðŸ‘ to @xavimonp who will receive the prize of Apple AirPods.\nFull list of winners | All the submissions\nOne more thing from GA Week#\nJust kidding, thereâ€™s always more than one. Hereâ€™s more awesome things we shipped:\nCommunity Highlights#\nJSR modules are supported in Edge Functions & Edge Runtime\nMay 7, 2024\n[data-ch-theme=\"supabase\"] {  --ch-t-colorScheme: var(--ch-0);--ch-t-foreground: var(--ch-4);--ch-t-background: var(--ch-16);--ch-t-editor-background: var(--ch-16);--ch-t-editor-foreground: var(--ch-4);--ch-t-editor-rangeHighlightBackground: var(--ch-19);--ch-t-editor-infoForeground: var(--ch-18);--ch-t-editor-selectionBackground: var(--ch-17);--ch-t-tab-activeBackground: var(--ch-16);--ch-t-tab-activeForeground: var(--ch-4);--ch-t-tab-inactiveBackground: var(--ch-21);--ch-t-tab-inactiveForeground: var(--ch-15);--ch-t-tab-border: var(--ch-22);--ch-t-tab-activeBorder: var(--ch-16);--ch-t-editorGroupHeader-tabsBackground: var(--ch-21);--ch-t-editorLineNumber-foreground: var(--ch-20);--ch-t-input-foreground: var(--ch-4);--ch-t-sideBar-foreground: var(--ch-4);--ch-t-list-hoverBackground: var(--ch-25);--ch-t-list-hoverForeground: var(--ch-4); }\nYou can now use JSR packages in your Edge Functions. JSR is a modern package registry for JavaScript and TypeScript created by the Deno team. With JSR support, you can use the latest versions of popular Deno packages like Oak.\nHow to use:\n1import { Application } from \"jsr:@oak/oak/application\";2import { Router } from \"jsr:@oak/oak/router\";\nFor local development, you will need to update Supabase CLI for the version v1.166.1 or above.\nEdge Functions also supports using NPM  and deno.land/x packages. If you are already using them, no changes are needed.\nYou can now use JSR packages in your Edge Functions. JSR is a modern package registry for JavaScript and TypeScript created by the Deno team. With JSR support, you can use the latest versions of popular Deno packages like Oak.\nHow to use:\nFor local development, you will need to update Supabase CLI for the version v1.166.1 or above.\nEdge Functions also supports using NPM  and deno.land/x packages. If you are already using them, no changes are needed.\nDashboard Weekly Updates [22/04/24 - 29/04/24]\nApr 30, 2024\nOther improvements and bug fixes#\nWe've been focusing on improving existing features on the dashboard and fixing some issues over the past week, so while we've got nothing shiny to shout out about, here's still a list of things that we've shipped! ðŸ™‚ As always, feel free to let us know if there's something that you guys really want to see in the dashboard - we'll see how we can make it happen ðŸ˜‰\nGeneral\n\nFeedback widget will not clear its contents when closing until explicitly cleared or submitted [PR]\n\nTable Editor\n\nReinstate link button for foreign keys in table editor side panel [PR]\nFix creating foreign key on new column after changing column's name [PR]\n\nSQL Editor\n\nSet column width of results to be relative to column content length [PR]\n\nAuthentication\n\nAdded Create policy CTA under each table for convenience [PR]\n\nStorage\n\nAdded file size validation against project's upload limit when uploading files in dashboard [PR]\n\nDatabase\n\nQuery performance: Fix searching via role and query [PR]\nQuery performance: Add db inspect docs link for visibility to aid in helping identify potential Postgres issues [PR]\nEnumerated types: clean up form field when reopening create enumerated type panel [PR]\nTables: Add ellipses to table descriptions to prevent odd wrapping for long descriptions [PR]\nOther improvements and bug fixes#\nWe've been focusing on improving existing features on the dashboard and fixing some issues over the past week, so while we've got nothing shiny to shout out about, here's still a list of things that we've shipped! ðŸ™‚ As always, feel free to let us know if there's something that you guys really want to see in the dashboard - we'll see how we can make it happen ðŸ˜‰\nGeneral\nTable Editor\nSQL Editor\nAuthentication\nStorage\nDatabase\nDashboard Weekly Updates [15/04/24 - 22/04/24]\nApr 22, 2024\nSupabase GA Week just wrapped up but the shipping doesn't! This just summarises what have been shipped over the last week - and more ðŸ˜‰\nAuth support for anonymous sign-ins#\n\nSupabase Auth now supports anonymous sign-ins, which can be used to create temporary users who havenâ€™t signed up for your application yet! This lowers the friction for new users to try out your product since they donâ€™t have to provide any signup credentials.\nRead more about this here\nPR: https://github.com/supabase/supabase/issues/21813\nLink: https://supabase.com/dashboard/project/_/settings/auth\nStorage support for S3 protocol#\n\nSupabase Storage is now officially an S3-Compatible Storage Provider, and now you can use any S3 client to interact with your buckets and files: upload with TUS, serve them with REST, and manage them with the S3 protocol.\nRead more about this here\nPR: https://github.com/supabase/supabase/issues/22620\nLink: http://supabase.com/dashboard/project/_/settings/storage\n3 new advisors to your database#\n\nWe've added a Security Advisor, a Performance Advisor and a bonus Index Advisor as tools that can help improve your database, more specifically:\n\nSecurity Advisor: for detecting insecure database configuration\nPerformance Advisor: for suggesting database optimizations\nIndex Advisor: for suggesting indexes on slow-running queries\n\nRead more about them here!\nPR: https://github.com/supabase/supabase/issues/22842\nLink: http://supabase.com/dashboard/project/_/database/security-advisor\n4 new database foreign data wrappers#\n\nWe've added support for data wrappers with Auth0, Cognito, Microsoft SQL Server, and Redis! Connect to these external data sources and query them directly from your database.\nPR: https://github.com/supabase/supabase/pull/22289\nLink: https://supabase.com/dashboard/project/_/database/wrappers\nUpdating of some projects pages to more appropriate sections#\n\nWe've renamed and shifted a couple of pages within a project to sections which we believe are more appropriate and relevant. These include:\n\nColumn Priveleges: Shifted from Auth section to Database section\nDatabase Replications: Renamed to Publications within the Database section\nQuery Performance Reports: Shifted from Reports section to Database section\n\nWe've also added more appropriate sections within the Database section in hopes to make things easier to find!\nPR: https://github.com/supabase/supabase/issues/22835\nLink: https://supabase.com/dashboard/project/_\nAn option to submit a request to delete your account#\n\nIf comes the day that you'd no longer want to use Supabase anymore (hopefully not!) and want to be removed from our systems entirely, feel free to submit a request to delete your account through the account preferences page.\nPR: https://github.com/supabase/supabase/pull/22486\nLink: [https://supabase.com/dashboard/account/me](https://supabase.com/dashboard/account/me\nOther improvements and bug fixes#\nGeneral\n\nAdded project connection instructions for Vite [PR]\nSupabase GA Week just wrapped up but the shipping doesn't! This just summarises what have been shipped over the last week - and more ðŸ˜‰\nAuth support for anonymous sign-ins#\n\nSupabase Auth now supports anonymous sign-ins, which can be used to create temporary users who havenâ€™t signed up for your application yet! This lowers the friction for new users to try out your product since they donâ€™t have to provide any signup credentials.\nRead more about this here\nPR: https://github.com/supabase/supabase/issues/21813\nLink: https://supabase.com/dashboard/project/_/settings/auth\nStorage support for S3 protocol#\n\nSupabase Storage is now officially an S3-Compatible Storage Provider, and now you can use any S3 client to interact with your buckets and files: upload with TUS, serve them with REST, and manage them with the S3 protocol.\nRead more about this here\nPR: https://github.com/supabase/supabase/issues/22620\nLink: http://supabase.com/dashboard/project/_/settings/storage\n3 new advisors to your database#\n\nWe've added a Security Advisor, a Performance Advisor and a bonus Index Advisor as tools that can help improve your database, more specifically:\nRead more about them here!\nPR: https://github.com/supabase/supabase/issues/22842\nLink: http://supabase.com/dashboard/project/_/database/security-advisor\n4 new database foreign data wrappers#\n\nWe've added support for data wrappers with Auth0, Cognito, Microsoft SQL Server, and Redis! Connect to these external data sources and query them directly from your database.\nPR: https://github.com/supabase/supabase/pull/22289\nLink: https://supabase.com/dashboard/project/_/database/wrappers\nUpdating of some projects pages to more appropriate sections#\n\nWe've renamed and shifted a couple of pages within a project to sections which we believe are more appropriate and relevant. These include:\nWe've also added more appropriate sections within the Database section in hopes to make things easier to find!\nPR: https://github.com/supabase/supabase/issues/22835\nLink: https://supabase.com/dashboard/project/_\nAn option to submit a request to delete your account#\n\nIf comes the day that you'd no longer want to use Supabase anymore (hopefully not!) and want to be removed from our systems entirely, feel free to submit a request to delete your account through the account preferences page.\nPR: https://github.com/supabase/supabase/pull/22486\nLink: [https://supabase.com/dashboard/account/me](https://supabase.com/dashboard/account/me\nOther improvements and bug fixes#\nGeneral\nMarch Beta 2021\nApr 6, 2021\nLaunch week, Storage, Supabase CLI, Connection Pooling, Supabase UI, and Pricing. Here's what we released last month.\nThis is also available as a blog post and a video demo.\nSupabase Storage#\nNeed to store images, audio, and video clips? Well now you can do it onÂ SupabaseÂ Storage. It's backed by S3 and our newÂ OSS storage APIÂ written in Fastify and Typescript. Read the full blog post.\n\nConnection Pooling#\nTheÂ SupabaseÂ API already handles Connection Pooling, but if you're connecting to your database directly (for example, with Prisma) we nowÂ bundle PgBouncer. Read the full blog post.\n\nReact UI Component Library#\nWe open sourced our internal UI component library, so that anyone can use and contribute to theÂ SupabaseÂ aesthetic. It lives atÂ ui.supabase.ioÂ . It was also the #1 Product of the Day on Product Hunt.\n\nCLI#\nNow you can runÂ SupabaseÂ locally in the terminal with supabaseÂ start. We have done some preliminary work on diff-based schema migrations, and added some new tooling for self-hostingÂ SupabaseÂ with Docker.Â Blog post here.\n\nOAuth Scopes#\nThanks to a comunity contribution (@_mateomorris and @Beamanator), Supabase Auth now includes OAuth scopes. These allow you to request elevated access during login. For example, you may want to request access to a list of Repositories when users log in with GitHub. Check out theÂ Documentation.\n\nKaizen#\n\nYou can now manage your PostgREST configuration inside the Dashboard.\nOur website has been redesigned. Check out our new Homepage and Blog, and our new  Database, Auth, and Storage product pages.\nWe refactored some of our Filter methods to make them even easier to use. Check out the Full Text Search refactor.\nWe have added several new sections to our Docs including: Local Dev, Self Hosting, and Postgres Reference docs (all still under development).\nLaunch week, Storage, Supabase CLI, Connection Pooling, Supabase UI, and Pricing. Here's what we released last month.\nThis is also available as a blog post and a video demo.\nSupabase Storage#\nNeed to store images, audio, and video clips? Well now you can do it onÂ SupabaseÂ Storage. It's backed by S3 and our newÂ OSS storage APIÂ written in Fastify and Typescript. Read the full blog post.\n\nConnection Pooling#\nTheÂ SupabaseÂ API already handles Connection Pooling, but if you're connecting to your database directly (for example, with Prisma) we nowÂ bundle PgBouncer. Read the full blog post.\n\nReact UI Component Library#\nWe open sourced our internal UI component library, so that anyone can use and contribute to theÂ SupabaseÂ aesthetic. It lives atÂ ui.supabase.ioÂ . It was also the #1 Product of the Day on Product Hunt.\n\nCLI#\nNow you can runÂ SupabaseÂ locally in the terminal with supabaseÂ start. We have done some preliminary work on diff-based schema migrations, and added some new tooling for self-hostingÂ SupabaseÂ with Docker.Â Blog post here.\n\nOAuth Scopes#\nThanks to a comunity contribution (@_mateomorris and @Beamanator), Supabase Auth now includes OAuth scopes. These allow you to request elevated access during login. For example, you may want to request access to a list of Repositories when users log in with GitHub. Check out theÂ Documentation.\n\nKaizen#\nFebruary Beta 2021\nMar 1, 2021\nSupabase is an open source Firebase alternative. We've now been building for one year. Here's what we released last month.\nThis is also available as a blog post and a video demo.\nDashboard Sidebars#\nWe've improved the UX of our Dashboard with sidebars in every section, including the Table view, the Auth section, and the SQL Editor.\n\nSQL Autocomplete#\nWriting SQL just got 10x easier. We added autocomplete to the SQL editor, including table & column suggestions.\n\nAuth Redirects#\nRedirect your users to specific route within your site on signIn() and signUp().\n\nLearning Resources#\nWe've released a new Resources section in our docs, as well as two new Auth modules: GoTrue Overview and Google OAuth.\n\nNew Region#\nLaunch your database in South Africa.\n\nKaizen#\n\nWe filled up our Examples page with a lot of new content.\nWe released a Docker Compose file for running Supabase locally. This will be used in our upcoming CLI.\nWe have a couple of pending RFCs which you may want to participate in:\n\nPlanning our CLI and Local Development\nConnection Pooling on Supabase\nSupabase is an open source Firebase alternative. We've now been building for one year. Here's what we released last month.\nThis is also available as a blog post and a video demo.\nDashboard Sidebars#\nWe've improved the UX of our Dashboard with sidebars in every section, including the Table view, the Auth section, and the SQL Editor.\n\nSQL Autocomplete#\nWriting SQL just got 10x easier. We added autocomplete to the SQL editor, including table & column suggestions.\n\nAuth Redirects#\nRedirect your users to specific route within your site on signIn() and signUp().\nLearning Resources#\nWe've released a new Resources section in our docs, as well as two new Auth modules: GoTrue Overview and Google OAuth.\n\nNew Region#\nLaunch your database in South Africa.\n\nKaizen#\nJanuary Beta 2021\nFeb 2, 2021\nNew year, new features. We've been busy at Supabase during January and our community has been even busier. Here's a few things you'll find interesting.\nThis is also available as a blog post and a video demo.\nCount functionality#\nAnyone who has worked with Firebase long enough has become frustrated over the lack of count functionality. This isn't a problem with PostgreSQL! Our libraries now have support for PostgREST's exact, planned, and estimated counts. A massive thanks to @dshukertjr for this adding support to our client library.\n\nNew Auth Providers#\nWe enabled 2 new Auth providers - Facebook and Azure. Thanks to @Levet for the Azure plugin, and once again to Netlify's amazing work with GoTrue to implement Facebook.\n\nAuth Audit Trail#\nWe have exposed the audit trail directly in the dashboard, as well as the GoTrue logs. Great for security and debugging.\n\nAuth UI widget#\nIn case our Auth endpoints aren't easy enough already, we've built a React Auth Widget for you to drop into your app and to get up-and-running in minutes.\n\nNew auth.email() function#\nWe added a helper function for extracting the logged in user's email address.\n\nNew Regions#\nLaunch your database in London or Sydney!\n\nCopy rows as Markdown#\nYou can now copy SQL results as Markdown - super useful for adding to blogs and issues.\n\nReact server components#\nIf you're excited by React Server components then check out the Supabase + Server Components experimental repo. https://github.com/supabase/next-server-components\n\nLearn#\nWe know that Auth can be a bit daunting when you're just starting out, so we have created some intro videos to get you up to speed in no time:\n\nSupabase Auth Deep Dive Part 1: JWTs\nSupabase Auth Deep Dive Part 2: Restrict Table Access\nSupabase Auth Deep Dive Part 3: User Based Access Policies\n\nKaizen#\n\nPerformance: We migrated all of our subdomains to Route53, implementing custom Let's Encrypt certs for your APIs. As a result, our read benchmarks are measuring up 12% faster.\nPerformance: We upgrade your databases to the new GP3 storage for faster and more consistent throughput.\nNew year, new features. We've been busy at Supabase during January and our community has been even busier. Here's a few things you'll find interesting.\nThis is also available as a blog post and a video demo.\nCount functionality#\nAnyone who has worked with Firebase long enough has become frustrated over the lack of count functionality. This isn't a problem with PostgreSQL! Our libraries now have support for PostgREST's exact, planned, and estimated counts. A massive thanks to @dshukertjr for this adding support to our client library.\n\nNew Auth Providers#\nWe enabled 2 new Auth providers - Facebook and Azure. Thanks to @Levet for the Azure plugin, and once again to Netlify's amazing work with GoTrue to implement Facebook.\n\nAuth Audit Trail#\nWe have exposed the audit trail directly in the dashboard, as well as the GoTrue logs. Great for security and debugging.\n\nAuth UI widget#\nIn case our Auth endpoints aren't easy enough already, we've built a React Auth Widget for you to drop into your app and to get up-and-running in minutes.\n\nNew auth.email() function#\nWe added a helper function for extracting the logged in user's email address.\n\nNew Regions#\nLaunch your database in London or Sydney!\nCopy rows as Markdown#\nYou can now copy SQL results as Markdown - super useful for adding to blogs and issues.\n\nReact server components#\nIf you're excited by React Server components then check out the Supabase + Server Components experimental repo. https://github.com/supabase/next-server-components\n\nLearn#\nWe know that Auth can be a bit daunting when you're just starting out, so we have created some intro videos to get you up to speed in no time:\nKaizen#\nBuild in a weekend, scale to millions\nFooter\nProduct\nResources\nDevelopers\nCompany\n"
  },
  {
    "id": "49",
    "url": "https://status.supabase.com/",
    "title": "Supabase Status",
    "content": "Subscribe to Incident\nSubscribe to updates for Compute capacity issues observed in the eu-west-3b availability zone via email and/or text message. You'll receive email notifications when incidents are updated, and text message notifications whenever Supabase creates or resolves an incident.\nRelated\nNo incidents or maintenance related to this downtime.\nNo incidents reported.\nNo incidents reported.\nNo incidents reported.\nNo incidents reported.\nNo incidents reported.\nNo incidents reported.\nNo incidents reported.\nNo incidents reported.\nNo incidents reported."
  },
  {
    "id": "50",
    "url": "https://supabase.com/",
    "title": "Supabase | The Open Source Firebase Alternative",
    "content": "Enterprise\nPricing\nDocs\nBlog\nBuild in a weekendScale to millions\nSupabase is an open source Firebase alternative. Start your project with a Postgres database, Authentication, instant APIs, Edge Functions, Realtime subscriptions, Storage, and Vector embeddings.\nTrusted by fast-growing companies worldwide\nPostgres Database\nEvery project is a full Postgres database, the world's most trusted relational database.\nAuthentication\nAdd user sign ups and logins, securing your data with Row Level Security.\nEdge Functions\nEasily write custom code without deploying or scaling servers.\nStorage\nStore, organize, and serve large files, from videos to images.\nRealtime\nBuild multiplayer experiences with real-time data synchronization.\nVector\nIntegrate your favorite ML-models to store, index and search vector embeddings.\nData APIs\nInstant ready-to-use Restful APIs.\nUse one or all. Best of breed products. Integrated as a platform.\nInfrastructure to innovate and scale with ease.\nSee how Supabase empowers companies of all sizes to accelerate their growth and streamline their work.\nMaergo's Express Delivery: How Supabase Helped Achieve Scalability, Speed, and Cost Saving\nBootstrapped founder builds an AI app with Supabase and scales to $1M in 5 months.\nScaling securely: one million users in 7 months protected with Supabase Auth\nMaergo's Express Delivery: How Supabase Helped Achieve Scalability, Speed, and Cost Saving\nBootstrapped founder builds an AI app with Supabase and scales to $1M in 5 months.\nScaling securely: one million users in 7 months protected with Supabase Auth\nMaergo's Express Delivery: How Supabase Helped Achieve Scalability, Speed, and Cost Saving\nBootstrapped founder builds an AI app with Supabase and scales to $1M in 5 months.\nScaling securely: one million users in 7 months protected with Supabase Auth\nStart building in seconds\nKickstart your next project with templates built by us and our community.\nStripe Subscriptions Starter\nThe all-in-one subscription starter kit for high-performance SaaS applications, powered by Stripe, Supabase, and Vercel.\nNext.js Starter\nA Next.js App Router template configured with cookie-based auth using Supabase, TypeScript and Tailwind CSS.\nAI Chatbot\nAn open-source AI chatbot app template built with Next.js, the Vercel AI SDK, OpenAI, and Supabase.\nLangChain + Next.js Starter\nStarter template and example use-cases for LangChain projects in Next.js, including chat, agents, and retrieval.\nFlutter User Management\nGet started with Supabase and Flutter by building a user management app with auth, file storage, and database.\nExpo React Native Starter\nAn extended version of create-t3-turbo implementing authentication on both the web and mobile applications.\nStripe Subscriptions Starter\nThe all-in-one subscription starter kit for high-performance SaaS applications, powered by Stripe, Supabase, and Vercel.\nNext.js Starter\nA Next.js App Router template configured with cookie-based auth using Supabase, TypeScript and Tailwind CSS.\nAI Chatbot\nAn open-source AI chatbot app template built with Next.js, the Vercel AI SDK, OpenAI, and Supabase.\nLangChain + Next.js Starter\nStarter template and example use-cases for LangChain projects in Next.js, including chat, agents, and retrieval.\nFlutter User Management\nGet started with Supabase and Flutter by building a user management app with auth, file storage, and database.\nExpo React Native Starter\nAn extended version of create-t3-turbo implementing authentication on both the web and mobile applications.\nStay productive and manage your app without leaving the dashboard\nJoin the community\nDiscover what our community has to say about their Supabase experience.\n@thatguy_tex\n\"Working with @supabase has been one of the best dev experiences I've had lately. Incredibly easy to set up, great documentation, and so many fewer hoops to jump through than the competition. I definitely plan to use it on any and all future projects.\"\n@IxoyeDesign\n\"@supabase is just ðŸ¤¯ Now I see why a lot of people love using it as a backend for their applications. I am really impressed with how easy it is to set up an Auth and then just code it together for the frontend. @IngoKpp now I see your joy with Supabase #coding #fullstackwebdev\"\n@varlenneto\n\"I've been using @supabase for two personal projects and it has been amazing being able to use the power of Postgres and don't have to worry about the backend\"\n@justinjunodev\n\"Y'all @supabase + @nextjs is amazing! ðŸ™Œ Barely an hour into a proof-of-concept and already have most of the functionality in place. ðŸ¤¯ðŸ¤¯ðŸ¤¯\"\n@BraydonCoyer\n\"And thanks to @supabase, I was able to go from idea to launched feature in a matter of hours. Absolutely amazing!\"\n@damlakoksal\n\"Contributing to open-source projects and seeing merged PRs gives enormous happiness! Special thanks to @supabase, for giving this opportunity by staying open-source and being junior-friendlyâœŒðŸ¼\"\n@KenTheRogers\n\"Holy crap. @supabase is absolutely incredible. Most elegant backend as a service I've ever used. This is a dream.\"\n@PaoloRicciuti\n\"Using @supabase I'm really pleased on the power of postgres (and sql in general). Despite being a bit dubious about the whole backend as a service thing I have to say I really don't miss anything. The whole experience feel very robust and secure.\"\n@saxxone\n\"@supabase is lit. It took me less than 10 minutes to setup, the DX is just amazing.\"\n@michaelcdever\n\"Iâ€™m not sure what magic @supabase is using but weâ€™ve migrated @happyteamsdotio database to @supabase from @heroku and itâ€™s much much faster at half the cost.\"\n@swyx\n\"There are a lot of indie hackers building in public, but itâ€™s rare to see a startup shipping as consistently and transparently as Supabase. Their upcoming March releases look to be ðŸ”¥ Def worth a follow! also opened my eyes as to how to value add in open source.\"\n@jperelli\n\"This weekend I made a personal record ðŸ¥‡ on the less time spent creating an application with social login / permissions, database, cdn, infinite scaling, git push to deploy and for free. Thanks to @supabase and @vercel\"\n@KennethCassel\n\"Badass! Supabase is amazing. literally saves our small team a whole engineerâ€™s worth of work constantly. The founders and everyone Iâ€™ve chatted with at supabase are just awesome people as well :)\"\n@the_BrianB\n\"Working with Supabase is just fun. It makes working with a DB so much easier.\"\n@_wilhelm__\n\"This community is STRONG and will continue to be the reason why developers flock to @supabase over an alternative. Keep up the good work! âš¡ï¸\"\n@drewclemcr8\n\"Working on my next SaaS app and I want this to be my whole job because I'm just straight out vibing putting it together. @supabase and chill, if you will\"\n@CodiferousCoder\n\"@supabase Putting a ton of well-explained example API queries in a self-building documentation is just a classy move all around. I also love having GraphQL-style nested queries with traditional SQL filtering. This is pure DX delight. A+++. #backend\"\n@nasiscoe\n\"Me using @supabase for the first time right now ðŸ¤¯\"\n@thatguy_tex\n\"Working with @supabase has been one of the best dev experiences I've had lately. Incredibly easy to set up, great documentation, and so many fewer hoops to jump through than the competition. I definitely plan to use it on any and all future projects.\"\n@IxoyeDesign\n\"@supabase is just ðŸ¤¯ Now I see why a lot of people love using it as a backend for their applications. I am really impressed with how easy it is to set up an Auth and then just code it together for the frontend. @IngoKpp now I see your joy with Supabase #coding #fullstackwebdev\"\n@varlenneto\n\"I've been using @supabase for two personal projects and it has been amazing being able to use the power of Postgres and don't have to worry about the backend\"\n@justinjunodev\n\"Y'all @supabase + @nextjs is amazing! ðŸ™Œ Barely an hour into a proof-of-concept and already have most of the functionality in place. ðŸ¤¯ðŸ¤¯ðŸ¤¯\"\n@BraydonCoyer\n\"And thanks to @supabase, I was able to go from idea to launched feature in a matter of hours. Absolutely amazing!\"\n@damlakoksal\n\"Contributing to open-source projects and seeing merged PRs gives enormous happiness! Special thanks to @supabase, for giving this opportunity by staying open-source and being junior-friendlyâœŒðŸ¼\"\n@KenTheRogers\n\"Holy crap. @supabase is absolutely incredible. Most elegant backend as a service I've ever used. This is a dream.\"\n@PaoloRicciuti\n\"Using @supabase I'm really pleased on the power of postgres (and sql in general). Despite being a bit dubious about the whole backend as a service thing I have to say I really don't miss anything. The whole experience feel very robust and secure.\"\n@saxxone\n\"@supabase is lit. It took me less than 10 minutes to setup, the DX is just amazing.\"\n@michaelcdever\n\"Iâ€™m not sure what magic @supabase is using but weâ€™ve migrated @happyteamsdotio database to @supabase from @heroku and itâ€™s much much faster at half the cost.\"\n@swyx\n\"There are a lot of indie hackers building in public, but itâ€™s rare to see a startup shipping as consistently and transparently as Supabase. Their upcoming March releases look to be ðŸ”¥ Def worth a follow! also opened my eyes as to how to value add in open source.\"\n@jperelli\n\"This weekend I made a personal record ðŸ¥‡ on the less time spent creating an application with social login / permissions, database, cdn, infinite scaling, git push to deploy and for free. Thanks to @supabase and @vercel\"\n@KennethCassel\n\"Badass! Supabase is amazing. literally saves our small team a whole engineerâ€™s worth of work constantly. The founders and everyone Iâ€™ve chatted with at supabase are just awesome people as well :)\"\n@the_BrianB\n\"Working with Supabase is just fun. It makes working with a DB so much easier.\"\n@_wilhelm__\n\"This community is STRONG and will continue to be the reason why developers flock to @supabase over an alternative. Keep up the good work! âš¡ï¸\"\n@drewclemcr8\n\"Working on my next SaaS app and I want this to be my whole job because I'm just straight out vibing putting it together. @supabase and chill, if you will\"\n@CodiferousCoder\n\"@supabase Putting a ton of well-explained example API queries in a self-building documentation is just a classy move all around. I also love having GraphQL-style nested queries with traditional SQL filtering. This is pure DX delight. A+++. #backend\"\n@nasiscoe\n\"Me using @supabase for the first time right now ðŸ¤¯\"\n@thatguy_tex\n\"Working with @supabase has been one of the best dev experiences I've had lately. Incredibly easy to set up, great documentation, and so many fewer hoops to jump through than the competition. I definitely plan to use it on any and all future projects.\"\n@IxoyeDesign\n\"@supabase is just ðŸ¤¯ Now I see why a lot of people love using it as a backend for their applications. I am really impressed with how easy it is to set up an Auth and then just code it together for the frontend. @IngoKpp now I see your joy with Supabase #coding #fullstackwebdev\"\n@varlenneto\n\"I've been using @supabase for two personal projects and it has been amazing being able to use the power of Postgres and don't have to worry about the backend\"\n@justinjunodev\n\"Y'all @supabase + @nextjs is amazing! ðŸ™Œ Barely an hour into a proof-of-concept and already have most of the functionality in place. ðŸ¤¯ðŸ¤¯ðŸ¤¯\"\n@BraydonCoyer\n\"And thanks to @supabase, I was able to go from idea to launched feature in a matter of hours. Absolutely amazing!\"\n@damlakoksal\n\"Contributing to open-source projects and seeing merged PRs gives enormous happiness! Special thanks to @supabase, for giving this opportunity by staying open-source and being junior-friendlyâœŒðŸ¼\"\n@KenTheRogers\n\"Holy crap. @supabase is absolutely incredible. Most elegant backend as a service I've ever used. This is a dream.\"\n@PaoloRicciuti\n\"Using @supabase I'm really pleased on the power of postgres (and sql in general). Despite being a bit dubious about the whole backend as a service thing I have to say I really don't miss anything. The whole experience feel very robust and secure.\"\n@saxxone\n\"@supabase is lit. It took me less than 10 minutes to setup, the DX is just amazing.\"\n@michaelcdever\n\"Iâ€™m not sure what magic @supabase is using but weâ€™ve migrated @happyteamsdotio database to @supabase from @heroku and itâ€™s much much faster at half the cost.\"\n@swyx\n\"There are a lot of indie hackers building in public, but itâ€™s rare to see a startup shipping as consistently and transparently as Supabase. Their upcoming March releases look to be ðŸ”¥ Def worth a follow! also opened my eyes as to how to value add in open source.\"\n@jperelli\n\"This weekend I made a personal record ðŸ¥‡ on the less time spent creating an application with social login / permissions, database, cdn, infinite scaling, git push to deploy and for free. Thanks to @supabase and @vercel\"\n@KennethCassel\n\"Badass! Supabase is amazing. literally saves our small team a whole engineerâ€™s worth of work constantly. The founders and everyone Iâ€™ve chatted with at supabase are just awesome people as well :)\"\n@the_BrianB\n\"Working with Supabase is just fun. It makes working with a DB so much easier.\"\n@_wilhelm__\n\"This community is STRONG and will continue to be the reason why developers flock to @supabase over an alternative. Keep up the good work! âš¡ï¸\"\n@drewclemcr8\n\"Working on my next SaaS app and I want this to be my whole job because I'm just straight out vibing putting it together. @supabase and chill, if you will\"\n@CodiferousCoder\n\"@supabase Putting a ton of well-explained example API queries in a self-building documentation is just a classy move all around. I also love having GraphQL-style nested queries with traditional SQL filtering. This is pure DX delight. A+++. #backend\"\n@nasiscoe\n\"Me using @supabase for the first time right now ðŸ¤¯\"\n@thatguy_tex\n\"Working with @supabase has been one of the best dev experiences I've had lately. Incredibly easy to set up, great documentation, and so many fewer hoops to jump through than the competition. I definitely plan to use it on any and all future projects.\"\n@IxoyeDesign\n\"@supabase is just ðŸ¤¯ Now I see why a lot of people love using it as a backend for their applications. I am really impressed with how easy it is to set up an Auth and then just code it together for the frontend. @IngoKpp now I see your joy with Supabase #coding #fullstackwebdev\"\n@varlenneto\n\"I've been using @supabase for two personal projects and it has been amazing being able to use the power of Postgres and don't have to worry about the backend\"\n@justinjunodev\n\"Y'all @supabase + @nextjs is amazing! ðŸ™Œ Barely an hour into a proof-of-concept and already have most of the functionality in place. ðŸ¤¯ðŸ¤¯ðŸ¤¯\"\n@BraydonCoyer\n\"And thanks to @supabase, I was able to go from idea to launched feature in a matter of hours. Absolutely amazing!\"\n@damlakoksal\n\"Contributing to open-source projects and seeing merged PRs gives enormous happiness! Special thanks to @supabase, for giving this opportunity by staying open-source and being junior-friendlyâœŒðŸ¼\"\n@KenTheRogers\n\"Holy crap. @supabase is absolutely incredible. Most elegant backend as a service I've ever used. This is a dream.\"\n@PaoloRicciuti\n\"Using @supabase I'm really pleased on the power of postgres (and sql in general). Despite being a bit dubious about the whole backend as a service thing I have to say I really don't miss anything. The whole experience feel very robust and secure.\"\n@saxxone\n\"@supabase is lit. It took me less than 10 minutes to setup, the DX is just amazing.\"\n@michaelcdever\n\"Iâ€™m not sure what magic @supabase is using but weâ€™ve migrated @happyteamsdotio database to @supabase from @heroku and itâ€™s much much faster at half the cost.\"\n@swyx\n\"There are a lot of indie hackers building in public, but itâ€™s rare to see a startup shipping as consistently and transparently as Supabase. Their upcoming March releases look to be ðŸ”¥ Def worth a follow! also opened my eyes as to how to value add in open source.\"\n@jperelli\n\"This weekend I made a personal record ðŸ¥‡ on the less time spent creating an application with social login / permissions, database, cdn, infinite scaling, git push to deploy and for free. Thanks to @supabase and @vercel\"\n@KennethCassel\n\"Badass! Supabase is amazing. literally saves our small team a whole engineerâ€™s worth of work constantly. The founders and everyone Iâ€™ve chatted with at supabase are just awesome people as well :)\"\n@the_BrianB\n\"Working with Supabase is just fun. It makes working with a DB so much easier.\"\n@_wilhelm__\n\"This community is STRONG and will continue to be the reason why developers flock to @supabase over an alternative. Keep up the good work! âš¡ï¸\"\n@drewclemcr8\n\"Working on my next SaaS app and I want this to be my whole job because I'm just straight out vibing putting it together. @supabase and chill, if you will\"\n@CodiferousCoder\n\"@supabase Putting a ton of well-explained example API queries in a self-building documentation is just a classy move all around. I also love having GraphQL-style nested queries with traditional SQL filtering. This is pure DX delight. A+++. #backend\"\n@nasiscoe\n\"Me using @supabase for the first time right now ðŸ¤¯\"\nBuild in a weekend, scale to millions\nFooter\nProduct\nResources\nDevelopers\nCompany\n"
  },
  {
    "id": "51",
    "url": "https://github.com/supabase/supabase/blob/master/apps/docs/DEVELOPERS.md",
    "title": "supabase/apps/docs/DEVELOPERS.md at master Â· supabase/supabase Â· GitHub",
    "content": "Navigation Menu\nSearch code, repositories, users, issues, pull requests...\nProvide feedback\nWe read every piece of feedback, and take your input very seriously.\nSaved searches\nUse saved searches to filter your results more quickly\nTo see all available qualifiers, see our documentation.\n\nFiles\nBreadcrumbs\nDEVELOPERS.md\nLatest commit\nHistory\nBreadcrumbs\nDEVELOPERS.md\nFile metadata and controls\nDeveloping Supabase Docs\nGetting started\nThanks for your interest in Supabase docs and for wanting to contribute! Before you begin, read the\ncode of conduct and check out the\nexisting issues.\nThis document describes how to set up your development environment to contribute to Supabase docs.\nFor a complete run-down on how all of our tools work together, see the main DEVELOPERS.md. That readme describes how to get set up locally in lots of detail, including minimum requirements, our Turborepo setup, installing packages, sharing components across projects, and more. This readme deals specifically with the docs site.\nTipIf you work at Supabase, branch this repo directly to make PRs. Don't use a fork. This lets the CI checks auto-run and speeds up review.\n\nLocal setup\nsupabase.com/docs is a Next.js site. You can get setup by following the same steps for all of our other Next.js projects:\n\nFollow the steps outlined in the Local Development section of the main DEVELOPERS.md\nIf you work at Supabase, run dev:secrets:pull to pull down the internal environment variables. If you're a community member, create a .env file and add this line to it: NEXT_PUBLIC_IS_PLATFORM=false\nStart the local docs site by navigating to /apps/docs and running npm run dev\nVisit http://localhost:3001/docs in your browser - don't forget to append the /docs to the end\nYour local site should look exactly like https://supabase.com/docs\n\nContributing\nFor repo organization and style guide, see the contributing guide.\nDeveloping Supabase Docs\nGetting started\nThanks for your interest in Supabase docs and for wanting to contribute! Before you begin, read the\ncode of conduct and check out the\nexisting issues.\nThis document describes how to set up your development environment to contribute to Supabase docs.\nFor a complete run-down on how all of our tools work together, see the main DEVELOPERS.md. That readme describes how to get set up locally in lots of detail, including minimum requirements, our Turborepo setup, installing packages, sharing components across projects, and more. This readme deals specifically with the docs site.\nTipIf you work at Supabase, branch this repo directly to make PRs. Don't use a fork. This lets the CI checks auto-run and speeds up review.\n\nLocal setup\nsupabase.com/docs is a Next.js site. You can get setup by following the same steps for all of our other Next.js projects:\n\nFollow the steps outlined in the Local Development section of the main DEVELOPERS.md\nIf you work at Supabase, run dev:secrets:pull to pull down the internal environment variables. If you're a community member, create a .env file and add this line to it: NEXT_PUBLIC_IS_PLATFORM=false\nStart the local docs site by navigating to /apps/docs and running npm run dev\nVisit http://localhost:3001/docs in your browser - don't forget to append the /docs to the end\nYour local site should look exactly like https://supabase.com/docs\n\nContributing\nFor repo organization and style guide, see the contributing guide.\nDeveloping Supabase Docs\nGetting started\nThanks for your interest in Supabase docs and for wanting to contribute! Before you begin, read the\ncode of conduct and check out the\nexisting issues.\nThis document describes how to set up your development environment to contribute to Supabase docs.\nFor a complete run-down on how all of our tools work together, see the main DEVELOPERS.md. That readme describes how to get set up locally in lots of detail, including minimum requirements, our Turborepo setup, installing packages, sharing components across projects, and more. This readme deals specifically with the docs site.\nTip\nIf you work at Supabase, branch this repo directly to make PRs. Don't use a fork. This lets the CI checks auto-run and speeds up review.\nLocal setup\nsupabase.com/docs is a Next.js site. You can get setup by following the same steps for all of our other Next.js projects:\nContributing\nFor repo organization and style guide, see the contributing guide.\nFooter\nFooter navigation"
  },
  {
    "id": "52",
    "url": "https://github.com/supabase/supabase/blob/master/apps/docs/CONTRIBUTING.md",
    "title": "supabase/apps/docs/CONTRIBUTING.md at master Â· supabase/supabase Â· GitHub",
    "content": "Navigation Menu\nSearch code, repositories, users, issues, pull requests...\nProvide feedback\nWe read every piece of feedback, and take your input very seriously.\nSaved searches\nUse saved searches to filter your results more quickly\nTo see all available qualifiers, see our documentation.\n\nFiles\nBreadcrumbs\nCONTRIBUTING.md\nLatest commit\nHistory\nBreadcrumbs\nCONTRIBUTING.md\nFile metadata and controls\nContributing to Supabase docs\nOur docs help developers to get started and keep succeeding with Supabase. We welcome contributions from everyone.\nIf you'd like to contribute, see our list of recommended issues. We also welcome you to open a PR or a new issue with your question.\nHere are some general guidelines on writing docs for Supabase.\nGeneral principles\nDocs should be helpful, quick to read, and easy to understand. We have an audience of global readers who speak different native languages.\nTo make docs as clear as possible:\n\nWrite for the user. Think about what task they want to complete by reading your doc. Tell them what, and only what, they need to know.\nWrite like you talk. Use words and sentences that sound natural when speaking. Cut unnecessary words. Read your writing out loud to help you choose the clearest and simplest phrases.\nEach paragraph should have one topic only. Start a new paragraph whenever you change the topic. Don't worry about paragraphs being too short.\nAvoid using idioms and colloquialisms, such as piece of cake. These phrases are often specific to a region or culture.\nRefer to the reader as you. Don't use we to refer to the reader. Use we only to refer to the Supabase team.\n\nDocument types\nSupabase docs contain 4 types of documents. Before you start writing, think about what type of doc you need.\nExplainers\nExplainers help the reader to learn a topic. They are conceptual and mostly prose-based. They can include:\n\nA description of what a feature is\nSome reasons why it is useful\nSome examples of when to use it\nA high-level explanation of how it works\n\nThey shouldn't include:\n\nInstructions on how to use it\n\nTutorials\nTutorials are goal-oriented. They help a reader to finish a large, complex goal, such as setting up a web app that uses multiple Supabase features.\nTutorials mix prose explanations with procedures (lists of steps for the reader to follow). They provide context for why certain instructions are given.\nFor inspiration, see an example of a tutorial.\nGuides\nGuides are also goal-oriented, but they focus on shorter, more targeted tasks. For example, a guide might explain how to set up user login for an app.\nGuides contain mostly procedures. Think of an instruction manual for building a desk: it's a list of concise steps that the user can go through quickly.\nFor inspiration, see an example of a guide.\nReference\nReferences are factual and to the point. Think of dictionary entries.\nThey should include:\n\nFunction parameters\nReturn types\nCode samples\nWarnings for critical errors (for example, missteps that can cause data loss)\n\nThey shouldn't include:\n\nExplanations of the context for a feature\nExamples of use cases\nMulti-step instructions\n\nRepo organization\nMost docs pages are contained in the apps/docs/content directory. Some docs sections are federated from other repositories, for example pg_graphql. Reference docs are generated from spec files in the spec directory.\nYou can usually identify a federated or reference doc because it uses a Next.js dynamic route (for example, [[...slug]].tsx). Look for the spec file import or the repo definition to find the content location.\nExample spec file import:\nimport specFile from '~/spec/transforms/analytics_v0_openapi_deparsed.json' assert { type: 'json' }\n    \n      \n    \n\n      \n    \n\n    \n  \nExample repo definition:\nconst org = 'supabase'\nconst repo = 'pg_graphql'\nconst branch = 'master'\nconst docsDir = 'docs'\nconst externalSite = 'https://supabase.github.io/pg_graphql'\n    \n      \n    \n\n      \n    \n\n    \n  \nCheck the sections for guide structure and reference structure to learn more about the file structures.\nGuide structure\nThe Supabase docs use MDX. Guides are written in unstructured prose as MDX documents.\nAdding a new guide requires:\n\nYAML frontmatter\nA navigation entry (in a separate file)\n\nFrontmatter looks like this. title is mandatory. There are also optional properties that you can use to control the page display, including subtitle, tocVideo, and hideToc.\n---\ntitle: How to connect to Supabase\nhideToc: true\n---\n    \n      \n    \n\n      \n    \n\n    \n  \nThe navigation is defined in NavigationMenu.constants.ts.\nAdd an entry with the name, url, and (optional) icon for your page.\nReference structure\nReference docs are produced from the reference specs and library source code. A common spec file contains shared function and endpoint definitions, and library-specific spec files contain further details.\nCommon spec file\nEach type of library (for example, language SDK or CLI) has a common spec file. For example, see the spec file for the language SDKs. This file contains definitions for the common SDK functions:\n\nid - Identifies the function\ntitle - Human-readable title\nslug - URL slug\nproduct - Supabase product that owns the function. For example, database operations are owned by database, and auth functions are owned byauth\ntype - function for a structured function definition or markdown for a prose explainer section.\n\nTo add a new function, manually add an entry to this common file.\nSpecific spec file\nEach library also has its own spec file containing library-specific details. For example, see the JavaScript SDK spec file.\nThe functions listed in this file match the ones defined in the common spec file.\nEach function contains a description, code examples, and optional notes. The parameters are pulled from the source code via the $ref property, which references a function definition in the source code repo. These references are pulled down and transformed using commands in the spec Makefile. Unless you're a library maintainer, you don't need to worry about this.\nIf you're a library maintainer, follow these steps when updating function parameters or return values:\n\nGet your changes merged to master in your library\nThis will kick off an action that automatically updates the spec file in the library's gh-pages branch\nRun make in /spec of the supabase/supabase repo. This will regenerate all of the tsdoc files that the docs site uses\nYou should now see the changes you've made in the docs site locally\n\nContent reuse\nIf you copy the same content multiple times across different files, create a partial for content reuse instead. Partials are MDX files contained in apps/docs/components/MDX. They contain reusable snippets that can be inserted in multiple pages. For example, you can create a partial to define a common setup step for a group of tutorials.\nTo use a partial, import it into your MDX file. You can also set up a partial to automatically import by including it in the components within apps/docs/components/index.tsx.\nComponents and elements\nDocs include normal Markdown elements such as lists, and custom components such as admonitions (callouts).\nHere are some guidelines for using elements:\nAdmonitions\nAdmonitions (or callouts) draw reader attention to an important point or an aside. They highlight important information, but get less effective if they're overused.\nUse admonitions sparingly. Don't stack them on top of each other.\nChoose the appropriate type for your admonition:\n\ndanger to warn the user about any missteps that could cause data loss or data leaks\ndeprecation to notify the user about features that are (or will soon be) deprecated\ncaution to warn about anything that could cause a bug or serious user inconvenience\ntip to point out helpful but optional actions\nnote for anything else\n\n<Admonition type=\"note\" label=\"Optional label displays as title\">\n\nYour content here\n\n</Admonition>\n\n    \n      \n    \n\n      \n    \n\n    \n  \nBlockquotes\nDon't use blockquotes.\nCode blocks\nKeep code lines short to avoid scrolling. For example, you can split long shell commands with \\.\n\n\nJavaScript/TypeScript\nThe supabase repo uses Prettier, which also formats JS/TS in code blocks. Your PR is blocked from merging if the Prettier check fails. Ensure that your code blocks are formatted by running npm run format, or by setting up auto-formatting in your IDE.\n\n\nSQL\nPrefer lowercase for SQL. For example, select * from table rather than SELECT * FROM table.\n\n\nOptionally specify a filename for the codeblock by including it after the opening backticks and language specifier:\n```ts environment.ts\n    \n      \n    \n\n      \n    \n\n    \n  \nOptionally highlight lines by using mark=${lineNumber}.\n```js mark=12:13\n    \n      \n    \n\n      \n    \n\n    \n  \nFootnotes\nDon't use footnotes.\nImages\nImages are uploaded in the apps/docs/public/img folder.\nFor vector illustrations, use svg. For screenshots and non-vector graphics, use png. (These are automatically converted to webp for supported browsers.)\nRedact any sensitive information, such as API keys.\nLinks\nLink text should be descriptive. The reader should understand where the link goes from reading the link text alone. This is important for accessibility. For example, don't use here as link text.\nBut link text shouldn't be too long. Use the shortest part of the link that is descriptive enough. For example, see the [reference section](/link) rather than [see the reference section](/link).\nUse relative links when linking within the supabase.com domain. For example, [link to another page in Supabase docs](/docs/guides/getting-started).\nLists\nUse ordered lists for steps that must be taken one after the other. Use unordered lists when order doesn't matter.\nUse Arabic numerals (1, 2, 3) for ordered lists and dashes (-) for unordered lists.\nDon't nest lists more than two deep.\n1. List item\n2. List item\n   1. List item\n   2. List item\n3. List item\n   - List item\n   - List item\n   <!-- DON'T ADD ANOTHER LEVEL OF NESTING -->\n     - Overly nested list item\n    \n      \n    \n\n      \n    \n\n    \n  \nTabs\nUse tabs to provide alternative instructions for different platforms or languages.\nThe queryGroup param is optional. It lets you link directly to a tab by using the query group as a query param in the URL, for example: https://supabase.com/docs/my-page?packagemanager=ts\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"npm\"\n  queryGroup=\"packagemanager\"\n>\n<TabPanel id=\"npm\" label=\"npm\">\n\n// ...\n\n</TabPanel>\n<TabPanel id=\"yarn\" label=\"Yarn\">\n\n// ...\n\n</TabPanel>\n</Tabs>\n\n    \n      \n    \n\n      \n    \n\n    \n  \nVideos\nInclude videos as TOC (Table of Contents) videos rather than putting them in the main text.\nYou can define a TOC video in the page frontmatter:\n---\ntocVideo: 'rzglqRdZUQE',\n---\n    \n      \n    \n\n      \n    \n\n    \n  \nStyling, formatting, and grammar\nDon't worry too much about grammar rules. Grammar is useful if, and only if, it makes your writing clearer. For example, you can use sentence fragments if they're self-explanatory.\nThat said, a few rules help keep the docs concise, consistent, and clear:\n\nFormat headings in sentence case. Capitalize the first word and any proper nouns. All other words are lowercase. For example, Set up authentication rather than Set Up Authentication.\nUse the Oxford comma (a comma before the and that marks the last item in a list). For example, realtime, database, and authentication rather than realtime, database and authentication.\nUse the present tense as much as possible. For example, the AI assistant answers your question rather than the AI assistant will answer your question.\n\nWord usage and spelling\nUse American English. If in doubt, consult the Merriam-Webster dictionary.\nHere are some exceptions and Supabase-specific guidelines.\nGeneral word usage\n\nFiller words: You can often make your writing more concise by removing these words. (Some of these words can also sound patronizing.)\n\nActually\nEasy, easily\nJust\nLet's\nPlease\nSimple, simply\n\n\nUI elements\n\nButtons are clicked.\nCheckboxes are selected.\nToggles are enabled and disabled.\nLabels of UI elements are bolded. For example, Click **Confirm**.\n\n\n\nWord list\n\nBackend isn't hyphenated (not back-end).\nFrontend isn't hyphenated (not front-end).\nLogin is a noun. Log in is a verb.\nPostgres is capitalized, except in code, and used instead of PostgreSQL.\nSetup is a noun. Set up is a verb.\nSupabase is capitalized (not supabase), except in code.\nSupabase Platform is in title case (not Supabase platform).\n\nSearch\nSearch is handled using a Supabase instance. During CI, a script aggregates all content sources (eg. guides, reference docs, etc), indexes them using OpenAI embeddings, and stores them in a Supabase database.\nSearch uses a hybrid of native Postgres FTS and embedding similarity search based on pgvector. At runtime, a PostgREST call triggers the RPC that runs the weighted FTS search, and an Edge Function is executed to perform the embedding search.\nContributing to Supabase docs\nOur docs help developers to get started and keep succeeding with Supabase. We welcome contributions from everyone.\nIf you'd like to contribute, see our list of recommended issues. We also welcome you to open a PR or a new issue with your question.\nHere are some general guidelines on writing docs for Supabase.\nGeneral principles\nDocs should be helpful, quick to read, and easy to understand. We have an audience of global readers who speak different native languages.\nTo make docs as clear as possible:\n\nWrite for the user. Think about what task they want to complete by reading your doc. Tell them what, and only what, they need to know.\nWrite like you talk. Use words and sentences that sound natural when speaking. Cut unnecessary words. Read your writing out loud to help you choose the clearest and simplest phrases.\nEach paragraph should have one topic only. Start a new paragraph whenever you change the topic. Don't worry about paragraphs being too short.\nAvoid using idioms and colloquialisms, such as piece of cake. These phrases are often specific to a region or culture.\nRefer to the reader as you. Don't use we to refer to the reader. Use we only to refer to the Supabase team.\n\nDocument types\nSupabase docs contain 4 types of documents. Before you start writing, think about what type of doc you need.\nExplainers\nExplainers help the reader to learn a topic. They are conceptual and mostly prose-based. They can include:\n\nA description of what a feature is\nSome reasons why it is useful\nSome examples of when to use it\nA high-level explanation of how it works\n\nThey shouldn't include:\n\nInstructions on how to use it\n\nTutorials\nTutorials are goal-oriented. They help a reader to finish a large, complex goal, such as setting up a web app that uses multiple Supabase features.\nTutorials mix prose explanations with procedures (lists of steps for the reader to follow). They provide context for why certain instructions are given.\nFor inspiration, see an example of a tutorial.\nGuides\nGuides are also goal-oriented, but they focus on shorter, more targeted tasks. For example, a guide might explain how to set up user login for an app.\nGuides contain mostly procedures. Think of an instruction manual for building a desk: it's a list of concise steps that the user can go through quickly.\nFor inspiration, see an example of a guide.\nReference\nReferences are factual and to the point. Think of dictionary entries.\nThey should include:\n\nFunction parameters\nReturn types\nCode samples\nWarnings for critical errors (for example, missteps that can cause data loss)\n\nThey shouldn't include:\n\nExplanations of the context for a feature\nExamples of use cases\nMulti-step instructions\n\nRepo organization\nMost docs pages are contained in the apps/docs/content directory. Some docs sections are federated from other repositories, for example pg_graphql. Reference docs are generated from spec files in the spec directory.\nYou can usually identify a federated or reference doc because it uses a Next.js dynamic route (for example, [[...slug]].tsx). Look for the spec file import or the repo definition to find the content location.\nExample spec file import:\nimport specFile from '~/spec/transforms/analytics_v0_openapi_deparsed.json' assert { type: 'json' }\n    \n      \n    \n\n      \n    \n\n    \n  \nExample repo definition:\nconst org = 'supabase'\nconst repo = 'pg_graphql'\nconst branch = 'master'\nconst docsDir = 'docs'\nconst externalSite = 'https://supabase.github.io/pg_graphql'\n    \n      \n    \n\n      \n    \n\n    \n  \nCheck the sections for guide structure and reference structure to learn more about the file structures.\nGuide structure\nThe Supabase docs use MDX. Guides are written in unstructured prose as MDX documents.\nAdding a new guide requires:\n\nYAML frontmatter\nA navigation entry (in a separate file)\n\nFrontmatter looks like this. title is mandatory. There are also optional properties that you can use to control the page display, including subtitle, tocVideo, and hideToc.\n---\ntitle: How to connect to Supabase\nhideToc: true\n---\n    \n      \n    \n\n      \n    \n\n    \n  \nThe navigation is defined in NavigationMenu.constants.ts.\nAdd an entry with the name, url, and (optional) icon for your page.\nReference structure\nReference docs are produced from the reference specs and library source code. A common spec file contains shared function and endpoint definitions, and library-specific spec files contain further details.\nCommon spec file\nEach type of library (for example, language SDK or CLI) has a common spec file. For example, see the spec file for the language SDKs. This file contains definitions for the common SDK functions:\n\nid - Identifies the function\ntitle - Human-readable title\nslug - URL slug\nproduct - Supabase product that owns the function. For example, database operations are owned by database, and auth functions are owned byauth\ntype - function for a structured function definition or markdown for a prose explainer section.\n\nTo add a new function, manually add an entry to this common file.\nSpecific spec file\nEach library also has its own spec file containing library-specific details. For example, see the JavaScript SDK spec file.\nThe functions listed in this file match the ones defined in the common spec file.\nEach function contains a description, code examples, and optional notes. The parameters are pulled from the source code via the $ref property, which references a function definition in the source code repo. These references are pulled down and transformed using commands in the spec Makefile. Unless you're a library maintainer, you don't need to worry about this.\nIf you're a library maintainer, follow these steps when updating function parameters or return values:\n\nGet your changes merged to master in your library\nThis will kick off an action that automatically updates the spec file in the library's gh-pages branch\nRun make in /spec of the supabase/supabase repo. This will regenerate all of the tsdoc files that the docs site uses\nYou should now see the changes you've made in the docs site locally\n\nContent reuse\nIf you copy the same content multiple times across different files, create a partial for content reuse instead. Partials are MDX files contained in apps/docs/components/MDX. They contain reusable snippets that can be inserted in multiple pages. For example, you can create a partial to define a common setup step for a group of tutorials.\nTo use a partial, import it into your MDX file. You can also set up a partial to automatically import by including it in the components within apps/docs/components/index.tsx.\nComponents and elements\nDocs include normal Markdown elements such as lists, and custom components such as admonitions (callouts).\nHere are some guidelines for using elements:\nAdmonitions\nAdmonitions (or callouts) draw reader attention to an important point or an aside. They highlight important information, but get less effective if they're overused.\nUse admonitions sparingly. Don't stack them on top of each other.\nChoose the appropriate type for your admonition:\n\ndanger to warn the user about any missteps that could cause data loss or data leaks\ndeprecation to notify the user about features that are (or will soon be) deprecated\ncaution to warn about anything that could cause a bug or serious user inconvenience\ntip to point out helpful but optional actions\nnote for anything else\n\n<Admonition type=\"note\" label=\"Optional label displays as title\">\n\nYour content here\n\n</Admonition>\n\n    \n      \n    \n\n      \n    \n\n    \n  \nBlockquotes\nDon't use blockquotes.\nCode blocks\nKeep code lines short to avoid scrolling. For example, you can split long shell commands with \\.\n\n\nJavaScript/TypeScript\nThe supabase repo uses Prettier, which also formats JS/TS in code blocks. Your PR is blocked from merging if the Prettier check fails. Ensure that your code blocks are formatted by running npm run format, or by setting up auto-formatting in your IDE.\n\n\nSQL\nPrefer lowercase for SQL. For example, select * from table rather than SELECT * FROM table.\n\n\nOptionally specify a filename for the codeblock by including it after the opening backticks and language specifier:\n```ts environment.ts\n    \n      \n    \n\n      \n    \n\n    \n  \nOptionally highlight lines by using mark=${lineNumber}.\n```js mark=12:13\n    \n      \n    \n\n      \n    \n\n    \n  \nFootnotes\nDon't use footnotes.\nImages\nImages are uploaded in the apps/docs/public/img folder.\nFor vector illustrations, use svg. For screenshots and non-vector graphics, use png. (These are automatically converted to webp for supported browsers.)\nRedact any sensitive information, such as API keys.\nLinks\nLink text should be descriptive. The reader should understand where the link goes from reading the link text alone. This is important for accessibility. For example, don't use here as link text.\nBut link text shouldn't be too long. Use the shortest part of the link that is descriptive enough. For example, see the [reference section](/link) rather than [see the reference section](/link).\nUse relative links when linking within the supabase.com domain. For example, [link to another page in Supabase docs](/docs/guides/getting-started).\nLists\nUse ordered lists for steps that must be taken one after the other. Use unordered lists when order doesn't matter.\nUse Arabic numerals (1, 2, 3) for ordered lists and dashes (-) for unordered lists.\nDon't nest lists more than two deep.\n1. List item\n2. List item\n   1. List item\n   2. List item\n3. List item\n   - List item\n   - List item\n   <!-- DON'T ADD ANOTHER LEVEL OF NESTING -->\n     - Overly nested list item\n    \n      \n    \n\n      \n    \n\n    \n  \nTabs\nUse tabs to provide alternative instructions for different platforms or languages.\nThe queryGroup param is optional. It lets you link directly to a tab by using the query group as a query param in the URL, for example: https://supabase.com/docs/my-page?packagemanager=ts\n<Tabs\n  scrollable\n  size=\"small\"\n  type=\"underlined\"\n  defaultActiveId=\"npm\"\n  queryGroup=\"packagemanager\"\n>\n<TabPanel id=\"npm\" label=\"npm\">\n\n// ...\n\n</TabPanel>\n<TabPanel id=\"yarn\" label=\"Yarn\">\n\n// ...\n\n</TabPanel>\n</Tabs>\n\n    \n      \n    \n\n      \n    \n\n    \n  \nVideos\nInclude videos as TOC (Table of Contents) videos rather than putting them in the main text.\nYou can define a TOC video in the page frontmatter:\n---\ntocVideo: 'rzglqRdZUQE',\n---\n    \n      \n    \n\n      \n    \n\n    \n  \nStyling, formatting, and grammar\nDon't worry too much about grammar rules. Grammar is useful if, and only if, it makes your writing clearer. For example, you can use sentence fragments if they're self-explanatory.\nThat said, a few rules help keep the docs concise, consistent, and clear:\n\nFormat headings in sentence case. Capitalize the first word and any proper nouns. All other words are lowercase. For example, Set up authentication rather than Set Up Authentication.\nUse the Oxford comma (a comma before the and that marks the last item in a list). For example, realtime, database, and authentication rather than realtime, database and authentication.\nUse the present tense as much as possible. For example, the AI assistant answers your question rather than the AI assistant will answer your question.\n\nWord usage and spelling\nUse American English. If in doubt, consult the Merriam-Webster dictionary.\nHere are some exceptions and Supabase-specific guidelines.\nGeneral word usage\n\nFiller words: You can often make your writing more concise by removing these words. (Some of these words can also sound patronizing.)\n\nActually\nEasy, easily\nJust\nLet's\nPlease\nSimple, simply\n\n\nUI elements\n\nButtons are clicked.\nCheckboxes are selected.\nToggles are enabled and disabled.\nLabels of UI elements are bolded. For example, Click **Confirm**.\n\n\n\nWord list\n\nBackend isn't hyphenated (not back-end).\nFrontend isn't hyphenated (not front-end).\nLogin is a noun. Log in is a verb.\nPostgres is capitalized, except in code, and used instead of PostgreSQL.\nSetup is a noun. Set up is a verb.\nSupabase is capitalized (not supabase), except in code.\nSupabase Platform is in title case (not Supabase platform).\n\nSearch\nSearch is handled using a Supabase instance. During CI, a script aggregates all content sources (eg. guides, reference docs, etc), indexes them using OpenAI embeddings, and stores them in a Supabase database.\nSearch uses a hybrid of native Postgres FTS and embedding similarity search based on pgvector. At runtime, a PostgREST call triggers the RPC that runs the weighted FTS search, and an Edge Function is executed to perform the embedding search.\nContributing to Supabase docs\nOur docs help developers to get started and keep succeeding with Supabase. We welcome contributions from everyone.\nIf you'd like to contribute, see our list of recommended issues. We also welcome you to open a PR or a new issue with your question.\nHere are some general guidelines on writing docs for Supabase.\nGeneral principles\nDocs should be helpful, quick to read, and easy to understand. We have an audience of global readers who speak different native languages.\nTo make docs as clear as possible:\nDocument types\nSupabase docs contain 4 types of documents. Before you start writing, think about what type of doc you need.\nExplainers\nExplainers help the reader to learn a topic. They are conceptual and mostly prose-based. They can include:\nThey shouldn't include:\nTutorials\nTutorials are goal-oriented. They help a reader to finish a large, complex goal, such as setting up a web app that uses multiple Supabase features.\nTutorials mix prose explanations with procedures (lists of steps for the reader to follow). They provide context for why certain instructions are given.\nFor inspiration, see an example of a tutorial.\nGuides\nGuides are also goal-oriented, but they focus on shorter, more targeted tasks. For example, a guide might explain how to set up user login for an app.\nGuides contain mostly procedures. Think of an instruction manual for building a desk: it's a list of concise steps that the user can go through quickly.\nFor inspiration, see an example of a guide.\nReference\nReferences are factual and to the point. Think of dictionary entries.\nThey should include:\nThey shouldn't include:\nRepo organization\nMost docs pages are contained in the apps/docs/content directory. Some docs sections are federated from other repositories, for example pg_graphql. Reference docs are generated from spec files in the spec directory.\nYou can usually identify a federated or reference doc because it uses a Next.js dynamic route (for example, [[...slug]].tsx). Look for the spec file import or the repo definition to find the content location.\nExample spec file import:\nExample repo definition:\nCheck the sections for guide structure and reference structure to learn more about the file structures.\nGuide structure\nThe Supabase docs use MDX. Guides are written in unstructured prose as MDX documents.\nAdding a new guide requires:\nFrontmatter looks like this. title is mandatory. There are also optional properties that you can use to control the page display, including subtitle, tocVideo, and hideToc.\nThe navigation is defined in NavigationMenu.constants.ts.\nAdd an entry with the name, url, and (optional) icon for your page.\nReference structure\nReference docs are produced from the reference specs and library source code. A common spec file contains shared function and endpoint definitions, and library-specific spec files contain further details.\nCommon spec file\nEach type of library (for example, language SDK or CLI) has a common spec file. For example, see the spec file for the language SDKs. This file contains definitions for the common SDK functions:\nTo add a new function, manually add an entry to this common file.\nSpecific spec file\nEach library also has its own spec file containing library-specific details. For example, see the JavaScript SDK spec file.\nThe functions listed in this file match the ones defined in the common spec file.\nEach function contains a description, code examples, and optional notes. The parameters are pulled from the source code via the $ref property, which references a function definition in the source code repo. These references are pulled down and transformed using commands in the spec Makefile. Unless you're a library maintainer, you don't need to worry about this.\nIf you're a library maintainer, follow these steps when updating function parameters or return values:\nContent reuse\nIf you copy the same content multiple times across different files, create a partial for content reuse instead. Partials are MDX files contained in apps/docs/components/MDX. They contain reusable snippets that can be inserted in multiple pages. For example, you can create a partial to define a common setup step for a group of tutorials.\nTo use a partial, import it into your MDX file. You can also set up a partial to automatically import by including it in the components within apps/docs/components/index.tsx.\nComponents and elements\nDocs include normal Markdown elements such as lists, and custom components such as admonitions (callouts).\nHere are some guidelines for using elements:\nAdmonitions\nAdmonitions (or callouts) draw reader attention to an important point or an aside. They highlight important information, but get less effective if they're overused.\nUse admonitions sparingly. Don't stack them on top of each other.\nChoose the appropriate type for your admonition:\nBlockquotes\nDon't use blockquotes.\nCode blocks\nKeep code lines short to avoid scrolling. For example, you can split long shell commands with \\.\nJavaScript/TypeScript\nThe supabase repo uses Prettier, which also formats JS/TS in code blocks. Your PR is blocked from merging if the Prettier check fails. Ensure that your code blocks are formatted by running npm run format, or by setting up auto-formatting in your IDE.\nSQL\nPrefer lowercase for SQL. For example, select * from table rather than SELECT * FROM table.\nOptionally specify a filename for the codeblock by including it after the opening backticks and language specifier:\nOptionally highlight lines by using mark=${lineNumber}.\nFootnotes\nDon't use footnotes.\nImages\nImages are uploaded in the apps/docs/public/img folder.\nFor vector illustrations, use svg. For screenshots and non-vector graphics, use png. (These are automatically converted to webp for supported browsers.)\nRedact any sensitive information, such as API keys.\nLinks\nLink text should be descriptive. The reader should understand where the link goes from reading the link text alone. This is important for accessibility. For example, don't use here as link text.\nBut link text shouldn't be too long. Use the shortest part of the link that is descriptive enough. For example, see the [reference section](/link) rather than [see the reference section](/link).\nUse relative links when linking within the supabase.com domain. For example, [link to another page in Supabase docs](/docs/guides/getting-started).\nLists\nUse ordered lists for steps that must be taken one after the other. Use unordered lists when order doesn't matter.\nUse Arabic numerals (1, 2, 3) for ordered lists and dashes (-) for unordered lists.\nDon't nest lists more than two deep.\nTabs\nUse tabs to provide alternative instructions for different platforms or languages.\nThe queryGroup param is optional. It lets you link directly to a tab by using the query group as a query param in the URL, for example: https://supabase.com/docs/my-page?packagemanager=ts\nVideos\nInclude videos as TOC (Table of Contents) videos rather than putting them in the main text.\nYou can define a TOC video in the page frontmatter:\nStyling, formatting, and grammar\nDon't worry too much about grammar rules. Grammar is useful if, and only if, it makes your writing clearer. For example, you can use sentence fragments if they're self-explanatory.\nThat said, a few rules help keep the docs concise, consistent, and clear:\nWord usage and spelling\nUse American English. If in doubt, consult the Merriam-Webster dictionary.\nHere are some exceptions and Supabase-specific guidelines.\nGeneral word usage\nWord list\nSearch\nSearch is handled using a Supabase instance. During CI, a script aggregates all content sources (eg. guides, reference docs, etc), indexes them using OpenAI embeddings, and stores them in a Supabase database.\nSearch uses a hybrid of native Postgres FTS and embedding similarity search based on pgvector. At runtime, a PostgREST call triggers the RPC that runs the weighted FTS search, and an Edge Function is executed to perform the embedding search.\nFooter\nFooter navigation"
  },
  {
    "id": "53",
    "url": "https://supabase.com/open-source",
    "title": "Supabase Open Source Community",
    "content": "Enterprise\nPricing\nDocs\nBlog\nOpen Source Community\nSupabase is an open source company, actively fostering collaboration and supporting existing open source tools and communities.\nSponsored Projects\nWe don't just live and breath open-source, we also sponsor projects we love.\npostgrest\nPostgREST is a standalone web server that turns your PostgreSQL database directly into a RESTful API.\npgroonga\nPGroonga is a PostgreSQL extension to use Groonga as index. PGroonga makes PostgreSQL fast full text search platform for all languages!\npgsodium\nModern cryptography for PostgreSQL using libsodium.\nOpen Collective Profile\nWe have contributed with more than $250,000 on paying sponsorships.\nOrioleDB\nSponsoring OrioleDB â€“ the next generation storage engine for PostgreSQL\nElixir\nElixir is a dynamic, functional language for building scalable and maintainable applications.\nBuild in a weekend, scale to millions\nFooter\nProduct\nResources\nDevelopers\nCompany\n"
  },
  {
    "id": "54",
    "url": "https://supabase.com/supasquad",
    "title": "SupaSquad | Supabase",
    "content": "Enterprise\nPricing\nDocs\nBlog\nSupaSquad#\nThe SupaSquad is an official Supabase advocate program where community members help build and manage the Supabase community.\n\nRequirements#\nAs a member of the Squad, you choose the approach where you'll provide the most value.\nYou can help in one of five ways:\nMaintainer#\nHelp maintain Supabase repositories. This includes building client libraries, managing issues, and fixing bugs.\nExpert#\nAnswer user questions on GitHub Discussions, Discord, and various other social platforms.\nAdvocate#\nSpread the word on social channels and help to answer Supabase-related questions in the broader community and social channels.\nBuilder#\nBuild Supabase examples, blog about them, and add them to the Supabase repo.\nAuthor#\nWrite guest blog posts, create documentation, and help Supabase global expansion through translation.\nModerator#\nHelp us maintain the community guidelines in our GitHub and Community-led communities such as Discord, Reddit,\nStackOverflow, etc.\nBenefits for SupaSquad members#\nHow to join#\nApply to join the program using this form.\nFAQs#\nThe entire Supabase team is only 20 people, so as you can imagine adding another 20 people sounds like\na lot to us! We wish we could admit everyone who wanted to join. But we also want to make sure everyone\nwho joins the Squad has an awesome experience. In the future we will probably expand the intake to\ninclude a monthly quota.\nMostly just enthusiasm. If you are interested in Open Source and want to get involved, the SupaSquad\nprogram is a great channel. You'll be given opportunities to contribute to the community in whatever\nways match your skillset.\nNo worries! The program isn't a job. It's just an opportunity to build your skillset and audience within\nthe Supabase ecosystem.\nFooter\nProduct\nResources\nDevelopers\nCompany\n"
  },
  {
    "id": "55",
    "url": "https://github.com/supabase/supabase",
    "title": "GitHub - supabase/supabase: The open source Firebase alternative. Supabase gives you a dedicated Postgres database to build your web, mobile, and AI applications.",
    "content": "Navigation Menu\nSearch code, repositories, users, issues, pull requests...\nProvide feedback\nWe read every piece of feedback, and take your input very seriously.\nSaved searches\nUse saved searches to filter your results more quickly\nTo see all available qualifiers, see our documentation.\nThe open source Firebase alternative. Supabase gives you a dedicated Postgres database to build your web, mobile, and AI applications.\nLicense\nsupabase/supabase\nFolders and files\nLatest commit\nHistory\nRepository files navigation\nSupabase\nSupabase is an open source Firebase alternative. We're building the features of Firebase using enterprise-grade open source tools.\n\n Hosted Postgres Database. Docs\n Authentication and Authorization. Docs\n Auto-generated APIs.\n\n REST. Docs\n GraphQL. Docs\n Realtime subscriptions. Docs\n\n\n Functions.\n\n Database Functions. Docs\n Edge Functions Docs\n\n\n File Storage. Docs\n AI + Vector/Embeddings Toolkit. Docs\n Dashboard\n\n\nWatch \"releases\" of this repo to get notified of major updates.\n\n      \n        \n          \n        \n            \n          \n        \n        \n          \n            \n              \n            \n            \n              \n              \n            \n          \n          \n            \n              \n            \n          \n        \n      \nDocumentation\nFor full documentation, visit supabase.com/docs\nTo see how to Contribute, visit Getting Started\nCommunity & Support\n\nCommunity Forum. Best for: help with building, discussion about database best practices.\nGitHub Issues. Best for: bugs and errors you encounter using Supabase.\nEmail Support. Best for: problems with your database or infrastructure.\nDiscord. Best for: sharing your applications and hanging out with the community.\n\nHow it works\nSupabase is a combination of open source tools. Weâ€™re building the features of Firebase using enterprise-grade, open source products. If the tools and communities exist, with an MIT, Apache 2, or equivalent open license, we will use and support that tool. If the tool doesn't exist, we build and open source it ourselves. Supabase is not a 1-to-1 mapping of Firebase. Our aim is to give developers a Firebase-like developer experience using open source tools.\nArchitecture\nSupabase is a hosted platform. You can sign up and start using Supabase without installing anything.\nYou can also self-host and develop locally.\n\n\nPostgres is an object-relational database system with over 30 years of active development that has earned it a strong reputation for reliability, feature robustness, and performance.\nRealtime is an Elixir server that allows you to listen to PostgreSQL inserts, updates, and deletes using websockets. Realtime polls Postgres' built-in replication functionality for database changes, converts changes to JSON, then broadcasts the JSON over websockets to authorized clients.\nPostgREST is a web server that turns your PostgreSQL database directly into a RESTful API\nGoTrue is a JWT based API for managing users and issuing JWT tokens.\nStorage provides a RESTful interface for managing Files stored in S3, using Postgres to manage permissions.\npg_graphql a PostgreSQL extension that exposes a GraphQL API\npostgres-meta is a RESTful API for managing your Postgres, allowing you to fetch tables, add roles, and run queries, etc.\nKong is a cloud-native API gateway.\n\nClient libraries\nOur approach for client libraries is modular. Each sub-library is a standalone implementation for a single external system. This is one of the ways we support existing tools.\n\n  \n    Language\n    Client\n    Feature-Clients (bundled in Supabase client)\n  \n  \n  \n    \n    Supabase\n    PostgREST\n    GoTrue\n    Realtime\n    Storage\n    Functions\n  \n  \n  \n  \n  âš¡ï¸ Official âš¡ï¸\n  \n  \n    JavaScript (TypeScript)\n    supabase-js\n    postgrest-js\n    gotrue-js\n    realtime-js\n    storage-js\n    functions-js\n  \n    \n    Flutter\n    supabase-flutter\n    postgrest-dart\n    gotrue-dart\n    realtime-dart\n    storage-dart\n    functions-dart\n  \n  \n    Swift\n    supabase-swift\n    postgrest-swift\n    auth-swift\n    realtime-swift\n    storage-swift\n    functions-swift\n  \n  \n    Python\n    supabase-py\n    postgrest-py\n    gotrue-py\n    realtime-py\n    storage-py\n    functions-py\n  \n  \n  ðŸ’š Community ðŸ’š\n  \n  \n    C#\n    supabase-csharp\n    postgrest-csharp\n    gotrue-csharp\n    realtime-csharp\n    storage-csharp\n    functions-csharp\n  \n  \n    Go\n    -\n    postgrest-go\n    gotrue-go\n    -\n    storage-go\n    functions-go\n  \n  \n    Java\n    -\n    -\n    gotrue-java\n    -\n    storage-java\n    -\n  \n  \n    Kotlin\n    supabase-kt\n    postgrest-kt\n    auth-kt\n    realtime-kt\n    storage-kt\n    functions-kt\n  \n  \n    Ruby\n    supabase-rb\n    postgrest-rb\n    -\n    -\n    -\n    -\n  \n  \n    Rust\n    -\n    postgrest-rs\n    -\n    -\n    -\n    -\n  \n  \n    Godot Engine (GDScript)\n    supabase-gdscript\n    postgrest-gdscript\n    gotrue-gdscript\n    realtime-gdscript\n    storage-gdscript\n    functions-gdscript\n  \n  \n\n\n\nBadges\n\n[![Made with Supabase](https://supabase.com/badge-made-with-supabase.svg)](https://supabase.com)\n    \n      \n    \n\n      \n    \n\n    \n  \n<a href=\"https://supabase.com\">\n  <img\n    width=\"168\"\n    height=\"30\"\n    src=\"https://supabase.com/badge-made-with-supabase.svg\"\n    alt=\"Made with Supabase\"\n  />\n</a>\n    \n      \n    \n\n      \n    \n\n    \n  \n\n[![Made with Supabase](https://supabase.com/badge-made-with-supabase-dark.svg)](https://supabase.com)\n    \n      \n    \n\n      \n    \n\n    \n  \n<a href=\"https://supabase.com\">\n  <img\n    width=\"168\"\n    height=\"30\"\n    src=\"https://supabase.com/badge-made-with-supabase-dark.svg\"\n    alt=\"Made with Supabase\"\n  />\n</a>\n    \n      \n    \n\n      \n    \n\n    \n  \nTranslations\n\nArabic | Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©\nAlbanian / Shqip\nBangla / à¦¬à¦¾à¦‚à¦²à¦¾\nBulgarian / Ð‘ÑŠÐ»Ð³Ð°Ñ€ÑÐºÐ¸\nCatalan / CatalÃ \nCzech / ÄeÅ¡tina\nDanish / Dansk\nDutch / Nederlands\nEnglish\nEstonian / eesti keel\nFinnish / Suomalainen\nFrench / FranÃ§ais\nGerman / Deutsch\nGreek / Î•Î»Î»Î·Î½Î¹ÎºÎ¬\nGujarati / àª—à«àªœàª°àª¾àª¤à«€\nHebrew / ×¢×‘×¨×™×ª\nHindi / à¤¹à¤¿à¤‚à¤¦à¥€\nHungarian / Magyar\nNepali / à¤¨à¥‡à¤ªà¤¾à¤²à¥€\nIndonesian / Bahasa Indonesia\nItaliano / Italian\nJapanese / æ—¥æœ¬èªž\nKorean / í•œêµ­ì–´\nLithuanian / lietuviÅ³\nLatvian / latviski\nMalay / Bahasa Malaysia\nNorwegian (BokmÃ¥l) / Norsk (BokmÃ¥l)\nPersian / ÙØ§Ø±Ø³ÛŒ\nPolish / Polski\nPortuguese / PortuguÃªs\nPortuguese (Brazilian) / PortuguÃªs Brasileiro\nRomanian / RomÃ¢nÄƒ\nRussian / PÑƒÑÑÐºÐ¸Ð¹\nSerbian / Srpski\nSinhala / à·ƒà·’à¶‚à·„à¶½\nSlovak / slovenskÃ½\nSlovenian / SlovenÅ¡Äina\nSpanish / EspaÃ±ol\nSimplified Chinese / ç®€ä½“ä¸­æ–‡\nSwedish / Svenska\nThai / à¹„à¸—à¸¢\nTraditional Chinese / ç¹é«”ä¸­æ–‡\nTurkish / TÃ¼rkÃ§e\nUkrainian / Ð£ÐºÑ€Ð°Ñ—Ð½ÑÑŒÐºÐ°\nVietnamese / Tiáº¿ng Viá»‡t\nList of translations\n\nSupabase\nSupabase is an open source Firebase alternative. We're building the features of Firebase using enterprise-grade open source tools.\n\nWatch \"releases\" of this repo to get notified of major updates.\n\nDocumentation\nFor full documentation, visit supabase.com/docs\nTo see how to Contribute, visit Getting Started\nCommunity & Support\nHow it works\nSupabase is a combination of open source tools. Weâ€™re building the features of Firebase using enterprise-grade, open source products. If the tools and communities exist, with an MIT, Apache 2, or equivalent open license, we will use and support that tool. If the tool doesn't exist, we build and open source it ourselves. Supabase is not a 1-to-1 mapping of Firebase. Our aim is to give developers a Firebase-like developer experience using open source tools.\nArchitecture\nSupabase is a hosted platform. You can sign up and start using Supabase without installing anything.\nYou can also self-host and develop locally.\n\nClient libraries\nOur approach for client libraries is modular. Each sub-library is a standalone implementation for a single external system. This is one of the ways we support existing tools.\nBadges\n\n\nTranslations\nAbout\nThe open source Firebase alternative. Supabase gives you a dedicated Postgres database to build your web, mobile, and AI applications.\nTopics\nResources\nLicense\nCode of conduct\nSecurity policy\nStars\nWatchers\nForks\nReleases\n      17\nSponsor this project\nPackages\n      0\nContributors\n      1,352\nLanguages\nFooter\nFooter navigation"
  },
  {
    "id": "56",
    "url": "https://twitter.com/supabase",
    "title": "Profile / X",
    "content": "\nProfile\nNew to X?Sign up now to get your own personalized timeline!Sign up with GoogleSign up with GoogleSign up with AppleCreate accountBy signing up, you agree to the Terms of Service and Privacy Policy, including Cookie Use.\nNew to X?"
  },
  {
    "id": "57",
    "url": "https://discord.supabase.com/",
    "title": "Discord",
    "content": "Opening Discord App.\nOpening Discord App."
  }
]